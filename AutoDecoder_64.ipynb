{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4000\n",
    "batch_size = 64\n",
    "learning_rate = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./data/train_data.csv\")\n",
    "test = pd.read_csv(\"./data/test_data.csv\")\n",
    "train = train.drop(train.iloc[581:597,:].index.values) # motor vibe 중 이상치 데이터 삭제\n",
    "\n",
    "ss = RobustScaler()\n",
    "\n",
    "scaled_train = ss.fit_transform(train)\n",
    "scaled_test = ss.transform(test)\n",
    "\n",
    "train_data = scaled_train\n",
    "test_data = scaled_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = keras.losses.MeanSquaredError()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoDecoder(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(AutoDecoder, self).__init__()\n",
    "        self.decoder = keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(1e-9))\n",
    "        self.encoder = keras.layers.Dense(units=8,input_shape=[2463, 1, 8])\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        if training:\n",
    "            self.decoder.trainable = True\n",
    "            self.encoder.trainable = True\n",
    "\n",
    "        else:\n",
    "            self.decoder.trainable = False\n",
    "            self.encoder.trainable = False\n",
    "\n",
    "        x = self.decoder(inputs)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def train(self):\n",
    "        self.decoder.trainable = True\n",
    "        self.encoder.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, epochs, batch, loss_function, optimizer, patience=10):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.batch = batch\n",
    "        self.loss_function = loss_function\n",
    "        self.optimizer = optimizer\n",
    "        self.patience = patience\n",
    "        self.min_loss = np.Inf\n",
    "        self.counter = 0\n",
    "        self.history = {'train_loss':[], 'val_loss':[]}\n",
    "\n",
    "    def train(self, train_data, valid=False):\n",
    "        if valid == False:\n",
    "            valid_dataset = []\n",
    "            train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_data)).batch(batch_size)\n",
    "        else:\n",
    "            train_dataset, valid_dataset = train_test_split(train_data, test_size=0.2, stratify=train_data[:, 7], random_state=0)\n",
    "            n_train = len(train_dataset)\n",
    "            n_val = len(valid_dataset)\n",
    "            # train_dataset's shape : [step, batch_x_train, batch_y_train]\n",
    "            train_dataset = tf.data.Dataset.from_tensor_slices((train_dataset, train_dataset)).batch(batch_size)\n",
    "            valid_dataset = tf.data.Dataset.from_tensor_slices((valid_dataset, valid_dataset)).batch(batch_size)\n",
    "            \n",
    "        for epoch in range(self.epochs):\n",
    "            self.model.train()\n",
    "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "            # progress bar\n",
    "            progBar = Progbar(len(train_dataset) * self.batch, stateful_metrics=['train_loss', 'val_loss'])\n",
    "            total_loss = 0\n",
    "            step = 0\n",
    "\n",
    "            # start train\n",
    "            for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logits = self.model(x_batch_train, training=True)\n",
    "                    loss = self.loss_function(y_batch_train, logits)\n",
    "                grads = tape.gradient(loss, self.model.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n",
    "\n",
    "                total_loss += loss\n",
    "                if valid == False:\n",
    "                    values = [('train_loss', loss)]\n",
    "                    progBar.update((step + 1) * self.batch, values=values)\n",
    "            train_loss = total_loss / n_train\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            \n",
    "            # Calculate validation loss\n",
    "            if n_val:\n",
    "                # if validation set exists, do validation\n",
    "                valid_loss = self.evaluate(valid_dataset)\n",
    "                valid_loss /= n_val\n",
    "                self.history['val_loss'].append(valid_loss)\n",
    "                \n",
    "                # Check if validation loss has improved, if not increase counter\n",
    "                if valid_loss >= self.min_loss:\n",
    "                    self.counter += 1\n",
    "                else:\n",
    "                    self.min_loss = valid_loss\n",
    "                    self.counter = 0\n",
    "                \n",
    "                # Stop training if counter has reached patience\n",
    "                if self.counter >= self.patience:\n",
    "                    print(\"Validation loss did not improve for %d epochs. Training stopped.\" % (self.patience,))\n",
    "                    print(f\"Best Validation Loss : {self.min_loss}\")\n",
    "                    break\n",
    "\n",
    "                values = [('train_loss', train_loss), ('val_loss', valid_loss)]\n",
    "                progBar.update(len(train_dataset) * self.batch, values=values, finalize=True)\n",
    "\n",
    "        plot_graph(self.history)\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        total_loss = 0\n",
    "        for x, y in dataset:\n",
    "            logits = self.model(x, training=False)\n",
    "            loss = self.loss_function(y, logits)\n",
    "            total_loss += loss\n",
    "            \n",
    "        return total_loss\n",
    "    \n",
    "def plot_graph(history, start=0):\n",
    "    train_data = history[\"train_loss\"][start:]\n",
    "    val_data = history[\"val_loss\"][start:]\n",
    "    n_train = len(train_data)\n",
    "\n",
    "    gap = n_train // 5\n",
    "\n",
    "    plt.plot(train_data, linewidth=2, label=\"train\")\n",
    "    plt.plot(val_data, linewidth=2, label=\"val\")\n",
    "    \n",
    "    plt.xticks(range(0, n_train+1, gap), range(start, start+n_train+1, gap))\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"auto_decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  576       \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  520       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,096\n",
      "Trainable params: 1,096\n",
      "Non-trainable params: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "\n",
      "Start of epoch 0\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 0.0061 - val_loss: 0.0049\n",
      "\n",
      "Start of epoch 1\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 0.0049 - val_loss: 0.0039\n",
      "\n",
      "Start of epoch 2\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 0.0039 - val_loss: 0.0032\n",
      "\n",
      "Start of epoch 3\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 0.0031 - val_loss: 0.0026\n",
      "\n",
      "Start of epoch 4\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 0.0025 - val_loss: 0.0021\n",
      "\n",
      "Start of epoch 5\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 0.0020 - val_loss: 0.0017\n",
      "\n",
      "Start of epoch 6\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 0.0016 - val_loss: 0.0013\n",
      "\n",
      "Start of epoch 7\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 0.0013 - val_loss: 0.0011\n",
      "\n",
      "Start of epoch 8\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 0.0010 - val_loss: 8.9662e-04\n",
      "\n",
      "Start of epoch 9\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 8.4688e-04 - val_loss: 7.4388e-04\n",
      "\n",
      "Start of epoch 10\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 6.9972e-04 - val_loss: 6.2047e-04\n",
      "\n",
      "Start of epoch 11\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 5.8114e-04 - val_loss: 5.1873e-04\n",
      "\n",
      "Start of epoch 12\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.8367e-04 - val_loss: 4.3356e-04\n",
      "\n",
      "Start of epoch 13\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.0245e-04 - val_loss: 3.6191e-04\n",
      "\n",
      "Start of epoch 14\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.3438e-04 - val_loss: 3.0146e-04\n",
      "\n",
      "Start of epoch 15\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.7725e-04 - val_loss: 2.5082e-04\n",
      "\n",
      "Start of epoch 16\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.2982e-04 - val_loss: 2.0893e-04\n",
      "\n",
      "Start of epoch 17\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.9077e-04 - val_loss: 1.7459e-04\n",
      "\n",
      "Start of epoch 18\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5896e-04 - val_loss: 1.4670e-04\n",
      "\n",
      "Start of epoch 19\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3326e-04 - val_loss: 1.2428e-04\n",
      "\n",
      "Start of epoch 20\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1266e-04 - val_loss: 1.0630e-04\n",
      "\n",
      "Start of epoch 21\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.6163e-05 - val_loss: 9.1932e-05\n",
      "\n",
      "Start of epoch 22\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.3106e-05 - val_loss: 8.0572e-05\n",
      "\n",
      "Start of epoch 23\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.2837e-05 - val_loss: 7.1591e-05\n",
      "\n",
      "Start of epoch 24\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.4749e-05 - val_loss: 6.4423e-05\n",
      "\n",
      "Start of epoch 25\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.8317e-05 - val_loss: 5.8640e-05\n",
      "\n",
      "Start of epoch 26\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.3121e-05 - val_loss: 5.3892e-05\n",
      "\n",
      "Start of epoch 27\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.8851e-05 - val_loss: 4.9921e-05\n",
      "\n",
      "Start of epoch 28\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.5274e-05 - val_loss: 4.6549e-05\n",
      "\n",
      "Start of epoch 29\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.2233e-05 - val_loss: 4.3647e-05\n",
      "\n",
      "Start of epoch 30\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.9619e-05 - val_loss: 4.1119e-05\n",
      "\n",
      "Start of epoch 31\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.7338e-05 - val_loss: 3.8885e-05\n",
      "\n",
      "Start of epoch 32\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.5326e-05 - val_loss: 3.6901e-05\n",
      "\n",
      "Start of epoch 33\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 3.3536e-05 - val_loss: 3.5111e-05\n",
      "\n",
      "Start of epoch 34\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.1925e-05 - val_loss: 3.3488e-05\n",
      "\n",
      "Start of epoch 35\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.0466e-05 - val_loss: 3.2008e-05\n",
      "\n",
      "Start of epoch 36\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.9133e-05 - val_loss: 3.0646e-05\n",
      "\n",
      "Start of epoch 37\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.7915e-05 - val_loss: 2.9399e-05\n",
      "\n",
      "Start of epoch 38\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.6798e-05 - val_loss: 2.8251e-05\n",
      "\n",
      "Start of epoch 39\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 2.5770e-05 - val_loss: 2.7192e-05\n",
      "\n",
      "Start of epoch 40\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 2.4820e-05 - val_loss: 2.6208e-05\n",
      "\n",
      "Start of epoch 41\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.3935e-05 - val_loss: 2.5292e-05\n",
      "\n",
      "Start of epoch 42\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.3109e-05 - val_loss: 2.4434e-05\n",
      "\n",
      "Start of epoch 43\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.2336e-05 - val_loss: 2.3632e-05\n",
      "\n",
      "Start of epoch 44\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.1613e-05 - val_loss: 2.2883e-05\n",
      "\n",
      "Start of epoch 45\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.0935e-05 - val_loss: 2.2180e-05\n",
      "\n",
      "Start of epoch 46\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.0298e-05 - val_loss: 2.1517e-05\n",
      "\n",
      "Start of epoch 47\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.9696e-05 - val_loss: 2.0892e-05\n",
      "\n",
      "Start of epoch 48\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.9128e-05 - val_loss: 2.0298e-05\n",
      "\n",
      "Start of epoch 49\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.8589e-05 - val_loss: 1.9734e-05\n",
      "\n",
      "Start of epoch 50\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8074e-05 - val_loss: 1.9196e-05\n",
      "\n",
      "Start of epoch 51\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.7583e-05 - val_loss: 1.8683e-05\n",
      "\n",
      "Start of epoch 52\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.7115e-05 - val_loss: 1.8194e-05\n",
      "\n",
      "Start of epoch 53\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6667e-05 - val_loss: 1.7727e-05\n",
      "\n",
      "Start of epoch 54\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.6238e-05 - val_loss: 1.7280e-05\n",
      "\n",
      "Start of epoch 55\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.5825e-05 - val_loss: 1.6851e-05\n",
      "\n",
      "Start of epoch 56\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5429e-05 - val_loss: 1.6439e-05\n",
      "\n",
      "Start of epoch 57\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5048e-05 - val_loss: 1.6044e-05\n",
      "\n",
      "Start of epoch 58\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4680e-05 - val_loss: 1.5663e-05\n",
      "\n",
      "Start of epoch 59\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4323e-05 - val_loss: 1.5293e-05\n",
      "\n",
      "Start of epoch 60\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.3978e-05 - val_loss: 1.4936e-05\n",
      "\n",
      "Start of epoch 61\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.3644e-05 - val_loss: 1.4590e-05\n",
      "\n",
      "Start of epoch 62\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.3320e-05 - val_loss: 1.4255e-05\n",
      "\n",
      "Start of epoch 63\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.3006e-05 - val_loss: 1.3929e-05\n",
      "\n",
      "Start of epoch 64\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2700e-05 - val_loss: 1.3611e-05\n",
      "\n",
      "Start of epoch 65\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.2401e-05 - val_loss: 1.3303e-05\n",
      "\n",
      "Start of epoch 66\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.2110e-05 - val_loss: 1.3004e-05\n",
      "\n",
      "Start of epoch 67\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1828e-05 - val_loss: 1.2712e-05\n",
      "\n",
      "Start of epoch 68\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1553e-05 - val_loss: 1.2429e-05\n",
      "\n",
      "Start of epoch 69\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1286e-05 - val_loss: 1.2152e-05\n",
      "\n",
      "Start of epoch 70\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1027e-05 - val_loss: 1.1884e-05\n",
      "\n",
      "Start of epoch 71\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0774e-05 - val_loss: 1.1622e-05\n",
      "\n",
      "Start of epoch 72\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0528e-05 - val_loss: 1.1368e-05\n",
      "\n",
      "Start of epoch 73\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0290e-05 - val_loss: 1.1120e-05\n",
      "\n",
      "Start of epoch 74\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0058e-05 - val_loss: 1.0879e-05\n",
      "\n",
      "Start of epoch 75\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.8311e-06 - val_loss: 1.0644e-05\n",
      "\n",
      "Start of epoch 76\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.6092e-06 - val_loss: 1.0415e-05\n",
      "\n",
      "Start of epoch 77\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.3924e-06 - val_loss: 1.0190e-05\n",
      "\n",
      "Start of epoch 78\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.1805e-06 - val_loss: 9.9712e-06\n",
      "\n",
      "Start of epoch 79\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.9736e-06 - val_loss: 9.7574e-06\n",
      "\n",
      "Start of epoch 80\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 8.7718e-06 - val_loss: 9.5489e-06\n",
      "\n",
      "Start of epoch 81\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 8.5749e-06 - val_loss: 9.3454e-06\n",
      "\n",
      "Start of epoch 82\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 8.3822e-06 - val_loss: 9.1460e-06\n",
      "\n",
      "Start of epoch 83\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.1930e-06 - val_loss: 8.9493e-06\n",
      "\n",
      "Start of epoch 84\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 8.0079e-06 - val_loss: 8.7557e-06\n",
      "\n",
      "Start of epoch 85\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 7.8274e-06 - val_loss: 8.5675e-06\n",
      "\n",
      "Start of epoch 86\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.6518e-06 - val_loss: 8.3838e-06\n",
      "\n",
      "Start of epoch 87\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 7.4802e-06 - val_loss: 8.2035e-06\n",
      "\n",
      "Start of epoch 88\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 7.3122e-06 - val_loss: 8.0256e-06\n",
      "\n",
      "Start of epoch 89\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 7.1475e-06 - val_loss: 7.8504e-06\n",
      "\n",
      "Start of epoch 90\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 6.9863e-06 - val_loss: 7.6786e-06\n",
      "\n",
      "Start of epoch 91\n",
      "1984/1984 [==============================] - 0s 49us/step - train_loss: 6.8283e-06 - val_loss: 7.5107e-06\n",
      "\n",
      "Start of epoch 92\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 6.6738e-06 - val_loss: 7.3447e-06\n",
      "\n",
      "Start of epoch 93\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 6.5220e-06 - val_loss: 7.1807e-06\n",
      "\n",
      "Start of epoch 94\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 6.3731e-06 - val_loss: 7.0192e-06\n",
      "\n",
      "Start of epoch 95\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 6.2271e-06 - val_loss: 6.8605e-06\n",
      "\n",
      "Start of epoch 96\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 6.0840e-06 - val_loss: 6.7034e-06\n",
      "\n",
      "Start of epoch 97\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 5.9432e-06 - val_loss: 6.5493e-06\n",
      "\n",
      "Start of epoch 98\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 5.8049e-06 - val_loss: 6.3981e-06\n",
      "\n",
      "Start of epoch 99\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 5.6695e-06 - val_loss: 6.2504e-06\n",
      "\n",
      "Start of epoch 100\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 5.5378e-06 - val_loss: 6.1061e-06\n",
      "\n",
      "Start of epoch 101\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 5.4093e-06 - val_loss: 5.9652e-06\n",
      "\n",
      "Start of epoch 102\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 5.2839e-06 - val_loss: 5.8276e-06\n",
      "\n",
      "Start of epoch 103\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 5.1621e-06 - val_loss: 5.6935e-06\n",
      "\n",
      "Start of epoch 104\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 5.0437e-06 - val_loss: 5.5622e-06\n",
      "\n",
      "Start of epoch 105\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.9283e-06 - val_loss: 5.4333e-06\n",
      "\n",
      "Start of epoch 106\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.8153e-06 - val_loss: 5.3064e-06\n",
      "\n",
      "Start of epoch 107\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 4.7043e-06 - val_loss: 5.1819e-06\n",
      "\n",
      "Start of epoch 108\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.5951e-06 - val_loss: 5.0597e-06\n",
      "\n",
      "Start of epoch 109\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.4880e-06 - val_loss: 4.9388e-06\n",
      "\n",
      "Start of epoch 110\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.3827e-06 - val_loss: 4.8204e-06\n",
      "\n",
      "Start of epoch 111\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.2799e-06 - val_loss: 4.7050e-06\n",
      "\n",
      "Start of epoch 112\n",
      "1984/1984 [==============================] - 0s 50us/step - train_loss: 4.1791e-06 - val_loss: 4.5918e-06\n",
      "\n",
      "Start of epoch 113\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 4.0797e-06 - val_loss: 4.4809e-06\n",
      "\n",
      "Start of epoch 114\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.9817e-06 - val_loss: 4.3718e-06\n",
      "\n",
      "Start of epoch 115\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.8862e-06 - val_loss: 4.2661e-06\n",
      "\n",
      "Start of epoch 116\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 3.7933e-06 - val_loss: 4.1620e-06\n",
      "\n",
      "Start of epoch 117\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.7020e-06 - val_loss: 4.0608e-06\n",
      "\n",
      "Start of epoch 118\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.6124e-06 - val_loss: 3.9622e-06\n",
      "\n",
      "Start of epoch 119\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 3.5248e-06 - val_loss: 3.8666e-06\n",
      "\n",
      "Start of epoch 120\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 3.4394e-06 - val_loss: 3.7738e-06\n",
      "\n",
      "Start of epoch 121\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 3.3559e-06 - val_loss: 3.6831e-06\n",
      "\n",
      "Start of epoch 122\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 3.2751e-06 - val_loss: 3.5957e-06\n",
      "\n",
      "Start of epoch 123\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 3.1965e-06 - val_loss: 3.5111e-06\n",
      "\n",
      "Start of epoch 124\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.1203e-06 - val_loss: 3.4288e-06\n",
      "\n",
      "Start of epoch 125\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.0461e-06 - val_loss: 3.3488e-06\n",
      "\n",
      "Start of epoch 126\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 2.9743e-06 - val_loss: 3.2716e-06\n",
      "\n",
      "Start of epoch 127\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 2.9051e-06 - val_loss: 3.1972e-06\n",
      "\n",
      "Start of epoch 128\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.8385e-06 - val_loss: 3.1247e-06\n",
      "\n",
      "Start of epoch 129\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.7737e-06 - val_loss: 3.0548e-06\n",
      "\n",
      "Start of epoch 130\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 2.7114e-06 - val_loss: 2.9872e-06\n",
      "\n",
      "Start of epoch 131\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 2.6509e-06 - val_loss: 2.9214e-06\n",
      "\n",
      "Start of epoch 132\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.5915e-06 - val_loss: 2.8567e-06\n",
      "\n",
      "Start of epoch 133\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5332e-06 - val_loss: 2.7938e-06\n",
      "\n",
      "Start of epoch 134\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.4763e-06 - val_loss: 2.7329e-06\n",
      "\n",
      "Start of epoch 135\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.4207e-06 - val_loss: 2.6738e-06\n",
      "\n",
      "Start of epoch 136\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.3670e-06 - val_loss: 2.6164e-06\n",
      "\n",
      "Start of epoch 137\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.3146e-06 - val_loss: 2.5606e-06\n",
      "\n",
      "Start of epoch 138\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.2638e-06 - val_loss: 2.5070e-06\n",
      "\n",
      "Start of epoch 139\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.2144e-06 - val_loss: 2.4541e-06\n",
      "\n",
      "Start of epoch 140\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1667e-06 - val_loss: 2.4031e-06\n",
      "\n",
      "Start of epoch 141\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1204e-06 - val_loss: 2.3538e-06\n",
      "\n",
      "Start of epoch 142\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.0754e-06 - val_loss: 2.3058e-06\n",
      "\n",
      "Start of epoch 143\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.0314e-06 - val_loss: 2.2594e-06\n",
      "\n",
      "Start of epoch 144\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.9883e-06 - val_loss: 2.2143e-06\n",
      "\n",
      "Start of epoch 145\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.9461e-06 - val_loss: 2.1702e-06\n",
      "\n",
      "Start of epoch 146\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.9053e-06 - val_loss: 2.1271e-06\n",
      "\n",
      "Start of epoch 147\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8660e-06 - val_loss: 2.0856e-06\n",
      "\n",
      "Start of epoch 148\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8278e-06 - val_loss: 2.0455e-06\n",
      "\n",
      "Start of epoch 149\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.7907e-06 - val_loss: 2.0065e-06\n",
      "\n",
      "Start of epoch 150\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7545e-06 - val_loss: 1.9679e-06\n",
      "\n",
      "Start of epoch 151\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7196e-06 - val_loss: 1.9305e-06\n",
      "\n",
      "Start of epoch 152\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6857e-06 - val_loss: 1.8941e-06\n",
      "\n",
      "Start of epoch 153\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.6523e-06 - val_loss: 1.8583e-06\n",
      "\n",
      "Start of epoch 154\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6196e-06 - val_loss: 1.8233e-06\n",
      "\n",
      "Start of epoch 155\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 1.5873e-06 - val_loss: 1.7889e-06\n",
      "\n",
      "Start of epoch 156\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.5558e-06 - val_loss: 1.7560e-06\n",
      "\n",
      "Start of epoch 157\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.5255e-06 - val_loss: 1.7240e-06\n",
      "\n",
      "Start of epoch 158\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.4962e-06 - val_loss: 1.6932e-06\n",
      "\n",
      "Start of epoch 159\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.4678e-06 - val_loss: 1.6633e-06\n",
      "\n",
      "Start of epoch 160\n",
      "1984/1984 [==============================] - 0s 46us/step - train_loss: 1.4403e-06 - val_loss: 1.6342e-06\n",
      "\n",
      "Start of epoch 161\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.4136e-06 - val_loss: 1.6060e-06\n",
      "\n",
      "Start of epoch 162\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.3878e-06 - val_loss: 1.5786e-06\n",
      "\n",
      "Start of epoch 163\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.3628e-06 - val_loss: 1.5522e-06\n",
      "\n",
      "Start of epoch 164\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.3385e-06 - val_loss: 1.5264e-06\n",
      "\n",
      "Start of epoch 165\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3146e-06 - val_loss: 1.5014e-06\n",
      "\n",
      "Start of epoch 166\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2915e-06 - val_loss: 1.4765e-06\n",
      "\n",
      "Start of epoch 167\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2687e-06 - val_loss: 1.4523e-06\n",
      "\n",
      "Start of epoch 168\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2464e-06 - val_loss: 1.4289e-06\n",
      "\n",
      "Start of epoch 169\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2247e-06 - val_loss: 1.4066e-06\n",
      "\n",
      "Start of epoch 170\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2037e-06 - val_loss: 1.3851e-06\n",
      "\n",
      "Start of epoch 171\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1833e-06 - val_loss: 1.3644e-06\n",
      "\n",
      "Start of epoch 172\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1634e-06 - val_loss: 1.3444e-06\n",
      "\n",
      "Start of epoch 173\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1443e-06 - val_loss: 1.3252e-06\n",
      "\n",
      "Start of epoch 174\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1255e-06 - val_loss: 1.3065e-06\n",
      "\n",
      "Start of epoch 175\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1073e-06 - val_loss: 1.2879e-06\n",
      "\n",
      "Start of epoch 176\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0895e-06 - val_loss: 1.2698e-06\n",
      "\n",
      "Start of epoch 177\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.0723e-06 - val_loss: 1.2519e-06\n",
      "\n",
      "Start of epoch 178\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0554e-06 - val_loss: 1.2345e-06\n",
      "\n",
      "Start of epoch 179\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0389e-06 - val_loss: 1.2177e-06\n",
      "\n",
      "Start of epoch 180\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0230e-06 - val_loss: 1.2011e-06\n",
      "\n",
      "Start of epoch 181\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.0076e-06 - val_loss: 1.1850e-06\n",
      "\n",
      "Start of epoch 182\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 9.9277e-07 - val_loss: 1.1697e-06\n",
      "\n",
      "Start of epoch 183\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 9.7869e-07 - val_loss: 1.1551e-06\n",
      "\n",
      "Start of epoch 184\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 9.6526e-07 - val_loss: 1.1410e-06\n",
      "\n",
      "Start of epoch 185\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.5231e-07 - val_loss: 1.1273e-06\n",
      "\n",
      "Start of epoch 186\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.3970e-07 - val_loss: 1.1136e-06\n",
      "\n",
      "Start of epoch 187\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.2726e-07 - val_loss: 1.1003e-06\n",
      "\n",
      "Start of epoch 188\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 9.1513e-07 - val_loss: 1.0873e-06\n",
      "\n",
      "Start of epoch 189\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 9.0321e-07 - val_loss: 1.0741e-06\n",
      "\n",
      "Start of epoch 190\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 8.9140e-07 - val_loss: 1.0614e-06\n",
      "\n",
      "Start of epoch 191\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 8.7986e-07 - val_loss: 1.0491e-06\n",
      "\n",
      "Start of epoch 192\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 8.6866e-07 - val_loss: 1.0373e-06\n",
      "\n",
      "Start of epoch 193\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 8.5776e-07 - val_loss: 1.0258e-06\n",
      "\n",
      "Start of epoch 194\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 8.4721e-07 - val_loss: 1.0145e-06\n",
      "\n",
      "Start of epoch 195\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.3710e-07 - val_loss: 1.0039e-06\n",
      "\n",
      "Start of epoch 196\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.2736e-07 - val_loss: 9.9382e-07\n",
      "\n",
      "Start of epoch 197\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.1789e-07 - val_loss: 9.8403e-07\n",
      "\n",
      "Start of epoch 198\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.0876e-07 - val_loss: 9.7456e-07\n",
      "\n",
      "Start of epoch 199\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.9987e-07 - val_loss: 9.6526e-07\n",
      "\n",
      "Start of epoch 200\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.9130e-07 - val_loss: 9.5632e-07\n",
      "\n",
      "Start of epoch 201\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.8295e-07 - val_loss: 9.4753e-07\n",
      "\n",
      "Start of epoch 202\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.7480e-07 - val_loss: 9.3887e-07\n",
      "\n",
      "Start of epoch 203\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.6681e-07 - val_loss: 9.3024e-07\n",
      "\n",
      "Start of epoch 204\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.5907e-07 - val_loss: 9.2176e-07\n",
      "\n",
      "Start of epoch 205\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 7.5147e-07 - val_loss: 9.1344e-07\n",
      "\n",
      "Start of epoch 206\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.4396e-07 - val_loss: 9.0536e-07\n",
      "\n",
      "Start of epoch 207\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.3674e-07 - val_loss: 8.9746e-07\n",
      "\n",
      "Start of epoch 208\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.2968e-07 - val_loss: 8.8962e-07\n",
      "\n",
      "Start of epoch 209\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.2269e-07 - val_loss: 8.8187e-07\n",
      "\n",
      "Start of epoch 210\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.1578e-07 - val_loss: 8.7410e-07\n",
      "\n",
      "Start of epoch 211\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 7.0900e-07 - val_loss: 8.6641e-07\n",
      "\n",
      "Start of epoch 212\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.0235e-07 - val_loss: 8.5877e-07\n",
      "\n",
      "Start of epoch 213\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.9581e-07 - val_loss: 8.5127e-07\n",
      "\n",
      "Start of epoch 214\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.8950e-07 - val_loss: 8.4406e-07\n",
      "\n",
      "Start of epoch 215\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.8335e-07 - val_loss: 8.3719e-07\n",
      "\n",
      "Start of epoch 216\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.7739e-07 - val_loss: 8.3036e-07\n",
      "\n",
      "Start of epoch 217\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.7156e-07 - val_loss: 8.2344e-07\n",
      "\n",
      "Start of epoch 218\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.6585e-07 - val_loss: 8.1671e-07\n",
      "\n",
      "Start of epoch 219\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.6022e-07 - val_loss: 8.0993e-07\n",
      "\n",
      "Start of epoch 220\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.5472e-07 - val_loss: 8.0321e-07\n",
      "\n",
      "Start of epoch 221\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.4930e-07 - val_loss: 7.9668e-07\n",
      "\n",
      "Start of epoch 222\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.4396e-07 - val_loss: 7.9030e-07\n",
      "\n",
      "Start of epoch 223\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.3865e-07 - val_loss: 7.8412e-07\n",
      "\n",
      "Start of epoch 224\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.3346e-07 - val_loss: 7.7796e-07\n",
      "\n",
      "Start of epoch 225\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 6.2835e-07 - val_loss: 7.7181e-07\n",
      "\n",
      "Start of epoch 226\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.2337e-07 - val_loss: 7.6596e-07\n",
      "\n",
      "Start of epoch 227\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.1851e-07 - val_loss: 7.5998e-07\n",
      "\n",
      "Start of epoch 228\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.1366e-07 - val_loss: 7.5410e-07\n",
      "\n",
      "Start of epoch 229\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.0891e-07 - val_loss: 7.4819e-07\n",
      "\n",
      "Start of epoch 230\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.0418e-07 - val_loss: 7.4258e-07\n",
      "\n",
      "Start of epoch 231\n",
      "1984/1984 [==============================] - 0s 53us/step - train_loss: 5.9953e-07 - val_loss: 7.3694e-07\n",
      "\n",
      "Start of epoch 232\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 5.9494e-07 - val_loss: 7.3134e-07\n",
      "\n",
      "Start of epoch 233\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 5.9042e-07 - val_loss: 7.2581e-07\n",
      "\n",
      "Start of epoch 234\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 5.8596e-07 - val_loss: 7.2037e-07\n",
      "\n",
      "Start of epoch 235\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.8163e-07 - val_loss: 7.1519e-07\n",
      "\n",
      "Start of epoch 236\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.7734e-07 - val_loss: 7.0994e-07\n",
      "\n",
      "Start of epoch 237\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.7309e-07 - val_loss: 7.0483e-07\n",
      "\n",
      "Start of epoch 238\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 5.6888e-07 - val_loss: 6.9967e-07\n",
      "\n",
      "Start of epoch 239\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 5.6474e-07 - val_loss: 6.9464e-07\n",
      "\n",
      "Start of epoch 240\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 5.6061e-07 - val_loss: 6.8970e-07\n",
      "\n",
      "Start of epoch 241\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.5652e-07 - val_loss: 6.8446e-07\n",
      "\n",
      "Start of epoch 242\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 5.5236e-07 - val_loss: 6.7918e-07\n",
      "\n",
      "Start of epoch 243\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.4816e-07 - val_loss: 6.7398e-07\n",
      "\n",
      "Start of epoch 244\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.4406e-07 - val_loss: 6.6909e-07\n",
      "\n",
      "Start of epoch 245\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 5.4008e-07 - val_loss: 6.6434e-07\n",
      "\n",
      "Start of epoch 246\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 5.3622e-07 - val_loss: 6.5977e-07\n",
      "\n",
      "Start of epoch 247\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 5.3247e-07 - val_loss: 6.5524e-07\n",
      "\n",
      "Start of epoch 248\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.2874e-07 - val_loss: 6.5067e-07\n",
      "\n",
      "Start of epoch 249\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 5.2503e-07 - val_loss: 6.4609e-07\n",
      "\n",
      "Start of epoch 250\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.2122e-07 - val_loss: 6.4144e-07\n",
      "\n",
      "Start of epoch 251\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.1753e-07 - val_loss: 6.3711e-07\n",
      "\n",
      "Start of epoch 252\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.1396e-07 - val_loss: 6.3281e-07\n",
      "\n",
      "Start of epoch 253\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.1033e-07 - val_loss: 6.2868e-07\n",
      "\n",
      "Start of epoch 254\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.0684e-07 - val_loss: 6.2475e-07\n",
      "\n",
      "Start of epoch 255\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.0338e-07 - val_loss: 6.2082e-07\n",
      "\n",
      "Start of epoch 256\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 4.9993e-07 - val_loss: 6.1690e-07\n",
      "\n",
      "Start of epoch 257\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.9646e-07 - val_loss: 6.1312e-07\n",
      "\n",
      "Start of epoch 258\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.9307e-07 - val_loss: 6.0933e-07\n",
      "\n",
      "Start of epoch 259\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.8970e-07 - val_loss: 6.0569e-07\n",
      "\n",
      "Start of epoch 260\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.8633e-07 - val_loss: 6.0205e-07\n",
      "\n",
      "Start of epoch 261\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.8295e-07 - val_loss: 5.9851e-07\n",
      "\n",
      "Start of epoch 262\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.7959e-07 - val_loss: 5.9493e-07\n",
      "\n",
      "Start of epoch 263\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.7630e-07 - val_loss: 5.9149e-07\n",
      "\n",
      "Start of epoch 264\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.7298e-07 - val_loss: 5.8816e-07\n",
      "\n",
      "Start of epoch 265\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.6968e-07 - val_loss: 5.8474e-07\n",
      "\n",
      "Start of epoch 266\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.6645e-07 - val_loss: 5.8137e-07\n",
      "\n",
      "Start of epoch 267\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.6324e-07 - val_loss: 5.7810e-07\n",
      "\n",
      "Start of epoch 268\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.6007e-07 - val_loss: 5.7462e-07\n",
      "\n",
      "Start of epoch 269\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.5693e-07 - val_loss: 5.7120e-07\n",
      "\n",
      "Start of epoch 270\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.5386e-07 - val_loss: 5.6773e-07\n",
      "\n",
      "Start of epoch 271\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.5087e-07 - val_loss: 5.6438e-07\n",
      "\n",
      "Start of epoch 272\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.4792e-07 - val_loss: 5.6109e-07\n",
      "\n",
      "Start of epoch 273\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.4502e-07 - val_loss: 5.5778e-07\n",
      "\n",
      "Start of epoch 274\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.4216e-07 - val_loss: 5.5445e-07\n",
      "\n",
      "Start of epoch 275\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 4.3933e-07 - val_loss: 5.5130e-07\n",
      "\n",
      "Start of epoch 276\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.3655e-07 - val_loss: 5.4817e-07\n",
      "\n",
      "Start of epoch 277\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.3374e-07 - val_loss: 5.4505e-07\n",
      "\n",
      "Start of epoch 278\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.3097e-07 - val_loss: 5.4182e-07\n",
      "\n",
      "Start of epoch 279\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.2818e-07 - val_loss: 5.3852e-07\n",
      "\n",
      "Start of epoch 280\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 4.2541e-07 - val_loss: 5.3529e-07\n",
      "\n",
      "Start of epoch 281\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.2270e-07 - val_loss: 5.3217e-07\n",
      "\n",
      "Start of epoch 282\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.2001e-07 - val_loss: 5.2897e-07\n",
      "\n",
      "Start of epoch 283\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.1738e-07 - val_loss: 5.2592e-07\n",
      "\n",
      "Start of epoch 284\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.1484e-07 - val_loss: 5.2287e-07\n",
      "\n",
      "Start of epoch 285\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 4.1234e-07 - val_loss: 5.1993e-07\n",
      "\n",
      "Start of epoch 286\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.0973e-07 - val_loss: 5.1692e-07\n",
      "\n",
      "Start of epoch 287\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.0722e-07 - val_loss: 5.1403e-07\n",
      "\n",
      "Start of epoch 288\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.0473e-07 - val_loss: 5.1104e-07\n",
      "\n",
      "Start of epoch 289\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.0223e-07 - val_loss: 5.0818e-07\n",
      "\n",
      "Start of epoch 290\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.9975e-07 - val_loss: 5.0521e-07\n",
      "\n",
      "Start of epoch 291\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.9721e-07 - val_loss: 5.0203e-07\n",
      "\n",
      "Start of epoch 292\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.9465e-07 - val_loss: 4.9893e-07\n",
      "\n",
      "Start of epoch 293\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.9219e-07 - val_loss: 4.9583e-07\n",
      "\n",
      "Start of epoch 294\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.8969e-07 - val_loss: 4.9281e-07\n",
      "\n",
      "Start of epoch 295\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.8714e-07 - val_loss: 4.8983e-07\n",
      "\n",
      "Start of epoch 296\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.8473e-07 - val_loss: 4.8702e-07\n",
      "\n",
      "Start of epoch 297\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.8229e-07 - val_loss: 4.8418e-07\n",
      "\n",
      "Start of epoch 298\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.7990e-07 - val_loss: 4.8132e-07\n",
      "\n",
      "Start of epoch 299\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.7749e-07 - val_loss: 4.7842e-07\n",
      "\n",
      "Start of epoch 300\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.7506e-07 - val_loss: 4.7560e-07\n",
      "\n",
      "Start of epoch 301\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.7271e-07 - val_loss: 4.7299e-07\n",
      "\n",
      "Start of epoch 302\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.7031e-07 - val_loss: 4.7009e-07\n",
      "\n",
      "Start of epoch 303\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.6798e-07 - val_loss: 4.6716e-07\n",
      "\n",
      "Start of epoch 304\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.6564e-07 - val_loss: 4.6430e-07\n",
      "\n",
      "Start of epoch 305\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.6332e-07 - val_loss: 4.6151e-07\n",
      "\n",
      "Start of epoch 306\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.6108e-07 - val_loss: 4.5886e-07\n",
      "\n",
      "Start of epoch 307\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.5876e-07 - val_loss: 4.5602e-07\n",
      "\n",
      "Start of epoch 308\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.5651e-07 - val_loss: 4.5340e-07\n",
      "\n",
      "Start of epoch 309\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.5416e-07 - val_loss: 4.5059e-07\n",
      "\n",
      "Start of epoch 310\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.5194e-07 - val_loss: 4.4809e-07\n",
      "\n",
      "Start of epoch 311\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.4963e-07 - val_loss: 4.4540e-07\n",
      "\n",
      "Start of epoch 312\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.4745e-07 - val_loss: 4.4292e-07\n",
      "\n",
      "Start of epoch 313\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.4524e-07 - val_loss: 4.4024e-07\n",
      "\n",
      "Start of epoch 314\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.4293e-07 - val_loss: 4.3758e-07\n",
      "\n",
      "Start of epoch 315\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.4067e-07 - val_loss: 4.3489e-07\n",
      "\n",
      "Start of epoch 316\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.3812e-07 - val_loss: 4.3201e-07\n",
      "\n",
      "Start of epoch 317\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.3584e-07 - val_loss: 4.2940e-07\n",
      "\n",
      "Start of epoch 318\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.3357e-07 - val_loss: 4.2703e-07\n",
      "\n",
      "Start of epoch 319\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 3.3130e-07 - val_loss: 4.2445e-07\n",
      "\n",
      "Start of epoch 320\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.2908e-07 - val_loss: 4.2194e-07\n",
      "\n",
      "Start of epoch 321\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.2689e-07 - val_loss: 4.1952e-07\n",
      "\n",
      "Start of epoch 322\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.2474e-07 - val_loss: 4.1707e-07\n",
      "\n",
      "Start of epoch 323\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.2256e-07 - val_loss: 4.1459e-07\n",
      "\n",
      "Start of epoch 324\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.2044e-07 - val_loss: 4.1205e-07\n",
      "\n",
      "Start of epoch 325\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.1835e-07 - val_loss: 4.0976e-07\n",
      "\n",
      "Start of epoch 326\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.1625e-07 - val_loss: 4.0731e-07\n",
      "\n",
      "Start of epoch 327\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.1409e-07 - val_loss: 4.0498e-07\n",
      "\n",
      "Start of epoch 328\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.1207e-07 - val_loss: 4.0264e-07\n",
      "\n",
      "Start of epoch 329\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.1005e-07 - val_loss: 4.0034e-07\n",
      "\n",
      "Start of epoch 330\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.0801e-07 - val_loss: 3.9793e-07\n",
      "\n",
      "Start of epoch 331\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 3.0604e-07 - val_loss: 3.9556e-07\n",
      "\n",
      "Start of epoch 332\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 3.0410e-07 - val_loss: 3.9330e-07\n",
      "\n",
      "Start of epoch 333\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 3.0211e-07 - val_loss: 3.9075e-07\n",
      "\n",
      "Start of epoch 334\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.0018e-07 - val_loss: 3.8842e-07\n",
      "\n",
      "Start of epoch 335\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 2.9827e-07 - val_loss: 3.8606e-07\n",
      "\n",
      "Start of epoch 336\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 2.9632e-07 - val_loss: 3.8368e-07\n",
      "\n",
      "Start of epoch 337\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 2.9438e-07 - val_loss: 3.8163e-07\n",
      "\n",
      "Start of epoch 338\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 2.9242e-07 - val_loss: 3.7928e-07\n",
      "\n",
      "Start of epoch 339\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.9050e-07 - val_loss: 3.7693e-07\n",
      "\n",
      "Start of epoch 340\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.8857e-07 - val_loss: 3.7474e-07\n",
      "\n",
      "Start of epoch 341\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.8678e-07 - val_loss: 3.7262e-07\n",
      "\n",
      "Start of epoch 342\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.8492e-07 - val_loss: 3.7054e-07\n",
      "\n",
      "Start of epoch 343\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.8300e-07 - val_loss: 3.6829e-07\n",
      "\n",
      "Start of epoch 344\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.8111e-07 - val_loss: 3.6605e-07\n",
      "\n",
      "Start of epoch 345\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.7921e-07 - val_loss: 3.6372e-07\n",
      "\n",
      "Start of epoch 346\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 2.7720e-07 - val_loss: 3.6133e-07\n",
      "\n",
      "Start of epoch 347\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.7533e-07 - val_loss: 3.5926e-07\n",
      "\n",
      "Start of epoch 348\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.7339e-07 - val_loss: 3.5698e-07\n",
      "\n",
      "Start of epoch 349\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.7162e-07 - val_loss: 3.5489e-07\n",
      "\n",
      "Start of epoch 350\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.6980e-07 - val_loss: 3.5278e-07\n",
      "\n",
      "Start of epoch 351\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 2.6801e-07 - val_loss: 3.5072e-07\n",
      "\n",
      "Start of epoch 352\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.6627e-07 - val_loss: 3.4874e-07\n",
      "\n",
      "Start of epoch 353\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.6439e-07 - val_loss: 3.4653e-07\n",
      "\n",
      "Start of epoch 354\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.6252e-07 - val_loss: 3.4447e-07\n",
      "\n",
      "Start of epoch 355\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.6077e-07 - val_loss: 3.4236e-07\n",
      "\n",
      "Start of epoch 356\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.5876e-07 - val_loss: 3.4015e-07\n",
      "\n",
      "Start of epoch 357\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.5688e-07 - val_loss: 3.3786e-07\n",
      "\n",
      "Start of epoch 358\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.5487e-07 - val_loss: 3.3569e-07\n",
      "\n",
      "Start of epoch 359\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5293e-07 - val_loss: 3.3345e-07\n",
      "\n",
      "Start of epoch 360\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.5108e-07 - val_loss: 3.3134e-07\n",
      "\n",
      "Start of epoch 361\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.4925e-07 - val_loss: 3.2909e-07\n",
      "\n",
      "Start of epoch 362\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.4741e-07 - val_loss: 3.2675e-07\n",
      "\n",
      "Start of epoch 363\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 2.4572e-07 - val_loss: 3.2486e-07\n",
      "\n",
      "Start of epoch 364\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.4394e-07 - val_loss: 3.2291e-07\n",
      "\n",
      "Start of epoch 365\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.4208e-07 - val_loss: 3.2098e-07\n",
      "\n",
      "Start of epoch 366\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.4028e-07 - val_loss: 3.1911e-07\n",
      "\n",
      "Start of epoch 367\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3840e-07 - val_loss: 3.1724e-07\n",
      "\n",
      "Start of epoch 368\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.3670e-07 - val_loss: 3.1544e-07\n",
      "\n",
      "Start of epoch 369\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.3518e-07 - val_loss: 3.1349e-07\n",
      "\n",
      "Start of epoch 370\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3374e-07 - val_loss: 3.1168e-07\n",
      "\n",
      "Start of epoch 371\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3229e-07 - val_loss: 3.0997e-07\n",
      "\n",
      "Start of epoch 372\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.3083e-07 - val_loss: 3.0809e-07\n",
      "\n",
      "Start of epoch 373\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 2.2946e-07 - val_loss: 3.0631e-07\n",
      "\n",
      "Start of epoch 374\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.2794e-07 - val_loss: 3.0441e-07\n",
      "\n",
      "Start of epoch 375\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 2.2648e-07 - val_loss: 3.0253e-07\n",
      "\n",
      "Start of epoch 376\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.2502e-07 - val_loss: 3.0071e-07\n",
      "\n",
      "Start of epoch 377\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.2364e-07 - val_loss: 2.9898e-07\n",
      "\n",
      "Start of epoch 378\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.2231e-07 - val_loss: 2.9722e-07\n",
      "\n",
      "Start of epoch 379\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.2100e-07 - val_loss: 2.9557e-07\n",
      "\n",
      "Start of epoch 380\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.1966e-07 - val_loss: 2.9389e-07\n",
      "\n",
      "Start of epoch 381\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1838e-07 - val_loss: 2.9207e-07\n",
      "\n",
      "Start of epoch 382\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1716e-07 - val_loss: 2.9053e-07\n",
      "\n",
      "Start of epoch 383\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.1591e-07 - val_loss: 2.8882e-07\n",
      "\n",
      "Start of epoch 384\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1479e-07 - val_loss: 2.8729e-07\n",
      "\n",
      "Start of epoch 385\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.1357e-07 - val_loss: 2.8566e-07\n",
      "\n",
      "Start of epoch 386\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1245e-07 - val_loss: 2.8407e-07\n",
      "\n",
      "Start of epoch 387\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1131e-07 - val_loss: 2.8233e-07\n",
      "\n",
      "Start of epoch 388\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.1019e-07 - val_loss: 2.8072e-07\n",
      "\n",
      "Start of epoch 389\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.0901e-07 - val_loss: 2.7904e-07\n",
      "\n",
      "Start of epoch 390\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.0783e-07 - val_loss: 2.7753e-07\n",
      "\n",
      "Start of epoch 391\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.0669e-07 - val_loss: 2.7601e-07\n",
      "\n",
      "Start of epoch 392\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.0546e-07 - val_loss: 2.7439e-07\n",
      "\n",
      "Start of epoch 393\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.0420e-07 - val_loss: 2.7296e-07\n",
      "\n",
      "Start of epoch 394\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.0301e-07 - val_loss: 2.7143e-07\n",
      "\n",
      "Start of epoch 395\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.0195e-07 - val_loss: 2.6984e-07\n",
      "\n",
      "Start of epoch 396\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 2.0084e-07 - val_loss: 2.6837e-07\n",
      "\n",
      "Start of epoch 397\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.9966e-07 - val_loss: 2.6681e-07\n",
      "\n",
      "Start of epoch 398\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.9858e-07 - val_loss: 2.6531e-07\n",
      "\n",
      "Start of epoch 399\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.9742e-07 - val_loss: 2.6366e-07\n",
      "\n",
      "Start of epoch 400\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.9633e-07 - val_loss: 2.6198e-07\n",
      "\n",
      "Start of epoch 401\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.9527e-07 - val_loss: 2.6031e-07\n",
      "\n",
      "Start of epoch 402\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.9420e-07 - val_loss: 2.5861e-07\n",
      "\n",
      "Start of epoch 403\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.9312e-07 - val_loss: 2.5703e-07\n",
      "\n",
      "Start of epoch 404\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.9198e-07 - val_loss: 2.5557e-07\n",
      "\n",
      "Start of epoch 405\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.9089e-07 - val_loss: 2.5401e-07\n",
      "\n",
      "Start of epoch 406\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8975e-07 - val_loss: 2.5256e-07\n",
      "\n",
      "Start of epoch 407\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8865e-07 - val_loss: 2.5101e-07\n",
      "\n",
      "Start of epoch 408\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8757e-07 - val_loss: 2.4940e-07\n",
      "\n",
      "Start of epoch 409\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8650e-07 - val_loss: 2.4780e-07\n",
      "\n",
      "Start of epoch 410\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8544e-07 - val_loss: 2.4619e-07\n",
      "\n",
      "Start of epoch 411\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8434e-07 - val_loss: 2.4467e-07\n",
      "\n",
      "Start of epoch 412\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8309e-07 - val_loss: 2.4305e-07\n",
      "\n",
      "Start of epoch 413\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8195e-07 - val_loss: 2.4169e-07\n",
      "\n",
      "Start of epoch 414\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8072e-07 - val_loss: 2.4016e-07\n",
      "\n",
      "Start of epoch 415\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7953e-07 - val_loss: 2.3878e-07\n",
      "\n",
      "Start of epoch 416\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.7845e-07 - val_loss: 2.3732e-07\n",
      "\n",
      "Start of epoch 417\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7736e-07 - val_loss: 2.3594e-07\n",
      "\n",
      "Start of epoch 418\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.7629e-07 - val_loss: 2.3461e-07\n",
      "\n",
      "Start of epoch 419\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.7517e-07 - val_loss: 2.3317e-07\n",
      "\n",
      "Start of epoch 420\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.7411e-07 - val_loss: 2.3184e-07\n",
      "\n",
      "Start of epoch 421\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.7307e-07 - val_loss: 2.3042e-07\n",
      "\n",
      "Start of epoch 422\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.7205e-07 - val_loss: 2.2904e-07\n",
      "\n",
      "Start of epoch 423\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.7107e-07 - val_loss: 2.2769e-07\n",
      "\n",
      "Start of epoch 424\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7010e-07 - val_loss: 2.2635e-07\n",
      "\n",
      "Start of epoch 425\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.6914e-07 - val_loss: 2.2504e-07\n",
      "\n",
      "Start of epoch 426\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.6820e-07 - val_loss: 2.2377e-07\n",
      "\n",
      "Start of epoch 427\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6725e-07 - val_loss: 2.2247e-07\n",
      "\n",
      "Start of epoch 428\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6634e-07 - val_loss: 2.2117e-07\n",
      "\n",
      "Start of epoch 429\n",
      "1984/1984 [==============================] - 0s 48us/step - train_loss: 1.6545e-07 - val_loss: 2.1988e-07\n",
      "\n",
      "Start of epoch 430\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.6457e-07 - val_loss: 2.1856e-07\n",
      "\n",
      "Start of epoch 431\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6372e-07 - val_loss: 2.1728e-07\n",
      "\n",
      "Start of epoch 432\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.6286e-07 - val_loss: 2.1602e-07\n",
      "\n",
      "Start of epoch 433\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.6205e-07 - val_loss: 2.1470e-07\n",
      "\n",
      "Start of epoch 434\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.6124e-07 - val_loss: 2.1339e-07\n",
      "\n",
      "Start of epoch 435\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.6038e-07 - val_loss: 2.1212e-07\n",
      "\n",
      "Start of epoch 436\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.5947e-07 - val_loss: 2.1090e-07\n",
      "\n",
      "Start of epoch 437\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5854e-07 - val_loss: 2.0960e-07\n",
      "\n",
      "Start of epoch 438\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5765e-07 - val_loss: 2.0834e-07\n",
      "\n",
      "Start of epoch 439\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.5676e-07 - val_loss: 2.0716e-07\n",
      "\n",
      "Start of epoch 440\n",
      "1984/1984 [==============================] - 0s 47us/step - train_loss: 1.5593e-07 - val_loss: 2.0602e-07\n",
      "\n",
      "Start of epoch 441\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.5510e-07 - val_loss: 2.0489e-07\n",
      "\n",
      "Start of epoch 442\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.5436e-07 - val_loss: 2.0382e-07\n",
      "\n",
      "Start of epoch 443\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5362e-07 - val_loss: 2.0269e-07\n",
      "\n",
      "Start of epoch 444\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5282e-07 - val_loss: 2.0162e-07\n",
      "\n",
      "Start of epoch 445\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5207e-07 - val_loss: 2.0057e-07\n",
      "\n",
      "Start of epoch 446\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5131e-07 - val_loss: 1.9948e-07\n",
      "\n",
      "Start of epoch 447\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5058e-07 - val_loss: 1.9850e-07\n",
      "\n",
      "Start of epoch 448\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.4982e-07 - val_loss: 1.9747e-07\n",
      "\n",
      "Start of epoch 449\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4908e-07 - val_loss: 1.9646e-07\n",
      "\n",
      "Start of epoch 450\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.4835e-07 - val_loss: 1.9542e-07\n",
      "\n",
      "Start of epoch 451\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.4764e-07 - val_loss: 1.9444e-07\n",
      "\n",
      "Start of epoch 452\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.4693e-07 - val_loss: 1.9346e-07\n",
      "\n",
      "Start of epoch 453\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.4620e-07 - val_loss: 1.9247e-07\n",
      "\n",
      "Start of epoch 454\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.4548e-07 - val_loss: 1.9148e-07\n",
      "\n",
      "Start of epoch 455\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.4478e-07 - val_loss: 1.9050e-07\n",
      "\n",
      "Start of epoch 456\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4408e-07 - val_loss: 1.8960e-07\n",
      "\n",
      "Start of epoch 457\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.4342e-07 - val_loss: 1.8874e-07\n",
      "\n",
      "Start of epoch 458\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4276e-07 - val_loss: 1.8783e-07\n",
      "\n",
      "Start of epoch 459\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4213e-07 - val_loss: 1.8693e-07\n",
      "\n",
      "Start of epoch 460\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4155e-07 - val_loss: 1.8600e-07\n",
      "\n",
      "Start of epoch 461\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4093e-07 - val_loss: 1.8509e-07\n",
      "\n",
      "Start of epoch 462\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.4029e-07 - val_loss: 1.8421e-07\n",
      "\n",
      "Start of epoch 463\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.3965e-07 - val_loss: 1.8335e-07\n",
      "\n",
      "Start of epoch 464\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.3900e-07 - val_loss: 1.8248e-07\n",
      "\n",
      "Start of epoch 465\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.3836e-07 - val_loss: 1.8166e-07\n",
      "\n",
      "Start of epoch 466\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.3774e-07 - val_loss: 1.8079e-07\n",
      "\n",
      "Start of epoch 467\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3709e-07 - val_loss: 1.7999e-07\n",
      "\n",
      "Start of epoch 468\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3641e-07 - val_loss: 1.7920e-07\n",
      "\n",
      "Start of epoch 469\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.3578e-07 - val_loss: 1.7842e-07\n",
      "\n",
      "Start of epoch 470\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.3515e-07 - val_loss: 1.7762e-07\n",
      "\n",
      "Start of epoch 471\n",
      "1984/1984 [==============================] - 0s 56us/step - train_loss: 1.3452e-07 - val_loss: 1.7684e-07\n",
      "\n",
      "Start of epoch 472\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.3394e-07 - val_loss: 1.7604e-07\n",
      "\n",
      "Start of epoch 473\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.3336e-07 - val_loss: 1.7523e-07\n",
      "\n",
      "Start of epoch 474\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.3279e-07 - val_loss: 1.7448e-07\n",
      "\n",
      "Start of epoch 475\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.3223e-07 - val_loss: 1.7364e-07\n",
      "\n",
      "Start of epoch 476\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3166e-07 - val_loss: 1.7281e-07\n",
      "\n",
      "Start of epoch 477\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.3112e-07 - val_loss: 1.7202e-07\n",
      "\n",
      "Start of epoch 478\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3062e-07 - val_loss: 1.7123e-07\n",
      "\n",
      "Start of epoch 479\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3009e-07 - val_loss: 1.7031e-07\n",
      "\n",
      "Start of epoch 480\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.2953e-07 - val_loss: 1.6948e-07\n",
      "\n",
      "Start of epoch 481\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.2899e-07 - val_loss: 1.6874e-07\n",
      "\n",
      "Start of epoch 482\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2844e-07 - val_loss: 1.6793e-07\n",
      "\n",
      "Start of epoch 483\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2791e-07 - val_loss: 1.6717e-07\n",
      "\n",
      "Start of epoch 484\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2736e-07 - val_loss: 1.6649e-07\n",
      "\n",
      "Start of epoch 485\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2684e-07 - val_loss: 1.6577e-07\n",
      "\n",
      "Start of epoch 486\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2632e-07 - val_loss: 1.6506e-07\n",
      "\n",
      "Start of epoch 487\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2577e-07 - val_loss: 1.6440e-07\n",
      "\n",
      "Start of epoch 488\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2525e-07 - val_loss: 1.6372e-07\n",
      "\n",
      "Start of epoch 489\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.2475e-07 - val_loss: 1.6301e-07\n",
      "\n",
      "Start of epoch 490\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2422e-07 - val_loss: 1.6238e-07\n",
      "\n",
      "Start of epoch 491\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2373e-07 - val_loss: 1.6171e-07\n",
      "\n",
      "Start of epoch 492\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.2324e-07 - val_loss: 1.6098e-07\n",
      "\n",
      "Start of epoch 493\n",
      "1984/1984 [==============================] - 0s 56us/step - train_loss: 1.2273e-07 - val_loss: 1.6032e-07\n",
      "\n",
      "Start of epoch 494\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.2224e-07 - val_loss: 1.5965e-07\n",
      "\n",
      "Start of epoch 495\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.2178e-07 - val_loss: 1.5900e-07\n",
      "\n",
      "Start of epoch 496\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.2132e-07 - val_loss: 1.5839e-07\n",
      "\n",
      "Start of epoch 497\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.2088e-07 - val_loss: 1.5778e-07\n",
      "\n",
      "Start of epoch 498\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.2041e-07 - val_loss: 1.5716e-07\n",
      "\n",
      "Start of epoch 499\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1996e-07 - val_loss: 1.5652e-07\n",
      "\n",
      "Start of epoch 500\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1951e-07 - val_loss: 1.5591e-07\n",
      "\n",
      "Start of epoch 501\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1907e-07 - val_loss: 1.5529e-07\n",
      "\n",
      "Start of epoch 502\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1862e-07 - val_loss: 1.5467e-07\n",
      "\n",
      "Start of epoch 503\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1816e-07 - val_loss: 1.5402e-07\n",
      "\n",
      "Start of epoch 504\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1772e-07 - val_loss: 1.5338e-07\n",
      "\n",
      "Start of epoch 505\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1726e-07 - val_loss: 1.5270e-07\n",
      "\n",
      "Start of epoch 506\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1681e-07 - val_loss: 1.5205e-07\n",
      "\n",
      "Start of epoch 507\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 1.1637e-07 - val_loss: 1.5141e-07\n",
      "\n",
      "Start of epoch 508\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1594e-07 - val_loss: 1.5079e-07\n",
      "\n",
      "Start of epoch 509\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1551e-07 - val_loss: 1.5010e-07\n",
      "\n",
      "Start of epoch 510\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1506e-07 - val_loss: 1.4942e-07\n",
      "\n",
      "Start of epoch 511\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1459e-07 - val_loss: 1.4873e-07\n",
      "\n",
      "Start of epoch 512\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1411e-07 - val_loss: 1.4806e-07\n",
      "\n",
      "Start of epoch 513\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1364e-07 - val_loss: 1.4737e-07\n",
      "\n",
      "Start of epoch 514\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.1315e-07 - val_loss: 1.4669e-07\n",
      "\n",
      "Start of epoch 515\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.1268e-07 - val_loss: 1.4602e-07\n",
      "\n",
      "Start of epoch 516\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1219e-07 - val_loss: 1.4535e-07\n",
      "\n",
      "Start of epoch 517\n",
      "1984/1984 [==============================] - 0s 49us/step - train_loss: 1.1172e-07 - val_loss: 1.4472e-07\n",
      "\n",
      "Start of epoch 518\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.1124e-07 - val_loss: 1.4402e-07\n",
      "\n",
      "Start of epoch 519\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.1079e-07 - val_loss: 1.4338e-07\n",
      "\n",
      "Start of epoch 520\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.1033e-07 - val_loss: 1.4274e-07\n",
      "\n",
      "Start of epoch 521\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.0988e-07 - val_loss: 1.4212e-07\n",
      "\n",
      "Start of epoch 522\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.0944e-07 - val_loss: 1.4145e-07\n",
      "\n",
      "Start of epoch 523\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0899e-07 - val_loss: 1.4089e-07\n",
      "\n",
      "Start of epoch 524\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0854e-07 - val_loss: 1.4021e-07\n",
      "\n",
      "Start of epoch 525\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0813e-07 - val_loss: 1.3962e-07\n",
      "\n",
      "Start of epoch 526\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0774e-07 - val_loss: 1.3896e-07\n",
      "\n",
      "Start of epoch 527\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.0736e-07 - val_loss: 1.3841e-07\n",
      "\n",
      "Start of epoch 528\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.0694e-07 - val_loss: 1.3777e-07\n",
      "\n",
      "Start of epoch 529\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.0656e-07 - val_loss: 1.3718e-07\n",
      "\n",
      "Start of epoch 530\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.0615e-07 - val_loss: 1.3669e-07\n",
      "\n",
      "Start of epoch 531\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.0578e-07 - val_loss: 1.3608e-07\n",
      "\n",
      "Start of epoch 532\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.0543e-07 - val_loss: 1.3548e-07\n",
      "\n",
      "Start of epoch 533\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.0500e-07 - val_loss: 1.3486e-07\n",
      "\n",
      "Start of epoch 534\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0454e-07 - val_loss: 1.3428e-07\n",
      "\n",
      "Start of epoch 535\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0411e-07 - val_loss: 1.3379e-07\n",
      "\n",
      "Start of epoch 536\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0367e-07 - val_loss: 1.3324e-07\n",
      "\n",
      "Start of epoch 537\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0323e-07 - val_loss: 1.3271e-07\n",
      "\n",
      "Start of epoch 538\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0282e-07 - val_loss: 1.3213e-07\n",
      "\n",
      "Start of epoch 539\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.0240e-07 - val_loss: 1.3155e-07\n",
      "\n",
      "Start of epoch 540\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0198e-07 - val_loss: 1.3097e-07\n",
      "\n",
      "Start of epoch 541\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0157e-07 - val_loss: 1.3039e-07\n",
      "\n",
      "Start of epoch 542\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0116e-07 - val_loss: 1.2983e-07\n",
      "\n",
      "Start of epoch 543\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0079e-07 - val_loss: 1.2927e-07\n",
      "\n",
      "Start of epoch 544\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0041e-07 - val_loss: 1.2872e-07\n",
      "\n",
      "Start of epoch 545\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0002e-07 - val_loss: 1.2816e-07\n",
      "\n",
      "Start of epoch 546\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.9629e-08 - val_loss: 1.2763e-07\n",
      "\n",
      "Start of epoch 547\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.9260e-08 - val_loss: 1.2709e-07\n",
      "\n",
      "Start of epoch 548\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.8874e-08 - val_loss: 1.2652e-07\n",
      "\n",
      "Start of epoch 549\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.8518e-08 - val_loss: 1.2595e-07\n",
      "\n",
      "Start of epoch 550\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.8087e-08 - val_loss: 1.2540e-07\n",
      "\n",
      "Start of epoch 551\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.7685e-08 - val_loss: 1.2484e-07\n",
      "\n",
      "Start of epoch 552\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.7335e-08 - val_loss: 1.2432e-07\n",
      "\n",
      "Start of epoch 553\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.6991e-08 - val_loss: 1.2380e-07\n",
      "\n",
      "Start of epoch 554\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.6582e-08 - val_loss: 1.2327e-07\n",
      "\n",
      "Start of epoch 555\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 9.6220e-08 - val_loss: 1.2278e-07\n",
      "\n",
      "Start of epoch 556\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.5850e-08 - val_loss: 1.2225e-07\n",
      "\n",
      "Start of epoch 557\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 9.5439e-08 - val_loss: 1.2168e-07\n",
      "\n",
      "Start of epoch 558\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 9.5019e-08 - val_loss: 1.2120e-07\n",
      "\n",
      "Start of epoch 559\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 9.4625e-08 - val_loss: 1.2074e-07\n",
      "\n",
      "Start of epoch 560\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.4264e-08 - val_loss: 1.2029e-07\n",
      "\n",
      "Start of epoch 561\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 9.3878e-08 - val_loss: 1.1981e-07\n",
      "\n",
      "Start of epoch 562\n",
      "1984/1984 [==============================] - 0s 46us/step - train_loss: 9.3474e-08 - val_loss: 1.1928e-07\n",
      "\n",
      "Start of epoch 563\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.3069e-08 - val_loss: 1.1876e-07\n",
      "\n",
      "Start of epoch 564\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.2687e-08 - val_loss: 1.1830e-07\n",
      "\n",
      "Start of epoch 565\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.2309e-08 - val_loss: 1.1782e-07\n",
      "\n",
      "Start of epoch 566\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 9.1941e-08 - val_loss: 1.1734e-07\n",
      "\n",
      "Start of epoch 567\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 9.1572e-08 - val_loss: 1.1684e-07\n",
      "\n",
      "Start of epoch 568\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.1231e-08 - val_loss: 1.1636e-07\n",
      "\n",
      "Start of epoch 569\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 9.0866e-08 - val_loss: 1.1587e-07\n",
      "\n",
      "Start of epoch 570\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.0530e-08 - val_loss: 1.1539e-07\n",
      "\n",
      "Start of epoch 571\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.0203e-08 - val_loss: 1.1496e-07\n",
      "\n",
      "Start of epoch 572\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.9845e-08 - val_loss: 1.1449e-07\n",
      "\n",
      "Start of epoch 573\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.9510e-08 - val_loss: 1.1405e-07\n",
      "\n",
      "Start of epoch 574\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.9148e-08 - val_loss: 1.1357e-07\n",
      "\n",
      "Start of epoch 575\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 8.8811e-08 - val_loss: 1.1308e-07\n",
      "\n",
      "Start of epoch 576\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 8.8480e-08 - val_loss: 1.1271e-07\n",
      "\n",
      "Start of epoch 577\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 8.8130e-08 - val_loss: 1.1224e-07\n",
      "\n",
      "Start of epoch 578\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 8.7806e-08 - val_loss: 1.1181e-07\n",
      "\n",
      "Start of epoch 579\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 8.7470e-08 - val_loss: 1.1137e-07\n",
      "\n",
      "Start of epoch 580\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 8.7142e-08 - val_loss: 1.1092e-07\n",
      "\n",
      "Start of epoch 581\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 8.6797e-08 - val_loss: 1.1047e-07\n",
      "\n",
      "Start of epoch 582\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 8.6471e-08 - val_loss: 1.0999e-07\n",
      "\n",
      "Start of epoch 583\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.6143e-08 - val_loss: 1.0952e-07\n",
      "\n",
      "Start of epoch 584\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.5815e-08 - val_loss: 1.0908e-07\n",
      "\n",
      "Start of epoch 585\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.5483e-08 - val_loss: 1.0862e-07\n",
      "\n",
      "Start of epoch 586\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.5141e-08 - val_loss: 1.0818e-07\n",
      "\n",
      "Start of epoch 587\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.4836e-08 - val_loss: 1.0778e-07\n",
      "\n",
      "Start of epoch 588\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.4532e-08 - val_loss: 1.0738e-07\n",
      "\n",
      "Start of epoch 589\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.4205e-08 - val_loss: 1.0691e-07\n",
      "\n",
      "Start of epoch 590\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.3898e-08 - val_loss: 1.0649e-07\n",
      "\n",
      "Start of epoch 591\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.3591e-08 - val_loss: 1.0608e-07\n",
      "\n",
      "Start of epoch 592\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 8.3269e-08 - val_loss: 1.0565e-07\n",
      "\n",
      "Start of epoch 593\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.2959e-08 - val_loss: 1.0523e-07\n",
      "\n",
      "Start of epoch 594\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.2664e-08 - val_loss: 1.0480e-07\n",
      "\n",
      "Start of epoch 595\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 8.2363e-08 - val_loss: 1.0442e-07\n",
      "\n",
      "Start of epoch 596\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 8.2079e-08 - val_loss: 1.0404e-07\n",
      "\n",
      "Start of epoch 597\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 8.1800e-08 - val_loss: 1.0365e-07\n",
      "\n",
      "Start of epoch 598\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.1505e-08 - val_loss: 1.0326e-07\n",
      "\n",
      "Start of epoch 599\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 8.1208e-08 - val_loss: 1.0290e-07\n",
      "\n",
      "Start of epoch 600\n",
      "1984/1984 [==============================] - 0s 46us/step - train_loss: 8.0922e-08 - val_loss: 1.0251e-07\n",
      "\n",
      "Start of epoch 601\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.0645e-08 - val_loss: 1.0217e-07\n",
      "\n",
      "Start of epoch 602\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 8.0358e-08 - val_loss: 1.0179e-07\n",
      "\n",
      "Start of epoch 603\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 8.0089e-08 - val_loss: 1.0143e-07\n",
      "\n",
      "Start of epoch 604\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.9804e-08 - val_loss: 1.0104e-07\n",
      "\n",
      "Start of epoch 605\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.9566e-08 - val_loss: 1.0067e-07\n",
      "\n",
      "Start of epoch 606\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.9297e-08 - val_loss: 1.0032e-07\n",
      "\n",
      "Start of epoch 607\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.9042e-08 - val_loss: 9.9943e-08\n",
      "\n",
      "Start of epoch 608\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.8787e-08 - val_loss: 9.9541e-08\n",
      "\n",
      "Start of epoch 609\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.8514e-08 - val_loss: 9.9145e-08\n",
      "\n",
      "Start of epoch 610\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.8273e-08 - val_loss: 9.8783e-08\n",
      "\n",
      "Start of epoch 611\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.8054e-08 - val_loss: 9.8425e-08\n",
      "\n",
      "Start of epoch 612\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.7793e-08 - val_loss: 9.8092e-08\n",
      "\n",
      "Start of epoch 613\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.7557e-08 - val_loss: 9.7728e-08\n",
      "\n",
      "Start of epoch 614\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 7.7301e-08 - val_loss: 9.7399e-08\n",
      "\n",
      "Start of epoch 615\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.7038e-08 - val_loss: 9.7014e-08\n",
      "\n",
      "Start of epoch 616\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.6818e-08 - val_loss: 9.6689e-08\n",
      "\n",
      "Start of epoch 617\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.6560e-08 - val_loss: 9.6341e-08\n",
      "\n",
      "Start of epoch 618\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 7.6343e-08 - val_loss: 9.5997e-08\n",
      "\n",
      "Start of epoch 619\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.6075e-08 - val_loss: 9.5638e-08\n",
      "\n",
      "Start of epoch 620\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.5858e-08 - val_loss: 9.5331e-08\n",
      "\n",
      "Start of epoch 621\n",
      "1984/1984 [==============================] - 0s 50us/step - train_loss: 7.5620e-08 - val_loss: 9.4987e-08\n",
      "\n",
      "Start of epoch 622\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 7.5401e-08 - val_loss: 9.4656e-08\n",
      "\n",
      "Start of epoch 623\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 7.5133e-08 - val_loss: 9.4310e-08\n",
      "\n",
      "Start of epoch 624\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.4915e-08 - val_loss: 9.4046e-08\n",
      "\n",
      "Start of epoch 625\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.4677e-08 - val_loss: 9.3770e-08\n",
      "\n",
      "Start of epoch 626\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.4468e-08 - val_loss: 9.3461e-08\n",
      "\n",
      "Start of epoch 627\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.4238e-08 - val_loss: 9.3185e-08\n",
      "\n",
      "Start of epoch 628\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.3993e-08 - val_loss: 9.2883e-08\n",
      "\n",
      "Start of epoch 629\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 7.3792e-08 - val_loss: 9.2584e-08\n",
      "\n",
      "Start of epoch 630\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.3565e-08 - val_loss: 9.2284e-08\n",
      "\n",
      "Start of epoch 631\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.3361e-08 - val_loss: 9.2053e-08\n",
      "\n",
      "Start of epoch 632\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.3136e-08 - val_loss: 9.1740e-08\n",
      "\n",
      "Start of epoch 633\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.2917e-08 - val_loss: 9.1469e-08\n",
      "\n",
      "Start of epoch 634\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.2677e-08 - val_loss: 9.1145e-08\n",
      "\n",
      "Start of epoch 635\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 7.2437e-08 - val_loss: 9.0850e-08\n",
      "\n",
      "Start of epoch 636\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 7.2216e-08 - val_loss: 9.0557e-08\n",
      "\n",
      "Start of epoch 637\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.1977e-08 - val_loss: 9.0248e-08\n",
      "\n",
      "Start of epoch 638\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.1749e-08 - val_loss: 8.9973e-08\n",
      "\n",
      "Start of epoch 639\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 7.1539e-08 - val_loss: 8.9668e-08\n",
      "\n",
      "Start of epoch 640\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 7.1308e-08 - val_loss: 8.9368e-08\n",
      "\n",
      "Start of epoch 641\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 7.1094e-08 - val_loss: 8.9071e-08\n",
      "\n",
      "Start of epoch 642\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 7.0849e-08 - val_loss: 8.8845e-08\n",
      "\n",
      "Start of epoch 643\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 7.0622e-08 - val_loss: 8.8597e-08\n",
      "\n",
      "Start of epoch 644\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 7.0391e-08 - val_loss: 8.8344e-08\n",
      "\n",
      "Start of epoch 645\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 7.0190e-08 - val_loss: 8.8098e-08\n",
      "\n",
      "Start of epoch 646\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.9940e-08 - val_loss: 8.7859e-08\n",
      "\n",
      "Start of epoch 647\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.9736e-08 - val_loss: 8.7712e-08\n",
      "\n",
      "Start of epoch 648\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.9512e-08 - val_loss: 8.7448e-08\n",
      "\n",
      "Start of epoch 649\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.9293e-08 - val_loss: 8.7207e-08\n",
      "\n",
      "Start of epoch 650\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.9044e-08 - val_loss: 8.6890e-08\n",
      "\n",
      "Start of epoch 651\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.8818e-08 - val_loss: 8.6638e-08\n",
      "\n",
      "Start of epoch 652\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.8610e-08 - val_loss: 8.6367e-08\n",
      "\n",
      "Start of epoch 653\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.8407e-08 - val_loss: 8.6077e-08\n",
      "\n",
      "Start of epoch 654\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.8196e-08 - val_loss: 8.5800e-08\n",
      "\n",
      "Start of epoch 655\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.8008e-08 - val_loss: 8.5541e-08\n",
      "\n",
      "Start of epoch 656\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 6.7801e-08 - val_loss: 8.5228e-08\n",
      "\n",
      "Start of epoch 657\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.7616e-08 - val_loss: 8.4973e-08\n",
      "\n",
      "Start of epoch 658\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.7430e-08 - val_loss: 8.4711e-08\n",
      "\n",
      "Start of epoch 659\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 6.7236e-08 - val_loss: 8.4442e-08\n",
      "\n",
      "Start of epoch 660\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.7028e-08 - val_loss: 8.4131e-08\n",
      "\n",
      "Start of epoch 661\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.6849e-08 - val_loss: 8.3887e-08\n",
      "\n",
      "Start of epoch 662\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.6667e-08 - val_loss: 8.3619e-08\n",
      "\n",
      "Start of epoch 663\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.6480e-08 - val_loss: 8.3343e-08\n",
      "\n",
      "Start of epoch 664\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.6282e-08 - val_loss: 8.3077e-08\n",
      "\n",
      "Start of epoch 665\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.6108e-08 - val_loss: 8.2831e-08\n",
      "\n",
      "Start of epoch 666\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.5930e-08 - val_loss: 8.2551e-08\n",
      "\n",
      "Start of epoch 667\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.5745e-08 - val_loss: 8.2304e-08\n",
      "\n",
      "Start of epoch 668\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.5565e-08 - val_loss: 8.2014e-08\n",
      "\n",
      "Start of epoch 669\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.5380e-08 - val_loss: 8.1760e-08\n",
      "\n",
      "Start of epoch 670\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 6.5210e-08 - val_loss: 8.1497e-08\n",
      "\n",
      "Start of epoch 671\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.5029e-08 - val_loss: 8.1248e-08\n",
      "\n",
      "Start of epoch 672\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 6.4847e-08 - val_loss: 8.0995e-08\n",
      "\n",
      "Start of epoch 673\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 6.4676e-08 - val_loss: 8.0748e-08\n",
      "\n",
      "Start of epoch 674\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.4493e-08 - val_loss: 8.0484e-08\n",
      "\n",
      "Start of epoch 675\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.4326e-08 - val_loss: 8.0269e-08\n",
      "\n",
      "Start of epoch 676\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.4154e-08 - val_loss: 8.0019e-08\n",
      "\n",
      "Start of epoch 677\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.3983e-08 - val_loss: 7.9762e-08\n",
      "\n",
      "Start of epoch 678\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.3803e-08 - val_loss: 7.9514e-08\n",
      "\n",
      "Start of epoch 679\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.3619e-08 - val_loss: 7.9276e-08\n",
      "\n",
      "Start of epoch 680\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 6.3440e-08 - val_loss: 7.9033e-08\n",
      "\n",
      "Start of epoch 681\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.3265e-08 - val_loss: 7.8793e-08\n",
      "\n",
      "Start of epoch 682\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.3094e-08 - val_loss: 7.8573e-08\n",
      "\n",
      "Start of epoch 683\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.2929e-08 - val_loss: 7.8321e-08\n",
      "\n",
      "Start of epoch 684\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.2759e-08 - val_loss: 7.8077e-08\n",
      "\n",
      "Start of epoch 685\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.2592e-08 - val_loss: 7.7836e-08\n",
      "\n",
      "Start of epoch 686\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.2432e-08 - val_loss: 7.7611e-08\n",
      "\n",
      "Start of epoch 687\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.2263e-08 - val_loss: 7.7391e-08\n",
      "\n",
      "Start of epoch 688\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.2101e-08 - val_loss: 7.7134e-08\n",
      "\n",
      "Start of epoch 689\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.1939e-08 - val_loss: 7.6900e-08\n",
      "\n",
      "Start of epoch 690\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.1793e-08 - val_loss: 7.6667e-08\n",
      "\n",
      "Start of epoch 691\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.1633e-08 - val_loss: 7.6432e-08\n",
      "\n",
      "Start of epoch 692\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.1475e-08 - val_loss: 7.6201e-08\n",
      "\n",
      "Start of epoch 693\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.1315e-08 - val_loss: 7.5965e-08\n",
      "\n",
      "Start of epoch 694\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 6.1160e-08 - val_loss: 7.5752e-08\n",
      "\n",
      "Start of epoch 695\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 6.0988e-08 - val_loss: 7.5491e-08\n",
      "\n",
      "Start of epoch 696\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 6.0836e-08 - val_loss: 7.5309e-08\n",
      "\n",
      "Start of epoch 697\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.0682e-08 - val_loss: 7.5055e-08\n",
      "\n",
      "Start of epoch 698\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.0507e-08 - val_loss: 7.4831e-08\n",
      "\n",
      "Start of epoch 699\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 6.0348e-08 - val_loss: 7.4596e-08\n",
      "\n",
      "Start of epoch 700\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 6.0182e-08 - val_loss: 7.4375e-08\n",
      "\n",
      "Start of epoch 701\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 6.0015e-08 - val_loss: 7.4104e-08\n",
      "\n",
      "Start of epoch 702\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.9846e-08 - val_loss: 7.3877e-08\n",
      "\n",
      "Start of epoch 703\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.9676e-08 - val_loss: 7.3645e-08\n",
      "\n",
      "Start of epoch 704\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.9502e-08 - val_loss: 7.3410e-08\n",
      "\n",
      "Start of epoch 705\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.9333e-08 - val_loss: 7.3172e-08\n",
      "\n",
      "Start of epoch 706\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.9165e-08 - val_loss: 7.2961e-08\n",
      "\n",
      "Start of epoch 707\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.9008e-08 - val_loss: 7.2726e-08\n",
      "\n",
      "Start of epoch 708\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.8837e-08 - val_loss: 7.2509e-08\n",
      "\n",
      "Start of epoch 709\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.8661e-08 - val_loss: 7.2256e-08\n",
      "\n",
      "Start of epoch 710\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.8500e-08 - val_loss: 7.2061e-08\n",
      "\n",
      "Start of epoch 711\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.8343e-08 - val_loss: 7.1849e-08\n",
      "\n",
      "Start of epoch 712\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.8189e-08 - val_loss: 7.1639e-08\n",
      "\n",
      "Start of epoch 713\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.8037e-08 - val_loss: 7.1423e-08\n",
      "\n",
      "Start of epoch 714\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.7889e-08 - val_loss: 7.1233e-08\n",
      "\n",
      "Start of epoch 715\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.7737e-08 - val_loss: 7.1010e-08\n",
      "\n",
      "Start of epoch 716\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.7588e-08 - val_loss: 7.0797e-08\n",
      "\n",
      "Start of epoch 717\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.7422e-08 - val_loss: 7.0614e-08\n",
      "\n",
      "Start of epoch 718\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.7281e-08 - val_loss: 7.0426e-08\n",
      "\n",
      "Start of epoch 719\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.7138e-08 - val_loss: 7.0260e-08\n",
      "\n",
      "Start of epoch 720\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 5.6989e-08 - val_loss: 7.0025e-08\n",
      "\n",
      "Start of epoch 721\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.6821e-08 - val_loss: 6.9860e-08\n",
      "\n",
      "Start of epoch 722\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.6655e-08 - val_loss: 6.9664e-08\n",
      "\n",
      "Start of epoch 723\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.6491e-08 - val_loss: 6.9501e-08\n",
      "\n",
      "Start of epoch 724\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.6326e-08 - val_loss: 6.9296e-08\n",
      "\n",
      "Start of epoch 725\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.6174e-08 - val_loss: 6.9158e-08\n",
      "\n",
      "Start of epoch 726\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.6036e-08 - val_loss: 6.8963e-08\n",
      "\n",
      "Start of epoch 727\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.5880e-08 - val_loss: 6.8773e-08\n",
      "\n",
      "Start of epoch 728\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.5722e-08 - val_loss: 6.8578e-08\n",
      "\n",
      "Start of epoch 729\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.5562e-08 - val_loss: 6.8353e-08\n",
      "\n",
      "Start of epoch 730\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.5404e-08 - val_loss: 6.8130e-08\n",
      "\n",
      "Start of epoch 731\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.5229e-08 - val_loss: 6.7902e-08\n",
      "\n",
      "Start of epoch 732\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.5071e-08 - val_loss: 6.7743e-08\n",
      "\n",
      "Start of epoch 733\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.4922e-08 - val_loss: 6.7524e-08\n",
      "\n",
      "Start of epoch 734\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.4752e-08 - val_loss: 6.7299e-08\n",
      "\n",
      "Start of epoch 735\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 5.4611e-08 - val_loss: 6.7135e-08\n",
      "\n",
      "Start of epoch 736\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 5.4482e-08 - val_loss: 6.6933e-08\n",
      "\n",
      "Start of epoch 737\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.4332e-08 - val_loss: 6.6722e-08\n",
      "\n",
      "Start of epoch 738\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.4190e-08 - val_loss: 6.6553e-08\n",
      "\n",
      "Start of epoch 739\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.4037e-08 - val_loss: 6.6324e-08\n",
      "\n",
      "Start of epoch 740\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.3907e-08 - val_loss: 6.6149e-08\n",
      "\n",
      "Start of epoch 741\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.3778e-08 - val_loss: 6.5948e-08\n",
      "\n",
      "Start of epoch 742\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.3610e-08 - val_loss: 6.5779e-08\n",
      "\n",
      "Start of epoch 743\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.3485e-08 - val_loss: 6.5592e-08\n",
      "\n",
      "Start of epoch 744\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.3357e-08 - val_loss: 6.5404e-08\n",
      "\n",
      "Start of epoch 745\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 5.3206e-08 - val_loss: 6.5201e-08\n",
      "\n",
      "Start of epoch 746\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.3067e-08 - val_loss: 6.5036e-08\n",
      "\n",
      "Start of epoch 747\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.2940e-08 - val_loss: 6.4857e-08\n",
      "\n",
      "Start of epoch 748\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.2804e-08 - val_loss: 6.4689e-08\n",
      "\n",
      "Start of epoch 749\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.2644e-08 - val_loss: 6.4504e-08\n",
      "\n",
      "Start of epoch 750\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.2518e-08 - val_loss: 6.4362e-08\n",
      "\n",
      "Start of epoch 751\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.2385e-08 - val_loss: 6.4177e-08\n",
      "\n",
      "Start of epoch 752\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.2246e-08 - val_loss: 6.4028e-08\n",
      "\n",
      "Start of epoch 753\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 5.2112e-08 - val_loss: 6.3851e-08\n",
      "\n",
      "Start of epoch 754\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.1972e-08 - val_loss: 6.3681e-08\n",
      "\n",
      "Start of epoch 755\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.1835e-08 - val_loss: 6.3511e-08\n",
      "\n",
      "Start of epoch 756\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 5.1690e-08 - val_loss: 6.3337e-08\n",
      "\n",
      "Start of epoch 757\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 5.1548e-08 - val_loss: 6.3192e-08\n",
      "\n",
      "Start of epoch 758\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 5.1392e-08 - val_loss: 6.2994e-08\n",
      "\n",
      "Start of epoch 759\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 5.1275e-08 - val_loss: 6.2851e-08\n",
      "\n",
      "Start of epoch 760\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 5.1159e-08 - val_loss: 6.2688e-08\n",
      "\n",
      "Start of epoch 761\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 5.1012e-08 - val_loss: 6.2514e-08\n",
      "\n",
      "Start of epoch 762\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 5.0868e-08 - val_loss: 6.2316e-08\n",
      "\n",
      "Start of epoch 763\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.0736e-08 - val_loss: 6.2146e-08\n",
      "\n",
      "Start of epoch 764\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.0591e-08 - val_loss: 6.1975e-08\n",
      "\n",
      "Start of epoch 765\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.0439e-08 - val_loss: 6.1792e-08\n",
      "\n",
      "Start of epoch 766\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.0301e-08 - val_loss: 6.1620e-08\n",
      "\n",
      "Start of epoch 767\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 5.0166e-08 - val_loss: 6.1462e-08\n",
      "\n",
      "Start of epoch 768\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 5.0021e-08 - val_loss: 6.1300e-08\n",
      "\n",
      "Start of epoch 769\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.9889e-08 - val_loss: 6.1144e-08\n",
      "\n",
      "Start of epoch 770\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.9743e-08 - val_loss: 6.0985e-08\n",
      "\n",
      "Start of epoch 771\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 4.9592e-08 - val_loss: 6.0823e-08\n",
      "\n",
      "Start of epoch 772\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.9447e-08 - val_loss: 6.0689e-08\n",
      "\n",
      "Start of epoch 773\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.9274e-08 - val_loss: 6.0563e-08\n",
      "\n",
      "Start of epoch 774\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.9126e-08 - val_loss: 6.0425e-08\n",
      "\n",
      "Start of epoch 775\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.8961e-08 - val_loss: 6.0282e-08\n",
      "\n",
      "Start of epoch 776\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.8819e-08 - val_loss: 6.0145e-08\n",
      "\n",
      "Start of epoch 777\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.8671e-08 - val_loss: 6.0009e-08\n",
      "\n",
      "Start of epoch 778\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.8535e-08 - val_loss: 5.9876e-08\n",
      "\n",
      "Start of epoch 779\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.8392e-08 - val_loss: 5.9744e-08\n",
      "\n",
      "Start of epoch 780\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.8253e-08 - val_loss: 5.9613e-08\n",
      "\n",
      "Start of epoch 781\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 4.8109e-08 - val_loss: 5.9458e-08\n",
      "\n",
      "Start of epoch 782\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.7967e-08 - val_loss: 5.9336e-08\n",
      "\n",
      "Start of epoch 783\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.7831e-08 - val_loss: 5.9211e-08\n",
      "\n",
      "Start of epoch 784\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.7689e-08 - val_loss: 5.9074e-08\n",
      "\n",
      "Start of epoch 785\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.7560e-08 - val_loss: 5.8949e-08\n",
      "\n",
      "Start of epoch 786\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.7429e-08 - val_loss: 5.8826e-08\n",
      "\n",
      "Start of epoch 787\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.7301e-08 - val_loss: 5.8700e-08\n",
      "\n",
      "Start of epoch 788\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 4.7172e-08 - val_loss: 5.8577e-08\n",
      "\n",
      "Start of epoch 789\n",
      "1984/1984 [==============================] - 0s 46us/step - train_loss: 4.7042e-08 - val_loss: 5.8468e-08\n",
      "\n",
      "Start of epoch 790\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 4.6904e-08 - val_loss: 5.8350e-08\n",
      "\n",
      "Start of epoch 791\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.6782e-08 - val_loss: 5.8195e-08\n",
      "\n",
      "Start of epoch 792\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.6650e-08 - val_loss: 5.8116e-08\n",
      "\n",
      "Start of epoch 793\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.6531e-08 - val_loss: 5.8007e-08\n",
      "\n",
      "Start of epoch 794\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.6398e-08 - val_loss: 5.7904e-08\n",
      "\n",
      "Start of epoch 795\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.6275e-08 - val_loss: 5.7794e-08\n",
      "\n",
      "Start of epoch 796\n",
      "1984/1984 [==============================] - 0s 46us/step - train_loss: 4.6147e-08 - val_loss: 5.7690e-08\n",
      "\n",
      "Start of epoch 797\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.6022e-08 - val_loss: 5.7600e-08\n",
      "\n",
      "Start of epoch 798\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.5902e-08 - val_loss: 5.7484e-08\n",
      "\n",
      "Start of epoch 799\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.5767e-08 - val_loss: 5.7400e-08\n",
      "\n",
      "Start of epoch 800\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.5644e-08 - val_loss: 5.7302e-08\n",
      "\n",
      "Start of epoch 801\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.5515e-08 - val_loss: 5.7228e-08\n",
      "\n",
      "Start of epoch 802\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.5402e-08 - val_loss: 5.7099e-08\n",
      "\n",
      "Start of epoch 803\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.5272e-08 - val_loss: 5.7029e-08\n",
      "\n",
      "Start of epoch 804\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.5158e-08 - val_loss: 5.6940e-08\n",
      "\n",
      "Start of epoch 805\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.5035e-08 - val_loss: 5.6862e-08\n",
      "\n",
      "Start of epoch 806\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.4920e-08 - val_loss: 5.6754e-08\n",
      "\n",
      "Start of epoch 807\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.4794e-08 - val_loss: 5.6669e-08\n",
      "\n",
      "Start of epoch 808\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.4680e-08 - val_loss: 5.6604e-08\n",
      "\n",
      "Start of epoch 809\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.4569e-08 - val_loss: 5.6507e-08\n",
      "\n",
      "Start of epoch 810\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.4449e-08 - val_loss: 5.6438e-08\n",
      "\n",
      "Start of epoch 811\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.4340e-08 - val_loss: 5.6355e-08\n",
      "\n",
      "Start of epoch 812\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 4.4221e-08 - val_loss: 5.6291e-08\n",
      "\n",
      "Start of epoch 813\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.4110e-08 - val_loss: 5.6190e-08\n",
      "\n",
      "Start of epoch 814\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.3999e-08 - val_loss: 5.6143e-08\n",
      "\n",
      "Start of epoch 815\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.3896e-08 - val_loss: 5.6068e-08\n",
      "\n",
      "Start of epoch 816\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.3779e-08 - val_loss: 5.5997e-08\n",
      "\n",
      "Start of epoch 817\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.3675e-08 - val_loss: 5.5928e-08\n",
      "\n",
      "Start of epoch 818\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.3559e-08 - val_loss: 5.5886e-08\n",
      "\n",
      "Start of epoch 819\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.3455e-08 - val_loss: 5.5813e-08\n",
      "\n",
      "Start of epoch 820\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.3334e-08 - val_loss: 5.5753e-08\n",
      "\n",
      "Start of epoch 821\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.3216e-08 - val_loss: 5.5683e-08\n",
      "\n",
      "Start of epoch 822\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.3110e-08 - val_loss: 5.5597e-08\n",
      "\n",
      "Start of epoch 823\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.3002e-08 - val_loss: 5.5507e-08\n",
      "\n",
      "Start of epoch 824\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.2898e-08 - val_loss: 5.5431e-08\n",
      "\n",
      "Start of epoch 825\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.2802e-08 - val_loss: 5.5332e-08\n",
      "\n",
      "Start of epoch 826\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.2698e-08 - val_loss: 5.5265e-08\n",
      "\n",
      "Start of epoch 827\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.2605e-08 - val_loss: 5.5165e-08\n",
      "\n",
      "Start of epoch 828\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.2504e-08 - val_loss: 5.5074e-08\n",
      "\n",
      "Start of epoch 829\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 4.2410e-08 - val_loss: 5.4980e-08\n",
      "\n",
      "Start of epoch 830\n",
      "1984/1984 [==============================] - 0s 47us/step - train_loss: 4.2320e-08 - val_loss: 5.4902e-08\n",
      "\n",
      "Start of epoch 831\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.2224e-08 - val_loss: 5.4809e-08\n",
      "\n",
      "Start of epoch 832\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.2123e-08 - val_loss: 5.4722e-08\n",
      "\n",
      "Start of epoch 833\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.2037e-08 - val_loss: 5.4636e-08\n",
      "\n",
      "Start of epoch 834\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.1945e-08 - val_loss: 5.4551e-08\n",
      "\n",
      "Start of epoch 835\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 4.1843e-08 - val_loss: 5.4450e-08\n",
      "\n",
      "Start of epoch 836\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.1747e-08 - val_loss: 5.4377e-08\n",
      "\n",
      "Start of epoch 837\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 4.1653e-08 - val_loss: 5.4268e-08\n",
      "\n",
      "Start of epoch 838\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 4.1552e-08 - val_loss: 5.4201e-08\n",
      "\n",
      "Start of epoch 839\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 4.1458e-08 - val_loss: 5.4085e-08\n",
      "\n",
      "Start of epoch 840\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.1344e-08 - val_loss: 5.4001e-08\n",
      "\n",
      "Start of epoch 841\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.1252e-08 - val_loss: 5.3908e-08\n",
      "\n",
      "Start of epoch 842\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.1152e-08 - val_loss: 5.3819e-08\n",
      "\n",
      "Start of epoch 843\n",
      "1984/1984 [==============================] - 0s 50us/step - train_loss: 4.1050e-08 - val_loss: 5.3698e-08\n",
      "\n",
      "Start of epoch 844\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 4.0944e-08 - val_loss: 5.3611e-08\n",
      "\n",
      "Start of epoch 845\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 4.0857e-08 - val_loss: 5.3541e-08\n",
      "\n",
      "Start of epoch 846\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 4.0762e-08 - val_loss: 5.3443e-08\n",
      "\n",
      "Start of epoch 847\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.0665e-08 - val_loss: 5.3320e-08\n",
      "\n",
      "Start of epoch 848\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.0573e-08 - val_loss: 5.3187e-08\n",
      "\n",
      "Start of epoch 849\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 4.0472e-08 - val_loss: 5.3084e-08\n",
      "\n",
      "Start of epoch 850\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 4.0377e-08 - val_loss: 5.3003e-08\n",
      "\n",
      "Start of epoch 851\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 4.0286e-08 - val_loss: 5.2879e-08\n",
      "\n",
      "Start of epoch 852\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 4.0189e-08 - val_loss: 5.2760e-08\n",
      "\n",
      "Start of epoch 853\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 4.0091e-08 - val_loss: 5.2649e-08\n",
      "\n",
      "Start of epoch 854\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.9993e-08 - val_loss: 5.2556e-08\n",
      "\n",
      "Start of epoch 855\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.9886e-08 - val_loss: 5.2465e-08\n",
      "\n",
      "Start of epoch 856\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.9789e-08 - val_loss: 5.2378e-08\n",
      "\n",
      "Start of epoch 857\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.9697e-08 - val_loss: 5.2271e-08\n",
      "\n",
      "Start of epoch 858\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.9611e-08 - val_loss: 5.2162e-08\n",
      "\n",
      "Start of epoch 859\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.9516e-08 - val_loss: 5.2043e-08\n",
      "\n",
      "Start of epoch 860\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 3.9407e-08 - val_loss: 5.1903e-08\n",
      "\n",
      "Start of epoch 861\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.9313e-08 - val_loss: 5.1780e-08\n",
      "\n",
      "Start of epoch 862\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.9205e-08 - val_loss: 5.1640e-08\n",
      "\n",
      "Start of epoch 863\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.9098e-08 - val_loss: 5.1525e-08\n",
      "\n",
      "Start of epoch 864\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.9023e-08 - val_loss: 5.1467e-08\n",
      "\n",
      "Start of epoch 865\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 3.8932e-08 - val_loss: 5.1362e-08\n",
      "\n",
      "Start of epoch 866\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 3.8843e-08 - val_loss: 5.1272e-08\n",
      "\n",
      "Start of epoch 867\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 3.8759e-08 - val_loss: 5.1157e-08\n",
      "\n",
      "Start of epoch 868\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.8664e-08 - val_loss: 5.1064e-08\n",
      "\n",
      "Start of epoch 869\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.8578e-08 - val_loss: 5.0975e-08\n",
      "\n",
      "Start of epoch 870\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.8495e-08 - val_loss: 5.0862e-08\n",
      "\n",
      "Start of epoch 871\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.8381e-08 - val_loss: 5.0748e-08\n",
      "\n",
      "Start of epoch 872\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.8278e-08 - val_loss: 5.0631e-08\n",
      "\n",
      "Start of epoch 873\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.8188e-08 - val_loss: 5.0523e-08\n",
      "\n",
      "Start of epoch 874\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.8087e-08 - val_loss: 5.0412e-08\n",
      "\n",
      "Start of epoch 875\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.7993e-08 - val_loss: 5.0300e-08\n",
      "\n",
      "Start of epoch 876\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.7909e-08 - val_loss: 5.0179e-08\n",
      "\n",
      "Start of epoch 877\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.7805e-08 - val_loss: 5.0091e-08\n",
      "\n",
      "Start of epoch 878\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.7721e-08 - val_loss: 4.9967e-08\n",
      "\n",
      "Start of epoch 879\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.7630e-08 - val_loss: 4.9815e-08\n",
      "\n",
      "Start of epoch 880\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.7529e-08 - val_loss: 4.9756e-08\n",
      "\n",
      "Start of epoch 881\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 3.7451e-08 - val_loss: 4.9632e-08\n",
      "\n",
      "Start of epoch 882\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 3.7345e-08 - val_loss: 4.9515e-08\n",
      "\n",
      "Start of epoch 883\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 3.7255e-08 - val_loss: 4.9399e-08\n",
      "\n",
      "Start of epoch 884\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 3.7158e-08 - val_loss: 4.9289e-08\n",
      "\n",
      "Start of epoch 885\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.7075e-08 - val_loss: 4.9160e-08\n",
      "\n",
      "Start of epoch 886\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.6965e-08 - val_loss: 4.9036e-08\n",
      "\n",
      "Start of epoch 887\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.6882e-08 - val_loss: 4.8910e-08\n",
      "\n",
      "Start of epoch 888\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.6782e-08 - val_loss: 4.8793e-08\n",
      "\n",
      "Start of epoch 889\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.6694e-08 - val_loss: 4.8681e-08\n",
      "\n",
      "Start of epoch 890\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.6596e-08 - val_loss: 4.8555e-08\n",
      "\n",
      "Start of epoch 891\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 3.6513e-08 - val_loss: 4.8430e-08\n",
      "\n",
      "Start of epoch 892\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 3.6407e-08 - val_loss: 4.8312e-08\n",
      "\n",
      "Start of epoch 893\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.6319e-08 - val_loss: 4.8199e-08\n",
      "\n",
      "Start of epoch 894\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.6219e-08 - val_loss: 4.8085e-08\n",
      "\n",
      "Start of epoch 895\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.6130e-08 - val_loss: 4.7955e-08\n",
      "\n",
      "Start of epoch 896\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 3.6023e-08 - val_loss: 4.7863e-08\n",
      "\n",
      "Start of epoch 897\n",
      "1984/1984 [==============================] - 0s 60us/step - train_loss: 3.5948e-08 - val_loss: 4.7743e-08\n",
      "\n",
      "Start of epoch 898\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 3.5844e-08 - val_loss: 4.7612e-08\n",
      "\n",
      "Start of epoch 899\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.5765e-08 - val_loss: 4.7507e-08\n",
      "\n",
      "Start of epoch 900\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.5692e-08 - val_loss: 4.7378e-08\n",
      "\n",
      "Start of epoch 901\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.5617e-08 - val_loss: 4.7257e-08\n",
      "\n",
      "Start of epoch 902\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.5531e-08 - val_loss: 4.7125e-08\n",
      "\n",
      "Start of epoch 903\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.5432e-08 - val_loss: 4.7027e-08\n",
      "\n",
      "Start of epoch 904\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.5359e-08 - val_loss: 4.6894e-08\n",
      "\n",
      "Start of epoch 905\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.5260e-08 - val_loss: 4.6770e-08\n",
      "\n",
      "Start of epoch 906\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.5155e-08 - val_loss: 4.6599e-08\n",
      "\n",
      "Start of epoch 907\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 3.5074e-08 - val_loss: 4.6470e-08\n",
      "\n",
      "Start of epoch 908\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 3.4990e-08 - val_loss: 4.6379e-08\n",
      "\n",
      "Start of epoch 909\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 3.4915e-08 - val_loss: 4.6281e-08\n",
      "\n",
      "Start of epoch 910\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.4823e-08 - val_loss: 4.6150e-08\n",
      "\n",
      "Start of epoch 911\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.4728e-08 - val_loss: 4.6025e-08\n",
      "\n",
      "Start of epoch 912\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.4607e-08 - val_loss: 4.5865e-08\n",
      "\n",
      "Start of epoch 913\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 3.4499e-08 - val_loss: 4.5734e-08\n",
      "\n",
      "Start of epoch 914\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.4390e-08 - val_loss: 4.5588e-08\n",
      "\n",
      "Start of epoch 915\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.4291e-08 - val_loss: 4.5460e-08\n",
      "\n",
      "Start of epoch 916\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.4192e-08 - val_loss: 4.5361e-08\n",
      "\n",
      "Start of epoch 917\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.4109e-08 - val_loss: 4.5270e-08\n",
      "\n",
      "Start of epoch 918\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.4013e-08 - val_loss: 4.5150e-08\n",
      "\n",
      "Start of epoch 919\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.3912e-08 - val_loss: 4.5014e-08\n",
      "\n",
      "Start of epoch 920\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.3811e-08 - val_loss: 4.4918e-08\n",
      "\n",
      "Start of epoch 921\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.3702e-08 - val_loss: 4.4792e-08\n",
      "\n",
      "Start of epoch 922\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.3604e-08 - val_loss: 4.4720e-08\n",
      "\n",
      "Start of epoch 923\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.3516e-08 - val_loss: 4.4626e-08\n",
      "\n",
      "Start of epoch 924\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.3413e-08 - val_loss: 4.4531e-08\n",
      "\n",
      "Start of epoch 925\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.3314e-08 - val_loss: 4.4448e-08\n",
      "\n",
      "Start of epoch 926\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.3215e-08 - val_loss: 4.4351e-08\n",
      "\n",
      "Start of epoch 927\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.3103e-08 - val_loss: 4.4229e-08\n",
      "\n",
      "Start of epoch 928\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.3004e-08 - val_loss: 4.4132e-08\n",
      "\n",
      "Start of epoch 929\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.2915e-08 - val_loss: 4.4045e-08\n",
      "\n",
      "Start of epoch 930\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 3.2813e-08 - val_loss: 4.3990e-08\n",
      "\n",
      "Start of epoch 931\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.2729e-08 - val_loss: 4.3927e-08\n",
      "\n",
      "Start of epoch 932\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.2632e-08 - val_loss: 4.3850e-08\n",
      "\n",
      "Start of epoch 933\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.2526e-08 - val_loss: 4.3769e-08\n",
      "\n",
      "Start of epoch 934\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.2433e-08 - val_loss: 4.3694e-08\n",
      "\n",
      "Start of epoch 935\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.2341e-08 - val_loss: 4.3640e-08\n",
      "\n",
      "Start of epoch 936\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.2251e-08 - val_loss: 4.3602e-08\n",
      "\n",
      "Start of epoch 937\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.2163e-08 - val_loss: 4.3526e-08\n",
      "\n",
      "Start of epoch 938\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.2071e-08 - val_loss: 4.3425e-08\n",
      "\n",
      "Start of epoch 939\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.1978e-08 - val_loss: 4.3383e-08\n",
      "\n",
      "Start of epoch 940\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.1902e-08 - val_loss: 4.3329e-08\n",
      "\n",
      "Start of epoch 941\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.1818e-08 - val_loss: 4.3257e-08\n",
      "\n",
      "Start of epoch 942\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.1731e-08 - val_loss: 4.3190e-08\n",
      "\n",
      "Start of epoch 943\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.1643e-08 - val_loss: 4.3083e-08\n",
      "\n",
      "Start of epoch 944\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 3.1565e-08 - val_loss: 4.2994e-08\n",
      "\n",
      "Start of epoch 945\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.1497e-08 - val_loss: 4.2869e-08\n",
      "\n",
      "Start of epoch 946\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.1415e-08 - val_loss: 4.2810e-08\n",
      "\n",
      "Start of epoch 947\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.1327e-08 - val_loss: 4.2711e-08\n",
      "\n",
      "Start of epoch 948\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.1244e-08 - val_loss: 4.2636e-08\n",
      "\n",
      "Start of epoch 949\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.1171e-08 - val_loss: 4.2510e-08\n",
      "\n",
      "Start of epoch 950\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.1096e-08 - val_loss: 4.2421e-08\n",
      "\n",
      "Start of epoch 951\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.1024e-08 - val_loss: 4.2341e-08\n",
      "\n",
      "Start of epoch 952\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.0954e-08 - val_loss: 4.2269e-08\n",
      "\n",
      "Start of epoch 953\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 3.0885e-08 - val_loss: 4.2172e-08\n",
      "\n",
      "Start of epoch 954\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.0812e-08 - val_loss: 4.2106e-08\n",
      "\n",
      "Start of epoch 955\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.0747e-08 - val_loss: 4.1967e-08\n",
      "\n",
      "Start of epoch 956\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.0669e-08 - val_loss: 4.1868e-08\n",
      "\n",
      "Start of epoch 957\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.0597e-08 - val_loss: 4.1758e-08\n",
      "\n",
      "Start of epoch 958\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.0524e-08 - val_loss: 4.1678e-08\n",
      "\n",
      "Start of epoch 959\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 3.0459e-08 - val_loss: 4.1508e-08\n",
      "\n",
      "Start of epoch 960\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 3.0380e-08 - val_loss: 4.1395e-08\n",
      "\n",
      "Start of epoch 961\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 3.0305e-08 - val_loss: 4.1291e-08\n",
      "\n",
      "Start of epoch 962\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.0234e-08 - val_loss: 4.1178e-08\n",
      "\n",
      "Start of epoch 963\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.0159e-08 - val_loss: 4.1062e-08\n",
      "\n",
      "Start of epoch 964\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 3.0089e-08 - val_loss: 4.0898e-08\n",
      "\n",
      "Start of epoch 965\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 3.0008e-08 - val_loss: 4.0789e-08\n",
      "\n",
      "Start of epoch 966\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.9940e-08 - val_loss: 4.0686e-08\n",
      "\n",
      "Start of epoch 967\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.9861e-08 - val_loss: 4.0563e-08\n",
      "\n",
      "Start of epoch 968\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.9779e-08 - val_loss: 4.0456e-08\n",
      "\n",
      "Start of epoch 969\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.9710e-08 - val_loss: 4.0311e-08\n",
      "\n",
      "Start of epoch 970\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 2.9633e-08 - val_loss: 4.0188e-08\n",
      "\n",
      "Start of epoch 971\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.9554e-08 - val_loss: 4.0048e-08\n",
      "\n",
      "Start of epoch 972\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 2.9486e-08 - val_loss: 3.9904e-08\n",
      "\n",
      "Start of epoch 973\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.9416e-08 - val_loss: 3.9786e-08\n",
      "\n",
      "Start of epoch 974\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.9342e-08 - val_loss: 3.9671e-08\n",
      "\n",
      "Start of epoch 975\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.9267e-08 - val_loss: 3.9561e-08\n",
      "\n",
      "Start of epoch 976\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.9195e-08 - val_loss: 3.9452e-08\n",
      "\n",
      "Start of epoch 977\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.9132e-08 - val_loss: 3.9274e-08\n",
      "\n",
      "Start of epoch 978\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.9056e-08 - val_loss: 3.9157e-08\n",
      "\n",
      "Start of epoch 979\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.8980e-08 - val_loss: 3.9011e-08\n",
      "\n",
      "Start of epoch 980\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.8903e-08 - val_loss: 3.8904e-08\n",
      "\n",
      "Start of epoch 981\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.8830e-08 - val_loss: 3.8771e-08\n",
      "\n",
      "Start of epoch 982\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.8758e-08 - val_loss: 3.8640e-08\n",
      "\n",
      "Start of epoch 983\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.8683e-08 - val_loss: 3.8496e-08\n",
      "\n",
      "Start of epoch 984\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.8612e-08 - val_loss: 3.8396e-08\n",
      "\n",
      "Start of epoch 985\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.8539e-08 - val_loss: 3.8222e-08\n",
      "\n",
      "Start of epoch 986\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 2.8462e-08 - val_loss: 3.8110e-08\n",
      "\n",
      "Start of epoch 987\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 2.8395e-08 - val_loss: 3.8032e-08\n",
      "\n",
      "Start of epoch 988\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.8329e-08 - val_loss: 3.7922e-08\n",
      "\n",
      "Start of epoch 989\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.8256e-08 - val_loss: 3.7846e-08\n",
      "\n",
      "Start of epoch 990\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.8194e-08 - val_loss: 3.7708e-08\n",
      "\n",
      "Start of epoch 991\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.8118e-08 - val_loss: 3.7627e-08\n",
      "\n",
      "Start of epoch 992\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.8053e-08 - val_loss: 3.7497e-08\n",
      "\n",
      "Start of epoch 993\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.7980e-08 - val_loss: 3.7377e-08\n",
      "\n",
      "Start of epoch 994\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.7898e-08 - val_loss: 3.7257e-08\n",
      "\n",
      "Start of epoch 995\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 2.7831e-08 - val_loss: 3.7173e-08\n",
      "\n",
      "Start of epoch 996\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.7749e-08 - val_loss: 3.7090e-08\n",
      "\n",
      "Start of epoch 997\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 2.7685e-08 - val_loss: 3.7008e-08\n",
      "\n",
      "Start of epoch 998\n",
      "1984/1984 [==============================] - 0s 58us/step - train_loss: 2.7616e-08 - val_loss: 3.6930e-08\n",
      "\n",
      "Start of epoch 999\n",
      "1984/1984 [==============================] - 0s 53us/step - train_loss: 2.7558e-08 - val_loss: 3.6799e-08\n",
      "\n",
      "Start of epoch 1000\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.7489e-08 - val_loss: 3.6708e-08\n",
      "\n",
      "Start of epoch 1001\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.7417e-08 - val_loss: 3.6615e-08\n",
      "\n",
      "Start of epoch 1002\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.7349e-08 - val_loss: 3.6539e-08\n",
      "\n",
      "Start of epoch 1003\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.7275e-08 - val_loss: 3.6446e-08\n",
      "\n",
      "Start of epoch 1004\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 2.7210e-08 - val_loss: 3.6374e-08\n",
      "\n",
      "Start of epoch 1005\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 2.7149e-08 - val_loss: 3.6257e-08\n",
      "\n",
      "Start of epoch 1006\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.7079e-08 - val_loss: 3.6160e-08\n",
      "\n",
      "Start of epoch 1007\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.7000e-08 - val_loss: 3.6049e-08\n",
      "\n",
      "Start of epoch 1008\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.6928e-08 - val_loss: 3.5982e-08\n",
      "\n",
      "Start of epoch 1009\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.6855e-08 - val_loss: 3.5889e-08\n",
      "\n",
      "Start of epoch 1010\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.6794e-08 - val_loss: 3.5754e-08\n",
      "\n",
      "Start of epoch 1011\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.6721e-08 - val_loss: 3.5698e-08\n",
      "\n",
      "Start of epoch 1012\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 2.6653e-08 - val_loss: 3.5637e-08\n",
      "\n",
      "Start of epoch 1013\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.6592e-08 - val_loss: 3.5554e-08\n",
      "\n",
      "Start of epoch 1014\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.6525e-08 - val_loss: 3.5493e-08\n",
      "\n",
      "Start of epoch 1015\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.6459e-08 - val_loss: 3.5363e-08\n",
      "\n",
      "Start of epoch 1016\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.6397e-08 - val_loss: 3.5287e-08\n",
      "\n",
      "Start of epoch 1017\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.6330e-08 - val_loss: 3.5234e-08\n",
      "\n",
      "Start of epoch 1018\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.6267e-08 - val_loss: 3.5157e-08\n",
      "\n",
      "Start of epoch 1019\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.6205e-08 - val_loss: 3.5078e-08\n",
      "\n",
      "Start of epoch 1020\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.6145e-08 - val_loss: 3.4922e-08\n",
      "\n",
      "Start of epoch 1021\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.6080e-08 - val_loss: 3.4864e-08\n",
      "\n",
      "Start of epoch 1022\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.6023e-08 - val_loss: 3.4811e-08\n",
      "\n",
      "Start of epoch 1023\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.5968e-08 - val_loss: 3.4792e-08\n",
      "\n",
      "Start of epoch 1024\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.5913e-08 - val_loss: 3.4674e-08\n",
      "\n",
      "Start of epoch 1025\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.5851e-08 - val_loss: 3.4624e-08\n",
      "\n",
      "Start of epoch 1026\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.5792e-08 - val_loss: 3.4553e-08\n",
      "\n",
      "Start of epoch 1027\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5727e-08 - val_loss: 3.4490e-08\n",
      "\n",
      "Start of epoch 1028\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5668e-08 - val_loss: 3.4437e-08\n",
      "\n",
      "Start of epoch 1029\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 2.5612e-08 - val_loss: 3.4334e-08\n",
      "\n",
      "Start of epoch 1030\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5545e-08 - val_loss: 3.4261e-08\n",
      "\n",
      "Start of epoch 1031\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5488e-08 - val_loss: 3.4207e-08\n",
      "\n",
      "Start of epoch 1032\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.5432e-08 - val_loss: 3.4153e-08\n",
      "\n",
      "Start of epoch 1033\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.5376e-08 - val_loss: 3.4059e-08\n",
      "\n",
      "Start of epoch 1034\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.5319e-08 - val_loss: 3.3988e-08\n",
      "\n",
      "Start of epoch 1035\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5261e-08 - val_loss: 3.3929e-08\n",
      "\n",
      "Start of epoch 1036\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5211e-08 - val_loss: 3.3900e-08\n",
      "\n",
      "Start of epoch 1037\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5154e-08 - val_loss: 3.3846e-08\n",
      "\n",
      "Start of epoch 1038\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5104e-08 - val_loss: 3.3736e-08\n",
      "\n",
      "Start of epoch 1039\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.5048e-08 - val_loss: 3.3673e-08\n",
      "\n",
      "Start of epoch 1040\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.4993e-08 - val_loss: 3.3600e-08\n",
      "\n",
      "Start of epoch 1041\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.4927e-08 - val_loss: 3.3558e-08\n",
      "\n",
      "Start of epoch 1042\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.4884e-08 - val_loss: 3.3467e-08\n",
      "\n",
      "Start of epoch 1043\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 2.4828e-08 - val_loss: 3.3390e-08\n",
      "\n",
      "Start of epoch 1044\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.4764e-08 - val_loss: 3.3352e-08\n",
      "\n",
      "Start of epoch 1045\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.4712e-08 - val_loss: 3.3288e-08\n",
      "\n",
      "Start of epoch 1046\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.4655e-08 - val_loss: 3.3242e-08\n",
      "\n",
      "Start of epoch 1047\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.4609e-08 - val_loss: 3.3146e-08\n",
      "\n",
      "Start of epoch 1048\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.4553e-08 - val_loss: 3.3077e-08\n",
      "\n",
      "Start of epoch 1049\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.4486e-08 - val_loss: 3.3038e-08\n",
      "\n",
      "Start of epoch 1050\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.4438e-08 - val_loss: 3.2953e-08\n",
      "\n",
      "Start of epoch 1051\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.4380e-08 - val_loss: 3.2899e-08\n",
      "\n",
      "Start of epoch 1052\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.4324e-08 - val_loss: 3.2805e-08\n",
      "\n",
      "Start of epoch 1053\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.4278e-08 - val_loss: 3.2755e-08\n",
      "\n",
      "Start of epoch 1054\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.4224e-08 - val_loss: 3.2681e-08\n",
      "\n",
      "Start of epoch 1055\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 2.4166e-08 - val_loss: 3.2623e-08\n",
      "\n",
      "Start of epoch 1056\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.4105e-08 - val_loss: 3.2550e-08\n",
      "\n",
      "Start of epoch 1057\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.4046e-08 - val_loss: 3.2453e-08\n",
      "\n",
      "Start of epoch 1058\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3989e-08 - val_loss: 3.2355e-08\n",
      "\n",
      "Start of epoch 1059\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.3930e-08 - val_loss: 3.2317e-08\n",
      "\n",
      "Start of epoch 1060\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3886e-08 - val_loss: 3.2253e-08\n",
      "\n",
      "Start of epoch 1061\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.3830e-08 - val_loss: 3.2177e-08\n",
      "\n",
      "Start of epoch 1062\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.3776e-08 - val_loss: 3.2096e-08\n",
      "\n",
      "Start of epoch 1063\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3729e-08 - val_loss: 3.2040e-08\n",
      "\n",
      "Start of epoch 1064\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.3671e-08 - val_loss: 3.1988e-08\n",
      "\n",
      "Start of epoch 1065\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3625e-08 - val_loss: 3.1962e-08\n",
      "\n",
      "Start of epoch 1066\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.3575e-08 - val_loss: 3.1890e-08\n",
      "\n",
      "Start of epoch 1067\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 2.3527e-08 - val_loss: 3.1826e-08\n",
      "\n",
      "Start of epoch 1068\n",
      "1984/1984 [==============================] - 0s 54us/step - train_loss: 2.3473e-08 - val_loss: 3.1759e-08\n",
      "\n",
      "Start of epoch 1069\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.3427e-08 - val_loss: 3.1702e-08\n",
      "\n",
      "Start of epoch 1070\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.3370e-08 - val_loss: 3.1664e-08\n",
      "\n",
      "Start of epoch 1071\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.3315e-08 - val_loss: 3.1565e-08\n",
      "\n",
      "Start of epoch 1072\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3265e-08 - val_loss: 3.1507e-08\n",
      "\n",
      "Start of epoch 1073\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3221e-08 - val_loss: 3.1446e-08\n",
      "\n",
      "Start of epoch 1074\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3161e-08 - val_loss: 3.1405e-08\n",
      "\n",
      "Start of epoch 1075\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.3125e-08 - val_loss: 3.1303e-08\n",
      "\n",
      "Start of epoch 1076\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.3067e-08 - val_loss: 3.1234e-08\n",
      "\n",
      "Start of epoch 1077\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.3026e-08 - val_loss: 3.1182e-08\n",
      "\n",
      "Start of epoch 1078\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.2971e-08 - val_loss: 3.1102e-08\n",
      "\n",
      "Start of epoch 1079\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.2932e-08 - val_loss: 3.1067e-08\n",
      "\n",
      "Start of epoch 1080\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.2886e-08 - val_loss: 3.1002e-08\n",
      "\n",
      "Start of epoch 1081\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.2848e-08 - val_loss: 3.0967e-08\n",
      "\n",
      "Start of epoch 1082\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 2.2799e-08 - val_loss: 3.0863e-08\n",
      "\n",
      "Start of epoch 1083\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.2753e-08 - val_loss: 3.0811e-08\n",
      "\n",
      "Start of epoch 1084\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.2708e-08 - val_loss: 3.0760e-08\n",
      "\n",
      "Start of epoch 1085\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.2655e-08 - val_loss: 3.0685e-08\n",
      "\n",
      "Start of epoch 1086\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.2609e-08 - val_loss: 3.0594e-08\n",
      "\n",
      "Start of epoch 1087\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.2567e-08 - val_loss: 3.0550e-08\n",
      "\n",
      "Start of epoch 1088\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.2518e-08 - val_loss: 3.0475e-08\n",
      "\n",
      "Start of epoch 1089\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.2473e-08 - val_loss: 3.0471e-08\n",
      "\n",
      "Start of epoch 1090\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.2423e-08 - val_loss: 3.0400e-08\n",
      "\n",
      "Start of epoch 1091\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.2380e-08 - val_loss: 3.0355e-08\n",
      "\n",
      "Start of epoch 1092\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.2321e-08 - val_loss: 3.0312e-08\n",
      "\n",
      "Start of epoch 1093\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.2281e-08 - val_loss: 3.0271e-08\n",
      "\n",
      "Start of epoch 1094\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.2231e-08 - val_loss: 3.0225e-08\n",
      "\n",
      "Start of epoch 1095\n",
      "1984/1984 [==============================] - 0s 52us/step - train_loss: 2.2174e-08 - val_loss: 3.0141e-08\n",
      "\n",
      "Start of epoch 1096\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 2.2114e-08 - val_loss: 3.0047e-08\n",
      "\n",
      "Start of epoch 1097\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.2049e-08 - val_loss: 2.9950e-08\n",
      "\n",
      "Start of epoch 1098\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.1996e-08 - val_loss: 2.9857e-08\n",
      "\n",
      "Start of epoch 1099\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 2.1932e-08 - val_loss: 2.9797e-08\n",
      "\n",
      "Start of epoch 1100\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.1880e-08 - val_loss: 2.9722e-08\n",
      "\n",
      "Start of epoch 1101\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.1828e-08 - val_loss: 2.9638e-08\n",
      "\n",
      "Start of epoch 1102\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.1775e-08 - val_loss: 2.9557e-08\n",
      "\n",
      "Start of epoch 1103\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1726e-08 - val_loss: 2.9511e-08\n",
      "\n",
      "Start of epoch 1104\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.1678e-08 - val_loss: 2.9420e-08\n",
      "\n",
      "Start of epoch 1105\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1631e-08 - val_loss: 2.9382e-08\n",
      "\n",
      "Start of epoch 1106\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1593e-08 - val_loss: 2.9327e-08\n",
      "\n",
      "Start of epoch 1107\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1546e-08 - val_loss: 2.9236e-08\n",
      "\n",
      "Start of epoch 1108\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.1498e-08 - val_loss: 2.9166e-08\n",
      "\n",
      "Start of epoch 1109\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.1447e-08 - val_loss: 2.9094e-08\n",
      "\n",
      "Start of epoch 1110\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 2.1407e-08 - val_loss: 2.9034e-08\n",
      "\n",
      "Start of epoch 1111\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.1351e-08 - val_loss: 2.8967e-08\n",
      "\n",
      "Start of epoch 1112\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.1313e-08 - val_loss: 2.8842e-08\n",
      "\n",
      "Start of epoch 1113\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.1264e-08 - val_loss: 2.8760e-08\n",
      "\n",
      "Start of epoch 1114\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.1207e-08 - val_loss: 2.8671e-08\n",
      "\n",
      "Start of epoch 1115\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.1144e-08 - val_loss: 2.8585e-08\n",
      "\n",
      "Start of epoch 1116\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1103e-08 - val_loss: 2.8528e-08\n",
      "\n",
      "Start of epoch 1117\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.1048e-08 - val_loss: 2.8441e-08\n",
      "\n",
      "Start of epoch 1118\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 2.1005e-08 - val_loss: 2.8350e-08\n",
      "\n",
      "Start of epoch 1119\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.0961e-08 - val_loss: 2.8272e-08\n",
      "\n",
      "Start of epoch 1120\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.0910e-08 - val_loss: 2.8213e-08\n",
      "\n",
      "Start of epoch 1121\n",
      "1984/1984 [==============================] - 0s 50us/step - train_loss: 2.0872e-08 - val_loss: 2.8153e-08\n",
      "\n",
      "Start of epoch 1122\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 2.0823e-08 - val_loss: 2.8074e-08\n",
      "\n",
      "Start of epoch 1123\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 2.0784e-08 - val_loss: 2.7998e-08\n",
      "\n",
      "Start of epoch 1124\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.0731e-08 - val_loss: 2.7902e-08\n",
      "\n",
      "Start of epoch 1125\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.0687e-08 - val_loss: 2.7862e-08\n",
      "\n",
      "Start of epoch 1126\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 2.0653e-08 - val_loss: 2.7781e-08\n",
      "\n",
      "Start of epoch 1127\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.0594e-08 - val_loss: 2.7734e-08\n",
      "\n",
      "Start of epoch 1128\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 2.0555e-08 - val_loss: 2.7649e-08\n",
      "\n",
      "Start of epoch 1129\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.0504e-08 - val_loss: 2.7580e-08\n",
      "\n",
      "Start of epoch 1130\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 2.0464e-08 - val_loss: 2.7479e-08\n",
      "\n",
      "Start of epoch 1131\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 2.0407e-08 - val_loss: 2.7440e-08\n",
      "\n",
      "Start of epoch 1132\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 2.0368e-08 - val_loss: 2.7380e-08\n",
      "\n",
      "Start of epoch 1133\n",
      "1984/1984 [==============================] - 0s 46us/step - train_loss: 2.0315e-08 - val_loss: 2.7295e-08\n",
      "\n",
      "Start of epoch 1134\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 2.0269e-08 - val_loss: 2.7254e-08\n",
      "\n",
      "Start of epoch 1135\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 2.0233e-08 - val_loss: 2.7160e-08\n",
      "\n",
      "Start of epoch 1136\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 2.0178e-08 - val_loss: 2.7137e-08\n",
      "\n",
      "Start of epoch 1137\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 2.0139e-08 - val_loss: 2.7082e-08\n",
      "\n",
      "Start of epoch 1138\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 2.0091e-08 - val_loss: 2.7017e-08\n",
      "\n",
      "Start of epoch 1139\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 2.0047e-08 - val_loss: 2.6969e-08\n",
      "\n",
      "Start of epoch 1140\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.9993e-08 - val_loss: 2.6940e-08\n",
      "\n",
      "Start of epoch 1141\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.9965e-08 - val_loss: 2.6816e-08\n",
      "\n",
      "Start of epoch 1142\n",
      "1984/1984 [==============================] - 0s 54us/step - train_loss: 1.9901e-08 - val_loss: 2.6808e-08\n",
      "\n",
      "Start of epoch 1143\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.9869e-08 - val_loss: 2.6729e-08\n",
      "\n",
      "Start of epoch 1144\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.9818e-08 - val_loss: 2.6698e-08\n",
      "\n",
      "Start of epoch 1145\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.9787e-08 - val_loss: 2.6603e-08\n",
      "\n",
      "Start of epoch 1146\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.9727e-08 - val_loss: 2.6554e-08\n",
      "\n",
      "Start of epoch 1147\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.9691e-08 - val_loss: 2.6521e-08\n",
      "\n",
      "Start of epoch 1148\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.9647e-08 - val_loss: 2.6445e-08\n",
      "\n",
      "Start of epoch 1149\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.9606e-08 - val_loss: 2.6380e-08\n",
      "\n",
      "Start of epoch 1150\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.9567e-08 - val_loss: 2.6316e-08\n",
      "\n",
      "Start of epoch 1151\n",
      "1984/1984 [==============================] - 0s 53us/step - train_loss: 1.9519e-08 - val_loss: 2.6276e-08\n",
      "\n",
      "Start of epoch 1152\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 1.9479e-08 - val_loss: 2.6214e-08\n",
      "\n",
      "Start of epoch 1153\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.9440e-08 - val_loss: 2.6120e-08\n",
      "\n",
      "Start of epoch 1154\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.9395e-08 - val_loss: 2.6096e-08\n",
      "\n",
      "Start of epoch 1155\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.9353e-08 - val_loss: 2.6014e-08\n",
      "\n",
      "Start of epoch 1156\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.9303e-08 - val_loss: 2.5991e-08\n",
      "\n",
      "Start of epoch 1157\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.9272e-08 - val_loss: 2.5902e-08\n",
      "\n",
      "Start of epoch 1158\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.9208e-08 - val_loss: 2.5857e-08\n",
      "\n",
      "Start of epoch 1159\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.9165e-08 - val_loss: 2.5733e-08\n",
      "\n",
      "Start of epoch 1160\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.9110e-08 - val_loss: 2.5678e-08\n",
      "\n",
      "Start of epoch 1161\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.9063e-08 - val_loss: 2.5633e-08\n",
      "\n",
      "Start of epoch 1162\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.9018e-08 - val_loss: 2.5577e-08\n",
      "\n",
      "Start of epoch 1163\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8987e-08 - val_loss: 2.5526e-08\n",
      "\n",
      "Start of epoch 1164\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 1.8937e-08 - val_loss: 2.5470e-08\n",
      "\n",
      "Start of epoch 1165\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8902e-08 - val_loss: 2.5423e-08\n",
      "\n",
      "Start of epoch 1166\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8846e-08 - val_loss: 2.5364e-08\n",
      "\n",
      "Start of epoch 1167\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8809e-08 - val_loss: 2.5309e-08\n",
      "\n",
      "Start of epoch 1168\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8762e-08 - val_loss: 2.5261e-08\n",
      "\n",
      "Start of epoch 1169\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.8705e-08 - val_loss: 2.5201e-08\n",
      "\n",
      "Start of epoch 1170\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8659e-08 - val_loss: 2.5147e-08\n",
      "\n",
      "Start of epoch 1171\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8625e-08 - val_loss: 2.5089e-08\n",
      "\n",
      "Start of epoch 1172\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8560e-08 - val_loss: 2.5082e-08\n",
      "\n",
      "Start of epoch 1173\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8535e-08 - val_loss: 2.5052e-08\n",
      "\n",
      "Start of epoch 1174\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8479e-08 - val_loss: 2.5033e-08\n",
      "\n",
      "Start of epoch 1175\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.8442e-08 - val_loss: 2.4968e-08\n",
      "\n",
      "Start of epoch 1176\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.8404e-08 - val_loss: 2.4941e-08\n",
      "\n",
      "Start of epoch 1177\n",
      "1984/1984 [==============================] - 0s 54us/step - train_loss: 1.8371e-08 - val_loss: 2.4906e-08\n",
      "\n",
      "Start of epoch 1178\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.8330e-08 - val_loss: 2.4889e-08\n",
      "\n",
      "Start of epoch 1179\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.8307e-08 - val_loss: 2.4834e-08\n",
      "\n",
      "Start of epoch 1180\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.8268e-08 - val_loss: 2.4798e-08\n",
      "\n",
      "Start of epoch 1181\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.8230e-08 - val_loss: 2.4751e-08\n",
      "\n",
      "Start of epoch 1182\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.8205e-08 - val_loss: 2.4717e-08\n",
      "\n",
      "Start of epoch 1183\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8166e-08 - val_loss: 2.4656e-08\n",
      "\n",
      "Start of epoch 1184\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8130e-08 - val_loss: 2.4656e-08\n",
      "\n",
      "Start of epoch 1185\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.8102e-08 - val_loss: 2.4608e-08\n",
      "\n",
      "Start of epoch 1186\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8062e-08 - val_loss: 2.4567e-08\n",
      "\n",
      "Start of epoch 1187\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.8036e-08 - val_loss: 2.4510e-08\n",
      "\n",
      "Start of epoch 1188\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7999e-08 - val_loss: 2.4457e-08\n",
      "\n",
      "Start of epoch 1189\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.7960e-08 - val_loss: 2.4431e-08\n",
      "\n",
      "Start of epoch 1190\n",
      "1984/1984 [==============================] - 0s 56us/step - train_loss: 1.7924e-08 - val_loss: 2.4374e-08\n",
      "\n",
      "Start of epoch 1191\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.7881e-08 - val_loss: 2.4382e-08\n",
      "\n",
      "Start of epoch 1192\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.7853e-08 - val_loss: 2.4370e-08\n",
      "\n",
      "Start of epoch 1193\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.7817e-08 - val_loss: 2.4314e-08\n",
      "\n",
      "Start of epoch 1194\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7776e-08 - val_loss: 2.4258e-08\n",
      "\n",
      "Start of epoch 1195\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7738e-08 - val_loss: 2.4242e-08\n",
      "\n",
      "Start of epoch 1196\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.7703e-08 - val_loss: 2.4210e-08\n",
      "\n",
      "Start of epoch 1197\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7674e-08 - val_loss: 2.4148e-08\n",
      "\n",
      "Start of epoch 1198\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7639e-08 - val_loss: 2.4167e-08\n",
      "\n",
      "Start of epoch 1199\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.7618e-08 - val_loss: 2.4081e-08\n",
      "\n",
      "Start of epoch 1200\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7580e-08 - val_loss: 2.4058e-08\n",
      "\n",
      "Start of epoch 1201\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7553e-08 - val_loss: 2.3989e-08\n",
      "\n",
      "Start of epoch 1202\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.7507e-08 - val_loss: 2.3966e-08\n",
      "\n",
      "Start of epoch 1203\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7482e-08 - val_loss: 2.3929e-08\n",
      "\n",
      "Start of epoch 1204\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.7454e-08 - val_loss: 2.3899e-08\n",
      "\n",
      "Start of epoch 1205\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7423e-08 - val_loss: 2.3847e-08\n",
      "\n",
      "Start of epoch 1206\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7399e-08 - val_loss: 2.3810e-08\n",
      "\n",
      "Start of epoch 1207\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7359e-08 - val_loss: 2.3754e-08\n",
      "\n",
      "Start of epoch 1208\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7330e-08 - val_loss: 2.3729e-08\n",
      "\n",
      "Start of epoch 1209\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7302e-08 - val_loss: 2.3696e-08\n",
      "\n",
      "Start of epoch 1210\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.7271e-08 - val_loss: 2.3649e-08\n",
      "\n",
      "Start of epoch 1211\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7241e-08 - val_loss: 2.3627e-08\n",
      "\n",
      "Start of epoch 1212\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7219e-08 - val_loss: 2.3569e-08\n",
      "\n",
      "Start of epoch 1213\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7178e-08 - val_loss: 2.3536e-08\n",
      "\n",
      "Start of epoch 1214\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7151e-08 - val_loss: 2.3525e-08\n",
      "\n",
      "Start of epoch 1215\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7129e-08 - val_loss: 2.3480e-08\n",
      "\n",
      "Start of epoch 1216\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7100e-08 - val_loss: 2.3451e-08\n",
      "\n",
      "Start of epoch 1217\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.7075e-08 - val_loss: 2.3396e-08\n",
      "\n",
      "Start of epoch 1218\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7046e-08 - val_loss: 2.3370e-08\n",
      "\n",
      "Start of epoch 1219\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.7017e-08 - val_loss: 2.3309e-08\n",
      "\n",
      "Start of epoch 1220\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6985e-08 - val_loss: 2.3288e-08\n",
      "\n",
      "Start of epoch 1221\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6951e-08 - val_loss: 2.3254e-08\n",
      "\n",
      "Start of epoch 1222\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.6925e-08 - val_loss: 2.3219e-08\n",
      "\n",
      "Start of epoch 1223\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6906e-08 - val_loss: 2.3195e-08\n",
      "\n",
      "Start of epoch 1224\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6867e-08 - val_loss: 2.3160e-08\n",
      "\n",
      "Start of epoch 1225\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6849e-08 - val_loss: 2.3116e-08\n",
      "\n",
      "Start of epoch 1226\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.6814e-08 - val_loss: 2.3088e-08\n",
      "\n",
      "Start of epoch 1227\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6796e-08 - val_loss: 2.3043e-08\n",
      "\n",
      "Start of epoch 1228\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6759e-08 - val_loss: 2.3008e-08\n",
      "\n",
      "Start of epoch 1229\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.6746e-08 - val_loss: 2.2963e-08\n",
      "\n",
      "Start of epoch 1230\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6710e-08 - val_loss: 2.2934e-08\n",
      "\n",
      "Start of epoch 1231\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6691e-08 - val_loss: 2.2903e-08\n",
      "\n",
      "Start of epoch 1232\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6664e-08 - val_loss: 2.2860e-08\n",
      "\n",
      "Start of epoch 1233\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6633e-08 - val_loss: 2.2852e-08\n",
      "\n",
      "Start of epoch 1234\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.6624e-08 - val_loss: 2.2808e-08\n",
      "\n",
      "Start of epoch 1235\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.6601e-08 - val_loss: 2.2794e-08\n",
      "\n",
      "Start of epoch 1236\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.6578e-08 - val_loss: 2.2741e-08\n",
      "\n",
      "Start of epoch 1237\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6551e-08 - val_loss: 2.2706e-08\n",
      "\n",
      "Start of epoch 1238\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.6524e-08 - val_loss: 2.2646e-08\n",
      "\n",
      "Start of epoch 1239\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6493e-08 - val_loss: 2.2609e-08\n",
      "\n",
      "Start of epoch 1240\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.6458e-08 - val_loss: 2.2540e-08\n",
      "\n",
      "Start of epoch 1241\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.6437e-08 - val_loss: 2.2526e-08\n",
      "\n",
      "Start of epoch 1242\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6421e-08 - val_loss: 2.2503e-08\n",
      "\n",
      "Start of epoch 1243\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6398e-08 - val_loss: 2.2479e-08\n",
      "\n",
      "Start of epoch 1244\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6371e-08 - val_loss: 2.2445e-08\n",
      "\n",
      "Start of epoch 1245\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.6354e-08 - val_loss: 2.2422e-08\n",
      "\n",
      "Start of epoch 1246\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6324e-08 - val_loss: 2.2399e-08\n",
      "\n",
      "Start of epoch 1247\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6302e-08 - val_loss: 2.2322e-08\n",
      "\n",
      "Start of epoch 1248\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6261e-08 - val_loss: 2.2291e-08\n",
      "\n",
      "Start of epoch 1249\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.6232e-08 - val_loss: 2.2240e-08\n",
      "\n",
      "Start of epoch 1250\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.6202e-08 - val_loss: 2.2200e-08\n",
      "\n",
      "Start of epoch 1251\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6170e-08 - val_loss: 2.2182e-08\n",
      "\n",
      "Start of epoch 1252\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.6154e-08 - val_loss: 2.2138e-08\n",
      "\n",
      "Start of epoch 1253\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.6120e-08 - val_loss: 2.2134e-08\n",
      "\n",
      "Start of epoch 1254\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6106e-08 - val_loss: 2.2075e-08\n",
      "\n",
      "Start of epoch 1255\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6074e-08 - val_loss: 2.2035e-08\n",
      "\n",
      "Start of epoch 1256\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.6040e-08 - val_loss: 2.2012e-08\n",
      "\n",
      "Start of epoch 1257\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.6017e-08 - val_loss: 2.1971e-08\n",
      "\n",
      "Start of epoch 1258\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5984e-08 - val_loss: 2.1953e-08\n",
      "\n",
      "Start of epoch 1259\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5957e-08 - val_loss: 2.1908e-08\n",
      "\n",
      "Start of epoch 1260\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5919e-08 - val_loss: 2.1884e-08\n",
      "\n",
      "Start of epoch 1261\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5894e-08 - val_loss: 2.1847e-08\n",
      "\n",
      "Start of epoch 1262\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5869e-08 - val_loss: 2.1825e-08\n",
      "\n",
      "Start of epoch 1263\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5845e-08 - val_loss: 2.1783e-08\n",
      "\n",
      "Start of epoch 1264\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5820e-08 - val_loss: 2.1765e-08\n",
      "\n",
      "Start of epoch 1265\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5798e-08 - val_loss: 2.1718e-08\n",
      "\n",
      "Start of epoch 1266\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.5764e-08 - val_loss: 2.1692e-08\n",
      "\n",
      "Start of epoch 1267\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5739e-08 - val_loss: 2.1655e-08\n",
      "\n",
      "Start of epoch 1268\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5717e-08 - val_loss: 2.1651e-08\n",
      "\n",
      "Start of epoch 1269\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5698e-08 - val_loss: 2.1613e-08\n",
      "\n",
      "Start of epoch 1270\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5666e-08 - val_loss: 2.1601e-08\n",
      "\n",
      "Start of epoch 1271\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5651e-08 - val_loss: 2.1577e-08\n",
      "\n",
      "Start of epoch 1272\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5625e-08 - val_loss: 2.1563e-08\n",
      "\n",
      "Start of epoch 1273\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5614e-08 - val_loss: 2.1531e-08\n",
      "\n",
      "Start of epoch 1274\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5578e-08 - val_loss: 2.1514e-08\n",
      "\n",
      "Start of epoch 1275\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5563e-08 - val_loss: 2.1492e-08\n",
      "\n",
      "Start of epoch 1276\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5537e-08 - val_loss: 2.1474e-08\n",
      "\n",
      "Start of epoch 1277\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5520e-08 - val_loss: 2.1430e-08\n",
      "\n",
      "Start of epoch 1278\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.5492e-08 - val_loss: 2.1415e-08\n",
      "\n",
      "Start of epoch 1279\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5475e-08 - val_loss: 2.1364e-08\n",
      "\n",
      "Start of epoch 1280\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5439e-08 - val_loss: 2.1336e-08\n",
      "\n",
      "Start of epoch 1281\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5414e-08 - val_loss: 2.1300e-08\n",
      "\n",
      "Start of epoch 1282\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5383e-08 - val_loss: 2.1272e-08\n",
      "\n",
      "Start of epoch 1283\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5364e-08 - val_loss: 2.1231e-08\n",
      "\n",
      "Start of epoch 1284\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5338e-08 - val_loss: 2.1195e-08\n",
      "\n",
      "Start of epoch 1285\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5308e-08 - val_loss: 2.1150e-08\n",
      "\n",
      "Start of epoch 1286\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5283e-08 - val_loss: 2.1135e-08\n",
      "\n",
      "Start of epoch 1287\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5264e-08 - val_loss: 2.1095e-08\n",
      "\n",
      "Start of epoch 1288\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5228e-08 - val_loss: 2.1088e-08\n",
      "\n",
      "Start of epoch 1289\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5207e-08 - val_loss: 2.1024e-08\n",
      "\n",
      "Start of epoch 1290\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5178e-08 - val_loss: 2.1028e-08\n",
      "\n",
      "Start of epoch 1291\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5163e-08 - val_loss: 2.0991e-08\n",
      "\n",
      "Start of epoch 1292\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.5134e-08 - val_loss: 2.0989e-08\n",
      "\n",
      "Start of epoch 1293\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5119e-08 - val_loss: 2.0965e-08\n",
      "\n",
      "Start of epoch 1294\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5090e-08 - val_loss: 2.0926e-08\n",
      "\n",
      "Start of epoch 1295\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5065e-08 - val_loss: 2.0907e-08\n",
      "\n",
      "Start of epoch 1296\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5048e-08 - val_loss: 2.0869e-08\n",
      "\n",
      "Start of epoch 1297\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.5023e-08 - val_loss: 2.0854e-08\n",
      "\n",
      "Start of epoch 1298\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.5001e-08 - val_loss: 2.0816e-08\n",
      "\n",
      "Start of epoch 1299\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4977e-08 - val_loss: 2.0784e-08\n",
      "\n",
      "Start of epoch 1300\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.4949e-08 - val_loss: 2.0774e-08\n",
      "\n",
      "Start of epoch 1301\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4933e-08 - val_loss: 2.0723e-08\n",
      "\n",
      "Start of epoch 1302\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4908e-08 - val_loss: 2.0708e-08\n",
      "\n",
      "Start of epoch 1303\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4886e-08 - val_loss: 2.0686e-08\n",
      "\n",
      "Start of epoch 1304\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4865e-08 - val_loss: 2.0658e-08\n",
      "\n",
      "Start of epoch 1305\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.4846e-08 - val_loss: 2.0648e-08\n",
      "\n",
      "Start of epoch 1306\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4826e-08 - val_loss: 2.0581e-08\n",
      "\n",
      "Start of epoch 1307\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4799e-08 - val_loss: 2.0583e-08\n",
      "\n",
      "Start of epoch 1308\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4786e-08 - val_loss: 2.0548e-08\n",
      "\n",
      "Start of epoch 1309\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4759e-08 - val_loss: 2.0528e-08\n",
      "\n",
      "Start of epoch 1310\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4740e-08 - val_loss: 2.0479e-08\n",
      "\n",
      "Start of epoch 1311\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4717e-08 - val_loss: 2.0466e-08\n",
      "\n",
      "Start of epoch 1312\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4698e-08 - val_loss: 2.0433e-08\n",
      "\n",
      "Start of epoch 1313\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4673e-08 - val_loss: 2.0415e-08\n",
      "\n",
      "Start of epoch 1314\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4662e-08 - val_loss: 2.0395e-08\n",
      "\n",
      "Start of epoch 1315\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4638e-08 - val_loss: 2.0357e-08\n",
      "\n",
      "Start of epoch 1316\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4619e-08 - val_loss: 2.0342e-08\n",
      "\n",
      "Start of epoch 1317\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.4602e-08 - val_loss: 2.0327e-08\n",
      "\n",
      "Start of epoch 1318\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4584e-08 - val_loss: 2.0321e-08\n",
      "\n",
      "Start of epoch 1319\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4571e-08 - val_loss: 2.0289e-08\n",
      "\n",
      "Start of epoch 1320\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4549e-08 - val_loss: 2.0280e-08\n",
      "\n",
      "Start of epoch 1321\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4529e-08 - val_loss: 2.0273e-08\n",
      "\n",
      "Start of epoch 1322\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4511e-08 - val_loss: 2.0274e-08\n",
      "\n",
      "Start of epoch 1323\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4502e-08 - val_loss: 2.0244e-08\n",
      "\n",
      "Start of epoch 1324\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4475e-08 - val_loss: 2.0171e-08\n",
      "\n",
      "Start of epoch 1325\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4436e-08 - val_loss: 2.0130e-08\n",
      "\n",
      "Start of epoch 1326\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4407e-08 - val_loss: 2.0100e-08\n",
      "\n",
      "Start of epoch 1327\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4384e-08 - val_loss: 2.0079e-08\n",
      "\n",
      "Start of epoch 1328\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.4370e-08 - val_loss: 2.0067e-08\n",
      "\n",
      "Start of epoch 1329\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4349e-08 - val_loss: 2.0035e-08\n",
      "\n",
      "Start of epoch 1330\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4332e-08 - val_loss: 2.0031e-08\n",
      "\n",
      "Start of epoch 1331\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4315e-08 - val_loss: 2.0003e-08\n",
      "\n",
      "Start of epoch 1332\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.4293e-08 - val_loss: 1.9989e-08\n",
      "\n",
      "Start of epoch 1333\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4276e-08 - val_loss: 1.9937e-08\n",
      "\n",
      "Start of epoch 1334\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4252e-08 - val_loss: 1.9927e-08\n",
      "\n",
      "Start of epoch 1335\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4234e-08 - val_loss: 1.9853e-08\n",
      "\n",
      "Start of epoch 1336\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4203e-08 - val_loss: 1.9836e-08\n",
      "\n",
      "Start of epoch 1337\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4185e-08 - val_loss: 1.9795e-08\n",
      "\n",
      "Start of epoch 1338\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4158e-08 - val_loss: 1.9739e-08\n",
      "\n",
      "Start of epoch 1339\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4135e-08 - val_loss: 1.9740e-08\n",
      "\n",
      "Start of epoch 1340\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4126e-08 - val_loss: 1.9674e-08\n",
      "\n",
      "Start of epoch 1341\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4097e-08 - val_loss: 1.9673e-08\n",
      "\n",
      "Start of epoch 1342\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4081e-08 - val_loss: 1.9594e-08\n",
      "\n",
      "Start of epoch 1343\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4053e-08 - val_loss: 1.9584e-08\n",
      "\n",
      "Start of epoch 1344\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.4035e-08 - val_loss: 1.9546e-08\n",
      "\n",
      "Start of epoch 1345\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.4010e-08 - val_loss: 1.9534e-08\n",
      "\n",
      "Start of epoch 1346\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.4003e-08 - val_loss: 1.9522e-08\n",
      "\n",
      "Start of epoch 1347\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3981e-08 - val_loss: 1.9465e-08\n",
      "\n",
      "Start of epoch 1348\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3957e-08 - val_loss: 1.9463e-08\n",
      "\n",
      "Start of epoch 1349\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3944e-08 - val_loss: 1.9418e-08\n",
      "\n",
      "Start of epoch 1350\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3919e-08 - val_loss: 1.9392e-08\n",
      "\n",
      "Start of epoch 1351\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3903e-08 - val_loss: 1.9362e-08\n",
      "\n",
      "Start of epoch 1352\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3883e-08 - val_loss: 1.9303e-08\n",
      "\n",
      "Start of epoch 1353\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3859e-08 - val_loss: 1.9280e-08\n",
      "\n",
      "Start of epoch 1354\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3840e-08 - val_loss: 1.9236e-08\n",
      "\n",
      "Start of epoch 1355\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3806e-08 - val_loss: 1.9213e-08\n",
      "\n",
      "Start of epoch 1356\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3782e-08 - val_loss: 1.9164e-08\n",
      "\n",
      "Start of epoch 1357\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3754e-08 - val_loss: 1.9120e-08\n",
      "\n",
      "Start of epoch 1358\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.3728e-08 - val_loss: 1.9118e-08\n",
      "\n",
      "Start of epoch 1359\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.3711e-08 - val_loss: 1.9077e-08\n",
      "\n",
      "Start of epoch 1360\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3686e-08 - val_loss: 1.9064e-08\n",
      "\n",
      "Start of epoch 1361\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3667e-08 - val_loss: 1.9035e-08\n",
      "\n",
      "Start of epoch 1362\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3640e-08 - val_loss: 1.9003e-08\n",
      "\n",
      "Start of epoch 1363\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3615e-08 - val_loss: 1.8982e-08\n",
      "\n",
      "Start of epoch 1364\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3587e-08 - val_loss: 1.8937e-08\n",
      "\n",
      "Start of epoch 1365\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3563e-08 - val_loss: 1.8935e-08\n",
      "\n",
      "Start of epoch 1366\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3548e-08 - val_loss: 1.8900e-08\n",
      "\n",
      "Start of epoch 1367\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3522e-08 - val_loss: 1.8892e-08\n",
      "\n",
      "Start of epoch 1368\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3509e-08 - val_loss: 1.8867e-08\n",
      "\n",
      "Start of epoch 1369\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3491e-08 - val_loss: 1.8847e-08\n",
      "\n",
      "Start of epoch 1370\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3467e-08 - val_loss: 1.8786e-08\n",
      "\n",
      "Start of epoch 1371\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3444e-08 - val_loss: 1.8798e-08\n",
      "\n",
      "Start of epoch 1372\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3434e-08 - val_loss: 1.8754e-08\n",
      "\n",
      "Start of epoch 1373\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.3409e-08 - val_loss: 1.8749e-08\n",
      "\n",
      "Start of epoch 1374\n",
      "1984/1984 [==============================] - 0s 49us/step - train_loss: 1.3396e-08 - val_loss: 1.8729e-08\n",
      "\n",
      "Start of epoch 1375\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3377e-08 - val_loss: 1.8667e-08\n",
      "\n",
      "Start of epoch 1376\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3358e-08 - val_loss: 1.8674e-08\n",
      "\n",
      "Start of epoch 1377\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3340e-08 - val_loss: 1.8648e-08\n",
      "\n",
      "Start of epoch 1378\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3325e-08 - val_loss: 1.8633e-08\n",
      "\n",
      "Start of epoch 1379\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3305e-08 - val_loss: 1.8584e-08\n",
      "\n",
      "Start of epoch 1380\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3283e-08 - val_loss: 1.8540e-08\n",
      "\n",
      "Start of epoch 1381\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3258e-08 - val_loss: 1.8510e-08\n",
      "\n",
      "Start of epoch 1382\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3235e-08 - val_loss: 1.8483e-08\n",
      "\n",
      "Start of epoch 1383\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3219e-08 - val_loss: 1.8438e-08\n",
      "\n",
      "Start of epoch 1384\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3189e-08 - val_loss: 1.8428e-08\n",
      "\n",
      "Start of epoch 1385\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.3176e-08 - val_loss: 1.8404e-08\n",
      "\n",
      "Start of epoch 1386\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3160e-08 - val_loss: 1.8404e-08\n",
      "\n",
      "Start of epoch 1387\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3149e-08 - val_loss: 1.8383e-08\n",
      "\n",
      "Start of epoch 1388\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3133e-08 - val_loss: 1.8371e-08\n",
      "\n",
      "Start of epoch 1389\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3118e-08 - val_loss: 1.8365e-08\n",
      "\n",
      "Start of epoch 1390\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3105e-08 - val_loss: 1.8364e-08\n",
      "\n",
      "Start of epoch 1391\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3094e-08 - val_loss: 1.8330e-08\n",
      "\n",
      "Start of epoch 1392\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3077e-08 - val_loss: 1.8333e-08\n",
      "\n",
      "Start of epoch 1393\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3061e-08 - val_loss: 1.8295e-08\n",
      "\n",
      "Start of epoch 1394\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.3039e-08 - val_loss: 1.8268e-08\n",
      "\n",
      "Start of epoch 1395\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.3016e-08 - val_loss: 1.8251e-08\n",
      "\n",
      "Start of epoch 1396\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2995e-08 - val_loss: 1.8233e-08\n",
      "\n",
      "Start of epoch 1397\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2980e-08 - val_loss: 1.8242e-08\n",
      "\n",
      "Start of epoch 1398\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.2970e-08 - val_loss: 1.8220e-08\n",
      "\n",
      "Start of epoch 1399\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2956e-08 - val_loss: 1.8223e-08\n",
      "\n",
      "Start of epoch 1400\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2945e-08 - val_loss: 1.8221e-08\n",
      "\n",
      "Start of epoch 1401\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2935e-08 - val_loss: 1.8188e-08\n",
      "\n",
      "Start of epoch 1402\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2917e-08 - val_loss: 1.8190e-08\n",
      "\n",
      "Start of epoch 1403\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2912e-08 - val_loss: 1.8188e-08\n",
      "\n",
      "Start of epoch 1404\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2900e-08 - val_loss: 1.8161e-08\n",
      "\n",
      "Start of epoch 1405\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2885e-08 - val_loss: 1.8160e-08\n",
      "\n",
      "Start of epoch 1406\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2877e-08 - val_loss: 1.8147e-08\n",
      "\n",
      "Start of epoch 1407\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2865e-08 - val_loss: 1.8160e-08\n",
      "\n",
      "Start of epoch 1408\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2853e-08 - val_loss: 1.8128e-08\n",
      "\n",
      "Start of epoch 1409\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2839e-08 - val_loss: 1.8134e-08\n",
      "\n",
      "Start of epoch 1410\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 1.2828e-08 - val_loss: 1.8098e-08\n",
      "\n",
      "Start of epoch 1411\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2811e-08 - val_loss: 1.8087e-08\n",
      "\n",
      "Start of epoch 1412\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2798e-08 - val_loss: 1.8063e-08\n",
      "\n",
      "Start of epoch 1413\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2787e-08 - val_loss: 1.8063e-08\n",
      "\n",
      "Start of epoch 1414\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2775e-08 - val_loss: 1.8031e-08\n",
      "\n",
      "Start of epoch 1415\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2756e-08 - val_loss: 1.8018e-08\n",
      "\n",
      "Start of epoch 1416\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2746e-08 - val_loss: 1.8003e-08\n",
      "\n",
      "Start of epoch 1417\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2734e-08 - val_loss: 1.7967e-08\n",
      "\n",
      "Start of epoch 1418\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2707e-08 - val_loss: 1.7956e-08\n",
      "\n",
      "Start of epoch 1419\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2698e-08 - val_loss: 1.7946e-08\n",
      "\n",
      "Start of epoch 1420\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.2683e-08 - val_loss: 1.7908e-08\n",
      "\n",
      "Start of epoch 1421\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2665e-08 - val_loss: 1.7881e-08\n",
      "\n",
      "Start of epoch 1422\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2646e-08 - val_loss: 1.7869e-08\n",
      "\n",
      "Start of epoch 1423\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.2632e-08 - val_loss: 1.7873e-08\n",
      "\n",
      "Start of epoch 1424\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2622e-08 - val_loss: 1.7862e-08\n",
      "\n",
      "Start of epoch 1425\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.2610e-08 - val_loss: 1.7838e-08\n",
      "\n",
      "Start of epoch 1426\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2596e-08 - val_loss: 1.7838e-08\n",
      "\n",
      "Start of epoch 1427\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2586e-08 - val_loss: 1.7828e-08\n",
      "\n",
      "Start of epoch 1428\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2571e-08 - val_loss: 1.7790e-08\n",
      "\n",
      "Start of epoch 1429\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2556e-08 - val_loss: 1.7807e-08\n",
      "\n",
      "Start of epoch 1430\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2552e-08 - val_loss: 1.7788e-08\n",
      "\n",
      "Start of epoch 1431\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2536e-08 - val_loss: 1.7785e-08\n",
      "\n",
      "Start of epoch 1432\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2527e-08 - val_loss: 1.7783e-08\n",
      "\n",
      "Start of epoch 1433\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2517e-08 - val_loss: 1.7768e-08\n",
      "\n",
      "Start of epoch 1434\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2504e-08 - val_loss: 1.7750e-08\n",
      "\n",
      "Start of epoch 1435\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2491e-08 - val_loss: 1.7724e-08\n",
      "\n",
      "Start of epoch 1436\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2478e-08 - val_loss: 1.7716e-08\n",
      "\n",
      "Start of epoch 1437\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2466e-08 - val_loss: 1.7682e-08\n",
      "\n",
      "Start of epoch 1438\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.2453e-08 - val_loss: 1.7674e-08\n",
      "\n",
      "Start of epoch 1439\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2436e-08 - val_loss: 1.7642e-08\n",
      "\n",
      "Start of epoch 1440\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2423e-08 - val_loss: 1.7596e-08\n",
      "\n",
      "Start of epoch 1441\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2405e-08 - val_loss: 1.7528e-08\n",
      "\n",
      "Start of epoch 1442\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2376e-08 - val_loss: 1.7483e-08\n",
      "\n",
      "Start of epoch 1443\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2357e-08 - val_loss: 1.7466e-08\n",
      "\n",
      "Start of epoch 1444\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2338e-08 - val_loss: 1.7444e-08\n",
      "\n",
      "Start of epoch 1445\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2320e-08 - val_loss: 1.7417e-08\n",
      "\n",
      "Start of epoch 1446\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2308e-08 - val_loss: 1.7404e-08\n",
      "\n",
      "Start of epoch 1447\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2291e-08 - val_loss: 1.7378e-08\n",
      "\n",
      "Start of epoch 1448\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2273e-08 - val_loss: 1.7366e-08\n",
      "\n",
      "Start of epoch 1449\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2267e-08 - val_loss: 1.7353e-08\n",
      "\n",
      "Start of epoch 1450\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.2259e-08 - val_loss: 1.7364e-08\n",
      "\n",
      "Start of epoch 1451\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 1.2253e-08 - val_loss: 1.7345e-08\n",
      "\n",
      "Start of epoch 1452\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2241e-08 - val_loss: 1.7340e-08\n",
      "\n",
      "Start of epoch 1453\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2238e-08 - val_loss: 1.7343e-08\n",
      "\n",
      "Start of epoch 1454\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2224e-08 - val_loss: 1.7289e-08\n",
      "\n",
      "Start of epoch 1455\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2203e-08 - val_loss: 1.7268e-08\n",
      "\n",
      "Start of epoch 1456\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2190e-08 - val_loss: 1.7252e-08\n",
      "\n",
      "Start of epoch 1457\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2179e-08 - val_loss: 1.7213e-08\n",
      "\n",
      "Start of epoch 1458\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2160e-08 - val_loss: 1.7181e-08\n",
      "\n",
      "Start of epoch 1459\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2149e-08 - val_loss: 1.7152e-08\n",
      "\n",
      "Start of epoch 1460\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2131e-08 - val_loss: 1.7129e-08\n",
      "\n",
      "Start of epoch 1461\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2114e-08 - val_loss: 1.7100e-08\n",
      "\n",
      "Start of epoch 1462\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2103e-08 - val_loss: 1.7080e-08\n",
      "\n",
      "Start of epoch 1463\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2086e-08 - val_loss: 1.7058e-08\n",
      "\n",
      "Start of epoch 1464\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2074e-08 - val_loss: 1.7028e-08\n",
      "\n",
      "Start of epoch 1465\n",
      "1984/1984 [==============================] - 0s 46us/step - train_loss: 1.2062e-08 - val_loss: 1.6992e-08\n",
      "\n",
      "Start of epoch 1466\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2044e-08 - val_loss: 1.6977e-08\n",
      "\n",
      "Start of epoch 1467\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.2026e-08 - val_loss: 1.6923e-08\n",
      "\n",
      "Start of epoch 1468\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.2010e-08 - val_loss: 1.6885e-08\n",
      "\n",
      "Start of epoch 1469\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1992e-08 - val_loss: 1.6870e-08\n",
      "\n",
      "Start of epoch 1470\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1981e-08 - val_loss: 1.6840e-08\n",
      "\n",
      "Start of epoch 1471\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1968e-08 - val_loss: 1.6822e-08\n",
      "\n",
      "Start of epoch 1472\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1957e-08 - val_loss: 1.6820e-08\n",
      "\n",
      "Start of epoch 1473\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1943e-08 - val_loss: 1.6766e-08\n",
      "\n",
      "Start of epoch 1474\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1930e-08 - val_loss: 1.6767e-08\n",
      "\n",
      "Start of epoch 1475\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1923e-08 - val_loss: 1.6720e-08\n",
      "\n",
      "Start of epoch 1476\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1905e-08 - val_loss: 1.6687e-08\n",
      "\n",
      "Start of epoch 1477\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1886e-08 - val_loss: 1.6681e-08\n",
      "\n",
      "Start of epoch 1478\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.1880e-08 - val_loss: 1.6658e-08\n",
      "\n",
      "Start of epoch 1479\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1872e-08 - val_loss: 1.6641e-08\n",
      "\n",
      "Start of epoch 1480\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1864e-08 - val_loss: 1.6605e-08\n",
      "\n",
      "Start of epoch 1481\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1850e-08 - val_loss: 1.6585e-08\n",
      "\n",
      "Start of epoch 1482\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1836e-08 - val_loss: 1.6560e-08\n",
      "\n",
      "Start of epoch 1483\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1825e-08 - val_loss: 1.6535e-08\n",
      "\n",
      "Start of epoch 1484\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1814e-08 - val_loss: 1.6496e-08\n",
      "\n",
      "Start of epoch 1485\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1794e-08 - val_loss: 1.6455e-08\n",
      "\n",
      "Start of epoch 1486\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1778e-08 - val_loss: 1.6430e-08\n",
      "\n",
      "Start of epoch 1487\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1763e-08 - val_loss: 1.6399e-08\n",
      "\n",
      "Start of epoch 1488\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.1745e-08 - val_loss: 1.6386e-08\n",
      "\n",
      "Start of epoch 1489\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1736e-08 - val_loss: 1.6341e-08\n",
      "\n",
      "Start of epoch 1490\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1720e-08 - val_loss: 1.6329e-08\n",
      "\n",
      "Start of epoch 1491\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1708e-08 - val_loss: 1.6288e-08\n",
      "\n",
      "Start of epoch 1492\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1689e-08 - val_loss: 1.6266e-08\n",
      "\n",
      "Start of epoch 1493\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1675e-08 - val_loss: 1.6249e-08\n",
      "\n",
      "Start of epoch 1494\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1665e-08 - val_loss: 1.6244e-08\n",
      "\n",
      "Start of epoch 1495\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1646e-08 - val_loss: 1.6222e-08\n",
      "\n",
      "Start of epoch 1496\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1641e-08 - val_loss: 1.6222e-08\n",
      "\n",
      "Start of epoch 1497\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1628e-08 - val_loss: 1.6180e-08\n",
      "\n",
      "Start of epoch 1498\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.1614e-08 - val_loss: 1.6178e-08\n",
      "\n",
      "Start of epoch 1499\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1607e-08 - val_loss: 1.6175e-08\n",
      "\n",
      "Start of epoch 1500\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1602e-08 - val_loss: 1.6146e-08\n",
      "\n",
      "Start of epoch 1501\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1589e-08 - val_loss: 1.6148e-08\n",
      "\n",
      "Start of epoch 1502\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1582e-08 - val_loss: 1.6135e-08\n",
      "\n",
      "Start of epoch 1503\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1575e-08 - val_loss: 1.6119e-08\n",
      "\n",
      "Start of epoch 1504\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1562e-08 - val_loss: 1.6096e-08\n",
      "\n",
      "Start of epoch 1505\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1547e-08 - val_loss: 1.6082e-08\n",
      "\n",
      "Start of epoch 1506\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1541e-08 - val_loss: 1.6069e-08\n",
      "\n",
      "Start of epoch 1507\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1530e-08 - val_loss: 1.6059e-08\n",
      "\n",
      "Start of epoch 1508\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1523e-08 - val_loss: 1.6069e-08\n",
      "\n",
      "Start of epoch 1509\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1522e-08 - val_loss: 1.6061e-08\n",
      "\n",
      "Start of epoch 1510\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1523e-08 - val_loss: 1.6059e-08\n",
      "\n",
      "Start of epoch 1511\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.1520e-08 - val_loss: 1.6048e-08\n",
      "\n",
      "Start of epoch 1512\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1515e-08 - val_loss: 1.6049e-08\n",
      "\n",
      "Start of epoch 1513\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1513e-08 - val_loss: 1.6049e-08\n",
      "\n",
      "Start of epoch 1514\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1510e-08 - val_loss: 1.6050e-08\n",
      "\n",
      "Start of epoch 1515\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.1505e-08 - val_loss: 1.6047e-08\n",
      "\n",
      "Start of epoch 1516\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1510e-08 - val_loss: 1.6067e-08\n",
      "\n",
      "Start of epoch 1517\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1512e-08 - val_loss: 1.6074e-08\n",
      "\n",
      "Start of epoch 1518\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1511e-08 - val_loss: 1.6067e-08\n",
      "\n",
      "Start of epoch 1519\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1512e-08 - val_loss: 1.6077e-08\n",
      "\n",
      "Start of epoch 1520\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1509e-08 - val_loss: 1.6053e-08\n",
      "\n",
      "Start of epoch 1521\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1502e-08 - val_loss: 1.6050e-08\n",
      "\n",
      "Start of epoch 1522\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.1498e-08 - val_loss: 1.6036e-08\n",
      "\n",
      "Start of epoch 1523\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.1490e-08 - val_loss: 1.6012e-08\n",
      "\n",
      "Start of epoch 1524\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1478e-08 - val_loss: 1.5996e-08\n",
      "\n",
      "Start of epoch 1525\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1472e-08 - val_loss: 1.5982e-08\n",
      "\n",
      "Start of epoch 1526\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.1464e-08 - val_loss: 1.5960e-08\n",
      "\n",
      "Start of epoch 1527\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1458e-08 - val_loss: 1.5939e-08\n",
      "\n",
      "Start of epoch 1528\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1449e-08 - val_loss: 1.5920e-08\n",
      "\n",
      "Start of epoch 1529\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1439e-08 - val_loss: 1.5903e-08\n",
      "\n",
      "Start of epoch 1530\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1428e-08 - val_loss: 1.5882e-08\n",
      "\n",
      "Start of epoch 1531\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1425e-08 - val_loss: 1.5870e-08\n",
      "\n",
      "Start of epoch 1532\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1419e-08 - val_loss: 1.5848e-08\n",
      "\n",
      "Start of epoch 1533\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1406e-08 - val_loss: 1.5832e-08\n",
      "\n",
      "Start of epoch 1534\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1402e-08 - val_loss: 1.5822e-08\n",
      "\n",
      "Start of epoch 1535\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1398e-08 - val_loss: 1.5804e-08\n",
      "\n",
      "Start of epoch 1536\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.1387e-08 - val_loss: 1.5778e-08\n",
      "\n",
      "Start of epoch 1537\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1379e-08 - val_loss: 1.5760e-08\n",
      "\n",
      "Start of epoch 1538\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1365e-08 - val_loss: 1.5732e-08\n",
      "\n",
      "Start of epoch 1539\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1354e-08 - val_loss: 1.5716e-08\n",
      "\n",
      "Start of epoch 1540\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1340e-08 - val_loss: 1.5682e-08\n",
      "\n",
      "Start of epoch 1541\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1327e-08 - val_loss: 1.5656e-08\n",
      "\n",
      "Start of epoch 1542\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1310e-08 - val_loss: 1.5627e-08\n",
      "\n",
      "Start of epoch 1543\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1297e-08 - val_loss: 1.5614e-08\n",
      "\n",
      "Start of epoch 1544\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1284e-08 - val_loss: 1.5592e-08\n",
      "\n",
      "Start of epoch 1545\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1277e-08 - val_loss: 1.5551e-08\n",
      "\n",
      "Start of epoch 1546\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1253e-08 - val_loss: 1.5513e-08\n",
      "\n",
      "Start of epoch 1547\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.1231e-08 - val_loss: 1.5504e-08\n",
      "\n",
      "Start of epoch 1548\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1227e-08 - val_loss: 1.5493e-08\n",
      "\n",
      "Start of epoch 1549\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1221e-08 - val_loss: 1.5473e-08\n",
      "\n",
      "Start of epoch 1550\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1213e-08 - val_loss: 1.5476e-08\n",
      "\n",
      "Start of epoch 1551\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1206e-08 - val_loss: 1.5451e-08\n",
      "\n",
      "Start of epoch 1552\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1204e-08 - val_loss: 1.5445e-08\n",
      "\n",
      "Start of epoch 1553\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1197e-08 - val_loss: 1.5422e-08\n",
      "\n",
      "Start of epoch 1554\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1188e-08 - val_loss: 1.5398e-08\n",
      "\n",
      "Start of epoch 1555\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1175e-08 - val_loss: 1.5381e-08\n",
      "\n",
      "Start of epoch 1556\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1170e-08 - val_loss: 1.5355e-08\n",
      "\n",
      "Start of epoch 1557\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1160e-08 - val_loss: 1.5350e-08\n",
      "\n",
      "Start of epoch 1558\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1157e-08 - val_loss: 1.5310e-08\n",
      "\n",
      "Start of epoch 1559\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.1145e-08 - val_loss: 1.5305e-08\n",
      "\n",
      "Start of epoch 1560\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1142e-08 - val_loss: 1.5286e-08\n",
      "\n",
      "Start of epoch 1561\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1139e-08 - val_loss: 1.5277e-08\n",
      "\n",
      "Start of epoch 1562\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.1148e-08 - val_loss: 1.5276e-08\n",
      "\n",
      "Start of epoch 1563\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1168e-08 - val_loss: 1.5290e-08\n",
      "\n",
      "Start of epoch 1564\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1202e-08 - val_loss: 1.5319e-08\n",
      "\n",
      "Start of epoch 1565\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.1259e-08 - val_loss: 1.5430e-08\n",
      "\n",
      "Start of epoch 1566\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1383e-08 - val_loss: 1.5707e-08\n",
      "\n",
      "Start of epoch 1567\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1587e-08 - val_loss: 1.6274e-08\n",
      "\n",
      "Start of epoch 1568\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1816e-08 - val_loss: 1.6425e-08\n",
      "\n",
      "Start of epoch 1569\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 1.1729e-08 - val_loss: 1.5303e-08\n",
      "\n",
      "Start of epoch 1570\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.1144e-08 - val_loss: 1.4801e-08\n",
      "\n",
      "Start of epoch 1571\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0873e-08 - val_loss: 1.4721e-08\n",
      "\n",
      "Start of epoch 1572\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0815e-08 - val_loss: 1.4701e-08\n",
      "\n",
      "Start of epoch 1573\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0794e-08 - val_loss: 1.4698e-08\n",
      "\n",
      "Start of epoch 1574\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0782e-08 - val_loss: 1.4696e-08\n",
      "\n",
      "Start of epoch 1575\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0778e-08 - val_loss: 1.4679e-08\n",
      "\n",
      "Start of epoch 1576\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0768e-08 - val_loss: 1.4679e-08\n",
      "\n",
      "Start of epoch 1577\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.0769e-08 - val_loss: 1.4680e-08\n",
      "\n",
      "Start of epoch 1578\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.0779e-08 - val_loss: 1.4690e-08\n",
      "\n",
      "Start of epoch 1579\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0789e-08 - val_loss: 1.4679e-08\n",
      "\n",
      "Start of epoch 1580\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0797e-08 - val_loss: 1.4689e-08\n",
      "\n",
      "Start of epoch 1581\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0812e-08 - val_loss: 1.4688e-08\n",
      "\n",
      "Start of epoch 1582\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.0828e-08 - val_loss: 1.4681e-08\n",
      "\n",
      "Start of epoch 1583\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.0830e-08 - val_loss: 1.4645e-08\n",
      "\n",
      "Start of epoch 1584\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0811e-08 - val_loss: 1.4585e-08\n",
      "\n",
      "Start of epoch 1585\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0769e-08 - val_loss: 1.4527e-08\n",
      "\n",
      "Start of epoch 1586\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.0733e-08 - val_loss: 1.4483e-08\n",
      "\n",
      "Start of epoch 1587\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0706e-08 - val_loss: 1.4456e-08\n",
      "\n",
      "Start of epoch 1588\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0689e-08 - val_loss: 1.4436e-08\n",
      "\n",
      "Start of epoch 1589\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0671e-08 - val_loss: 1.4420e-08\n",
      "\n",
      "Start of epoch 1590\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0661e-08 - val_loss: 1.4416e-08\n",
      "\n",
      "Start of epoch 1591\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0659e-08 - val_loss: 1.4414e-08\n",
      "\n",
      "Start of epoch 1592\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0656e-08 - val_loss: 1.4380e-08\n",
      "\n",
      "Start of epoch 1593\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0646e-08 - val_loss: 1.4383e-08\n",
      "\n",
      "Start of epoch 1594\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0650e-08 - val_loss: 1.4380e-08\n",
      "\n",
      "Start of epoch 1595\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.0658e-08 - val_loss: 1.4374e-08\n",
      "\n",
      "Start of epoch 1596\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0664e-08 - val_loss: 1.4381e-08\n",
      "\n",
      "Start of epoch 1597\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 1.0675e-08 - val_loss: 1.4349e-08\n",
      "\n",
      "Start of epoch 1598\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0680e-08 - val_loss: 1.4358e-08\n",
      "\n",
      "Start of epoch 1599\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0689e-08 - val_loss: 1.4324e-08\n",
      "\n",
      "Start of epoch 1600\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0678e-08 - val_loss: 1.4312e-08\n",
      "\n",
      "Start of epoch 1601\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0670e-08 - val_loss: 1.4283e-08\n",
      "\n",
      "Start of epoch 1602\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0653e-08 - val_loss: 1.4215e-08\n",
      "\n",
      "Start of epoch 1603\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0618e-08 - val_loss: 1.4194e-08\n",
      "\n",
      "Start of epoch 1604\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0601e-08 - val_loss: 1.4185e-08\n",
      "\n",
      "Start of epoch 1605\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0591e-08 - val_loss: 1.4164e-08\n",
      "\n",
      "Start of epoch 1606\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0566e-08 - val_loss: 1.4151e-08\n",
      "\n",
      "Start of epoch 1607\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0547e-08 - val_loss: 1.4138e-08\n",
      "\n",
      "Start of epoch 1608\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0541e-08 - val_loss: 1.4149e-08\n",
      "\n",
      "Start of epoch 1609\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0537e-08 - val_loss: 1.4121e-08\n",
      "\n",
      "Start of epoch 1610\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0519e-08 - val_loss: 1.4100e-08\n",
      "\n",
      "Start of epoch 1611\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 1.0508e-08 - val_loss: 1.4086e-08\n",
      "\n",
      "Start of epoch 1612\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0504e-08 - val_loss: 1.4085e-08\n",
      "\n",
      "Start of epoch 1613\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0498e-08 - val_loss: 1.4086e-08\n",
      "\n",
      "Start of epoch 1614\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0507e-08 - val_loss: 1.4106e-08\n",
      "\n",
      "Start of epoch 1615\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0515e-08 - val_loss: 1.4094e-08\n",
      "\n",
      "Start of epoch 1616\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0526e-08 - val_loss: 1.4125e-08\n",
      "\n",
      "Start of epoch 1617\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.0543e-08 - val_loss: 1.4135e-08\n",
      "\n",
      "Start of epoch 1618\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0563e-08 - val_loss: 1.4141e-08\n",
      "\n",
      "Start of epoch 1619\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0579e-08 - val_loss: 1.4161e-08\n",
      "\n",
      "Start of epoch 1620\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0602e-08 - val_loss: 1.4122e-08\n",
      "\n",
      "Start of epoch 1621\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0574e-08 - val_loss: 1.4102e-08\n",
      "\n",
      "Start of epoch 1622\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0551e-08 - val_loss: 1.4058e-08\n",
      "\n",
      "Start of epoch 1623\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 1.0528e-08 - val_loss: 1.4023e-08\n",
      "\n",
      "Start of epoch 1624\n",
      "1984/1984 [==============================] - 0s 40us/step - train_loss: 1.0475e-08 - val_loss: 1.4002e-08\n",
      "\n",
      "Start of epoch 1625\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 1.0454e-08 - val_loss: 1.3986e-08\n",
      "\n",
      "Start of epoch 1626\n",
      "1984/1984 [==============================] - 0s 48us/step - train_loss: 1.0435e-08 - val_loss: 1.3980e-08\n",
      "\n",
      "Start of epoch 1627\n",
      "1984/1984 [==============================] - 0s 49us/step - train_loss: 1.0415e-08 - val_loss: 1.4004e-08\n",
      "\n",
      "Start of epoch 1628\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0419e-08 - val_loss: 1.3969e-08\n",
      "\n",
      "Start of epoch 1629\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0398e-08 - val_loss: 1.3993e-08\n",
      "\n",
      "Start of epoch 1630\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0400e-08 - val_loss: 1.4013e-08\n",
      "\n",
      "Start of epoch 1631\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0396e-08 - val_loss: 1.4035e-08\n",
      "\n",
      "Start of epoch 1632\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 1.0401e-08 - val_loss: 1.4034e-08\n",
      "\n",
      "Start of epoch 1633\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0351e-08 - val_loss: 1.4077e-08\n",
      "\n",
      "Start of epoch 1634\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0326e-08 - val_loss: 1.4000e-08\n",
      "\n",
      "Start of epoch 1635\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0278e-08 - val_loss: 1.3940e-08\n",
      "\n",
      "Start of epoch 1636\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0244e-08 - val_loss: 1.3867e-08\n",
      "\n",
      "Start of epoch 1637\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0207e-08 - val_loss: 1.3831e-08\n",
      "\n",
      "Start of epoch 1638\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0185e-08 - val_loss: 1.3793e-08\n",
      "\n",
      "Start of epoch 1639\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.0162e-08 - val_loss: 1.3774e-08\n",
      "\n",
      "Start of epoch 1640\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0154e-08 - val_loss: 1.3749e-08\n",
      "\n",
      "Start of epoch 1641\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0151e-08 - val_loss: 1.3741e-08\n",
      "\n",
      "Start of epoch 1642\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0148e-08 - val_loss: 1.3735e-08\n",
      "\n",
      "Start of epoch 1643\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0143e-08 - val_loss: 1.3720e-08\n",
      "\n",
      "Start of epoch 1644\n",
      "1984/1984 [==============================] - 0s 39us/step - train_loss: 1.0161e-08 - val_loss: 1.3717e-08\n",
      "\n",
      "Start of epoch 1645\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 1.0156e-08 - val_loss: 1.3714e-08\n",
      "\n",
      "Start of epoch 1646\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0170e-08 - val_loss: 1.3724e-08\n",
      "\n",
      "Start of epoch 1647\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 1.0179e-08 - val_loss: 1.3731e-08\n",
      "\n",
      "Start of epoch 1648\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0210e-08 - val_loss: 1.3718e-08\n",
      "\n",
      "Start of epoch 1649\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 1.0194e-08 - val_loss: 1.3704e-08\n",
      "\n",
      "Start of epoch 1650\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0198e-08 - val_loss: 1.3669e-08\n",
      "\n",
      "Start of epoch 1651\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0191e-08 - val_loss: 1.3656e-08\n",
      "\n",
      "Start of epoch 1652\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0159e-08 - val_loss: 1.3607e-08\n",
      "\n",
      "Start of epoch 1653\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0139e-08 - val_loss: 1.3551e-08\n",
      "\n",
      "Start of epoch 1654\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0107e-08 - val_loss: 1.3555e-08\n",
      "\n",
      "Start of epoch 1655\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0086e-08 - val_loss: 1.3521e-08\n",
      "\n",
      "Start of epoch 1656\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0064e-08 - val_loss: 1.3480e-08\n",
      "\n",
      "Start of epoch 1657\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0045e-08 - val_loss: 1.3508e-08\n",
      "\n",
      "Start of epoch 1658\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 1.0026e-08 - val_loss: 1.3470e-08\n",
      "\n",
      "Start of epoch 1659\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0011e-08 - val_loss: 1.3473e-08\n",
      "\n",
      "Start of epoch 1660\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 1.0014e-08 - val_loss: 1.3497e-08\n",
      "\n",
      "Start of epoch 1661\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.9948e-09 - val_loss: 1.3472e-08\n",
      "\n",
      "Start of epoch 1662\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.9929e-09 - val_loss: 1.3457e-08\n",
      "\n",
      "Start of epoch 1663\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.9872e-09 - val_loss: 1.3501e-08\n",
      "\n",
      "Start of epoch 1664\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.9785e-09 - val_loss: 1.3451e-08\n",
      "\n",
      "Start of epoch 1665\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.9496e-09 - val_loss: 1.3446e-08\n",
      "\n",
      "Start of epoch 1666\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.9549e-09 - val_loss: 1.3478e-08\n",
      "\n",
      "Start of epoch 1667\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.9460e-09 - val_loss: 1.3452e-08\n",
      "\n",
      "Start of epoch 1668\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.9558e-09 - val_loss: 1.3464e-08\n",
      "\n",
      "Start of epoch 1669\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.9248e-09 - val_loss: 1.3442e-08\n",
      "\n",
      "Start of epoch 1670\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 9.9249e-09 - val_loss: 1.3409e-08\n",
      "\n",
      "Start of epoch 1671\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.9162e-09 - val_loss: 1.3440e-08\n",
      "\n",
      "Start of epoch 1672\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.9034e-09 - val_loss: 1.3400e-08\n",
      "\n",
      "Start of epoch 1673\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.9071e-09 - val_loss: 1.3412e-08\n",
      "\n",
      "Start of epoch 1674\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.8761e-09 - val_loss: 1.3375e-08\n",
      "\n",
      "Start of epoch 1675\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.8746e-09 - val_loss: 1.3346e-08\n",
      "\n",
      "Start of epoch 1676\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.8618e-09 - val_loss: 1.3379e-08\n",
      "\n",
      "Start of epoch 1677\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.8556e-09 - val_loss: 1.3331e-08\n",
      "\n",
      "Start of epoch 1678\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.8478e-09 - val_loss: 1.3343e-08\n",
      "\n",
      "Start of epoch 1679\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.8273e-09 - val_loss: 1.3292e-08\n",
      "\n",
      "Start of epoch 1680\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.8152e-09 - val_loss: 1.3276e-08\n",
      "\n",
      "Start of epoch 1681\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.8151e-09 - val_loss: 1.3288e-08\n",
      "\n",
      "Start of epoch 1682\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.7882e-09 - val_loss: 1.3277e-08\n",
      "\n",
      "Start of epoch 1683\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.8096e-09 - val_loss: 1.3278e-08\n",
      "\n",
      "Start of epoch 1684\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.7755e-09 - val_loss: 1.3260e-08\n",
      "\n",
      "Start of epoch 1685\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 9.7823e-09 - val_loss: 1.3219e-08\n",
      "\n",
      "Start of epoch 1686\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.7679e-09 - val_loss: 1.3259e-08\n",
      "\n",
      "Start of epoch 1687\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.7639e-09 - val_loss: 1.3245e-08\n",
      "\n",
      "Start of epoch 1688\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.7750e-09 - val_loss: 1.3232e-08\n",
      "\n",
      "Start of epoch 1689\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.7410e-09 - val_loss: 1.3199e-08\n",
      "\n",
      "Start of epoch 1690\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.7322e-09 - val_loss: 1.3176e-08\n",
      "\n",
      "Start of epoch 1691\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.7299e-09 - val_loss: 1.3174e-08\n",
      "\n",
      "Start of epoch 1692\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.7030e-09 - val_loss: 1.3179e-08\n",
      "\n",
      "Start of epoch 1693\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.7335e-09 - val_loss: 1.3157e-08\n",
      "\n",
      "Start of epoch 1694\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.6911e-09 - val_loss: 1.3152e-08\n",
      "\n",
      "Start of epoch 1695\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 9.7047e-09 - val_loss: 1.3132e-08\n",
      "\n",
      "Start of epoch 1696\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.7056e-09 - val_loss: 1.3152e-08\n",
      "\n",
      "Start of epoch 1697\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.6830e-09 - val_loss: 1.3153e-08\n",
      "\n",
      "Start of epoch 1698\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.6910e-09 - val_loss: 1.3113e-08\n",
      "\n",
      "Start of epoch 1699\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.6754e-09 - val_loss: 1.3133e-08\n",
      "\n",
      "Start of epoch 1700\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.6641e-09 - val_loss: 1.3126e-08\n",
      "\n",
      "Start of epoch 1701\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.6641e-09 - val_loss: 1.3109e-08\n",
      "\n",
      "Start of epoch 1702\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.6554e-09 - val_loss: 1.3105e-08\n",
      "\n",
      "Start of epoch 1703\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.6328e-09 - val_loss: 1.3107e-08\n",
      "\n",
      "Start of epoch 1704\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.6327e-09 - val_loss: 1.3079e-08\n",
      "\n",
      "Start of epoch 1705\n",
      "1984/1984 [==============================] - 0s 46us/step - train_loss: 9.6306e-09 - val_loss: 1.3071e-08\n",
      "\n",
      "Start of epoch 1706\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.6025e-09 - val_loss: 1.3039e-08\n",
      "\n",
      "Start of epoch 1707\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.5955e-09 - val_loss: 1.2992e-08\n",
      "\n",
      "Start of epoch 1708\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.5790e-09 - val_loss: 1.2981e-08\n",
      "\n",
      "Start of epoch 1709\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.5608e-09 - val_loss: 1.2951e-08\n",
      "\n",
      "Start of epoch 1710\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.5573e-09 - val_loss: 1.2910e-08\n",
      "\n",
      "Start of epoch 1711\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.5337e-09 - val_loss: 1.2881e-08\n",
      "\n",
      "Start of epoch 1712\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.5272e-09 - val_loss: 1.2847e-08\n",
      "\n",
      "Start of epoch 1713\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.5189e-09 - val_loss: 1.2862e-08\n",
      "\n",
      "Start of epoch 1714\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 9.5024e-09 - val_loss: 1.2849e-08\n",
      "\n",
      "Start of epoch 1715\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 9.5075e-09 - val_loss: 1.2824e-08\n",
      "\n",
      "Start of epoch 1716\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.4846e-09 - val_loss: 1.2813e-08\n",
      "\n",
      "Start of epoch 1717\n",
      "1984/1984 [==============================] - 0s 58us/step - train_loss: 9.4824e-09 - val_loss: 1.2770e-08\n",
      "\n",
      "Start of epoch 1718\n",
      "1984/1984 [==============================] - 0s 45us/step - train_loss: 9.4601e-09 - val_loss: 1.2768e-08\n",
      "\n",
      "Start of epoch 1719\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.4605e-09 - val_loss: 1.2744e-08\n",
      "\n",
      "Start of epoch 1720\n",
      "1984/1984 [==============================] - 0s 44us/step - train_loss: 9.4453e-09 - val_loss: 1.2743e-08\n",
      "\n",
      "Start of epoch 1721\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.4493e-09 - val_loss: 1.2717e-08\n",
      "\n",
      "Start of epoch 1722\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.4322e-09 - val_loss: 1.2715e-08\n",
      "\n",
      "Start of epoch 1723\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.4363e-09 - val_loss: 1.2699e-08\n",
      "\n",
      "Start of epoch 1724\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.4232e-09 - val_loss: 1.2692e-08\n",
      "\n",
      "Start of epoch 1725\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.4262e-09 - val_loss: 1.2674e-08\n",
      "\n",
      "Start of epoch 1726\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.4112e-09 - val_loss: 1.2682e-08\n",
      "\n",
      "Start of epoch 1727\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.4226e-09 - val_loss: 1.2666e-08\n",
      "\n",
      "Start of epoch 1728\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.4099e-09 - val_loss: 1.2660e-08\n",
      "\n",
      "Start of epoch 1729\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 9.4124e-09 - val_loss: 1.2658e-08\n",
      "\n",
      "Start of epoch 1730\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.4079e-09 - val_loss: 1.2658e-08\n",
      "\n",
      "Start of epoch 1731\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 9.4167e-09 - val_loss: 1.2650e-08\n",
      "\n",
      "Start of epoch 1732\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.4097e-09 - val_loss: 1.2658e-08\n",
      "\n",
      "Start of epoch 1733\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.4187e-09 - val_loss: 1.2635e-08\n",
      "\n",
      "Start of epoch 1734\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.4094e-09 - val_loss: 1.2639e-08\n",
      "\n",
      "Start of epoch 1735\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.4200e-09 - val_loss: 1.2629e-08\n",
      "\n",
      "Start of epoch 1736\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.4148e-09 - val_loss: 1.2603e-08\n",
      "\n",
      "Start of epoch 1737\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.4120e-09 - val_loss: 1.2571e-08\n",
      "\n",
      "Start of epoch 1738\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.4080e-09 - val_loss: 1.2569e-08\n",
      "\n",
      "Start of epoch 1739\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.4162e-09 - val_loss: 1.2526e-08\n",
      "\n",
      "Start of epoch 1740\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.3997e-09 - val_loss: 1.2492e-08\n",
      "\n",
      "Start of epoch 1741\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.4058e-09 - val_loss: 1.2478e-08\n",
      "\n",
      "Start of epoch 1742\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.4079e-09 - val_loss: 1.2446e-08\n",
      "\n",
      "Start of epoch 1743\n",
      "1984/1984 [==============================] - 0s 43us/step - train_loss: 9.4042e-09 - val_loss: 1.2404e-08\n",
      "\n",
      "Start of epoch 1744\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.3972e-09 - val_loss: 1.2379e-08\n",
      "\n",
      "Start of epoch 1745\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.3860e-09 - val_loss: 1.2338e-08\n",
      "\n",
      "Start of epoch 1746\n",
      "1984/1984 [==============================] - 0s 38us/step - train_loss: 9.3717e-09 - val_loss: 1.2320e-08\n",
      "\n",
      "Start of epoch 1747\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.3630e-09 - val_loss: 1.2288e-08\n",
      "\n",
      "Start of epoch 1748\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.3450e-09 - val_loss: 1.2264e-08\n",
      "\n",
      "Start of epoch 1749\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.3295e-09 - val_loss: 1.2247e-08\n",
      "\n",
      "Start of epoch 1750\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.3157e-09 - val_loss: 1.2233e-08\n",
      "\n",
      "Start of epoch 1751\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.3034e-09 - val_loss: 1.2205e-08\n",
      "\n",
      "Start of epoch 1752\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.2834e-09 - val_loss: 1.2196e-08\n",
      "\n",
      "Start of epoch 1753\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 9.2804e-09 - val_loss: 1.2205e-08\n",
      "\n",
      "Start of epoch 1754\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.2578e-09 - val_loss: 1.2176e-08\n",
      "\n",
      "Start of epoch 1755\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.2508e-09 - val_loss: 1.2150e-08\n",
      "\n",
      "Start of epoch 1756\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.2293e-09 - val_loss: 1.2135e-08\n",
      "\n",
      "Start of epoch 1757\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.2293e-09 - val_loss: 1.2140e-08\n",
      "\n",
      "Start of epoch 1758\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.2039e-09 - val_loss: 1.2113e-08\n",
      "\n",
      "Start of epoch 1759\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.2040e-09 - val_loss: 1.2078e-08\n",
      "\n",
      "Start of epoch 1760\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1850e-09 - val_loss: 1.2100e-08\n",
      "\n",
      "Start of epoch 1761\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.1765e-09 - val_loss: 1.2056e-08\n",
      "\n",
      "Start of epoch 1762\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1654e-09 - val_loss: 1.2026e-08\n",
      "\n",
      "Start of epoch 1763\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1564e-09 - val_loss: 1.2048e-08\n",
      "\n",
      "Start of epoch 1764\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1433e-09 - val_loss: 1.2004e-08\n",
      "\n",
      "Start of epoch 1765\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1358e-09 - val_loss: 1.1976e-08\n",
      "\n",
      "Start of epoch 1766\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1246e-09 - val_loss: 1.1988e-08\n",
      "\n",
      "Start of epoch 1767\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1175e-09 - val_loss: 1.1948e-08\n",
      "\n",
      "Start of epoch 1768\n",
      "1984/1984 [==============================] - 0s 41us/step - train_loss: 9.1079e-09 - val_loss: 1.1917e-08\n",
      "\n",
      "Start of epoch 1769\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.1024e-09 - val_loss: 1.1919e-08\n",
      "\n",
      "Start of epoch 1770\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.0915e-09 - val_loss: 1.1886e-08\n",
      "\n",
      "Start of epoch 1771\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.0934e-09 - val_loss: 1.1860e-08\n",
      "\n",
      "Start of epoch 1772\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.0896e-09 - val_loss: 1.1871e-08\n",
      "\n",
      "Start of epoch 1773\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.0880e-09 - val_loss: 1.1847e-08\n",
      "\n",
      "Start of epoch 1774\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.0933e-09 - val_loss: 1.1805e-08\n",
      "\n",
      "Start of epoch 1775\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.0894e-09 - val_loss: 1.1824e-08\n",
      "\n",
      "Start of epoch 1776\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1006e-09 - val_loss: 1.1807e-08\n",
      "\n",
      "Start of epoch 1777\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.1020e-09 - val_loss: 1.1785e-08\n",
      "\n",
      "Start of epoch 1778\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1039e-09 - val_loss: 1.1815e-08\n",
      "\n",
      "Start of epoch 1779\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1086e-09 - val_loss: 1.1801e-08\n",
      "\n",
      "Start of epoch 1780\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1219e-09 - val_loss: 1.1798e-08\n",
      "\n",
      "Start of epoch 1781\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1186e-09 - val_loss: 1.1818e-08\n",
      "\n",
      "Start of epoch 1782\n",
      "1984/1984 [==============================] - 0s 35us/step - train_loss: 9.1451e-09 - val_loss: 1.1835e-08\n",
      "\n",
      "Start of epoch 1783\n",
      "1984/1984 [==============================] - 0s 36us/step - train_loss: 9.1775e-09 - val_loss: 1.1916e-08\n",
      "\n",
      "Start of epoch 1784\n",
      "1984/1984 [==============================] - 0s 34us/step - train_loss: 9.2326e-09 - val_loss: 1.1975e-08\n",
      "\n",
      "Start of epoch 1785\n",
      "1984/1984 [==============================] - 0s 42us/step - train_loss: 9.2952e-09 - val_loss: 1.2096e-08\n",
      "\n",
      "Start of epoch 1786\n",
      "1984/1984 [==============================] - 0s 37us/step - train_loss: 9.3411e-09 - val_loss: 1.2161e-08\n",
      "\n",
      "Start of epoch 1787\n",
      "Validation loss did not improve for 10 epochs. Training stopped.\n",
      "Best Validation Loss : 1.1784924147661968e-08\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ad = AutoDecoder()\n",
    "ad.build(input_shape=(None, 64, 8))\n",
    "ad.summary()\n",
    "\n",
    "trainer = Trainer(model=ad,\n",
    "                  epochs=epochs,\n",
    "                  loss_function=loss_function,\n",
    "                  optimizer=optimizer,\n",
    "                  batch=batch_size)\n",
    "trainer.train(train_data=train_data,\n",
    "              valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graph(trainer.history, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 14:58:06.806715: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_pred = ad.predict(train_data)\n",
    "train_mse = np.mean(np.power(train_data - train_pred, 2), axis=1)\n",
    "threshold = train_mse.max()\n",
    "\n",
    "pred = ad.predict(test_data)\n",
    "\n",
    "mse = np.mean(np.power(test_data - pred, 2), axis=1)\n",
    "error_df = pd.DataFrame({\"reconstruction_error\" : mse, 'type' : test.type})\n",
    "error_df[\"reconstruction_error\"].plot(kind=\"hist\",bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7045\n",
      "1     344\n",
      "Name: label, dtype: int64\n",
      "\n",
      "type별 개수\n",
      "0    143\n",
      "6    101\n",
      "5     30\n",
      "2     27\n",
      "3     26\n",
      "4     13\n",
      "7      4\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sub = pd.read_csv(\"./data/answer_sample.csv\")\n",
    "\n",
    "error_df['label'] = 0\n",
    "\n",
    "index = error_df.reconstruction_error >= threshold\n",
    "error_df.iloc[index, 2] = 1\n",
    "\n",
    "sub[\"label\"] = error_df[\"label\"]\n",
    "\n",
    "print(sub[\"label\"].value_counts())\n",
    "print(\"\\ntype별 개수\")\n",
    "print(sub[sub.label == 1].type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "ori_test = pd.read_csv('./data/test_data.csv')\n",
    "ori_test[\"label\"] = sub[\"label\"].values\n",
    "\n",
    "outliers=sub.loc[ori_test['label']==1]\n",
    "outlier_index=list(outliers.index)\n",
    "\n",
    "pca = PCA(2)\n",
    "res = pd.DataFrame(pca.fit_transform(ori_test))\n",
    "\n",
    "plt.title(\"result - PCA\")\n",
    "b1 = plt.scatter(res[0], res[1], c='gray', s=20, label='normal')\n",
    "b2 = plt.scatter(res.iloc[outlier_index, 0], res.iloc[outlier_index, 1], c='red', s=20, edgecolor=\"red\", label='outliers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7015\n",
      "1     374\n",
      "Name: label, dtype: int64\n",
      "\n",
      "type별 개수\n",
      "0    143\n",
      "6    101\n",
      "3     50\n",
      "5     30\n",
      "2     27\n",
      "4     13\n",
      "1      6\n",
      "7      4\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_threshold = np.power(train_data - train_pred, 2).max(axis=0)\n",
    "\n",
    "error_df = pd.DataFrame({'anomalies' : (np.power(test_data - pred, 2) > col_threshold).sum(axis=1), 'type' : test.type})\n",
    "error_df[error_df['anomalies'] != 0] = 1\n",
    "\n",
    "sub = pd.read_csv(\"./data/answer_sample.csv\")\n",
    "\n",
    "sub[\"label\"] = error_df[\"anomalies\"]\n",
    "\n",
    "print(sub[\"label\"].value_counts())\n",
    "print(\"\\ntype별 개수\")\n",
    "print(sub[sub.label == 1].type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGzCAYAAAABsTylAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAACHNElEQVR4nO3deXhTZdo/8O9JmrXplnTf27RQlhYRoaKCG1oYN0ZQXMBlBGccxZ+DCzrOiM44g+K8Ou/oOzqCgoO41wU3FBUFEVqEQluW0qYbTfckbdomTdrk/P4oOTZtkqZt1vb+XFcvzTknJ08Wcu48z/3cD8OyLAtCCCGEkADE83cDCCGEEEKcoUCFEEIIIQGLAhVCCCGEBCwKVAghhBASsChQIYQQQkjAokCFEEIIIQGLAhVCCCGEBCwKVAghhBASsChQIYQQQkjAokCFEOJz27ZtA8MwqK2t9XdTCCEBjgIVQkhA+Pe//41t27Z55dzp6elgGIb7i42NxYIFC/DRRx85PP6jjz7CkiVLEB0dDaFQiMTERNx444347rvvHB7/xRdfgGEYJCYmwmq1euU5EDJZUaBCCAkI3gxUAOCcc87B9u3bsX37djz00ENobGzE9ddfj1deeYU7hmVZ3Hnnnbj++uvR0tKCdevW4ZVXXsG9996L6upqXH755fjpp5+GnXvHjh1IT09HU1OT02CGEDI2If5uACHEP3p6ehAaGurvZvhMUlISVq5cyd2+7bbbkJWVhRdeeAG/+93vAAD/8z//g23btuGBBx7A888/D4ZhuOMff/xxbN++HSEh9l+bPT09+OSTT7Bx40Zs3boVO3bswKJFi3zzpAiZBKhHhZBJ4MknnwTDMDhx4gRuueUWREVF4aKLLuL2v/nmm5gzZw4kEgnkcjluuukmnDlzxu4clZWVWLZsGeLj4yEWi5GcnIybbroJnZ2dAIDa2lowDOOwV4RhGDz55JNO25eeno7jx4/jhx9+4IZnLrnkEk88dafi4+Mxbdo01NTUAACMRiM2btyInJwc/OMf/7ALUmxWrVqFefPm2W376KOPYDQaccMNN+Cmm27Chx9+iN7eXq+2nZDJhHpUCJlEbrjhBmRnZ+Pvf/87WJYFAPztb3/Dn//8Z9x4441YvXo12tra8OKLL2LhwoUoKSlBZGQkzGYzCgoKYDKZsHbtWsTHx0OtVuOzzz5DR0cHIiIixtWuf/7zn1i7di1kMhkef/xxAEBcXNy4n68rfX19OHPmDBQKBQDgxx9/hFarxQMPPAA+n+/2eXbs2IFLL70U8fHxuOmmm/Doo4/i008/xQ033OCtphMyqVCgQsgkMmvWLLz11lvc7bq6OmzYsAFPP/00/vjHP3Lbr7/+esyePRv//ve/8cc//hEnTpxATU0N3n//fSxfvpw77oknnvBIu5YuXYo//elPiI6Othue8aS+vj60t7cDABobG7Fx40a0tLRg7dq1AICTJ08CAHJzc90+Z2trK7755hu8/PLLAIDU1FTMnz8fO3bsoECFEA+hoR9CJhFbLobNhx9+CKvVihtvvBHt7e3cX3x8PLKzs7Fnzx4A4HpMvvrqKxgMBp+32xO+/vprxMTEICYmBrNmzcL777+PVatW4dlnnwUA6PV6AEBYWJjb53znnXfA4/GwbNkybtvNN9+ML7/8EjqdzrNPgJBJinpUCJlEMjIy7G5XVlaCZVlkZ2c7PF4gEHD3W7duHZ5//nns2LEDCxYswLXXXouVK1eOe9hnLNra2mCxWLjbMpkMMpnM5X3y8/Px9NNPg2EYSKVSTJs2DZGRkdz+8PBwAEBXV5fb7XjzzTcxb948aDQaaDQaAMDs2bNhNpvx/vvv4+677x7FsyKEOEKBCiGTiEQisbtttVrBMAy+/PJLh3kZgy/+//M//4M77rgDn3zyCb7++mvcf//92LhxIw4ePIjk5GSHyacA7AIKT5k7dy7q6uq42xs2bHCZrAsA0dHRLmfj5OTkAADKysqwdOnSEdtQWVmJQ4cOAYDDQG/Hjh0UqBDiARSoEDKJKZVKsCyLjIwMTJkyZcTjc3NzkZubiz/96U/46aefcOGFF+KVV17B008/jaioKABAR0eH3X0GBxSuOAt0HNmxYweMRiN3OzMz0+37OnPRRRchKioKb7/9Nv74xz+OmFC7Y8cOCAQCbN++fdixP/74I/71r3+hvr4eqamp424bIZMZ5agQMoldf/314PP5eOqpp7hZQDYsy3LDGXq9Hv39/Xb7c3NzwePxYDKZAAwMnURHR2Pv3r12x/373/92qy2hoaHDghxnLrzwQixatIj780SgIpVKsX79epw8eRLr168f9noAA0M9xcXFAMANga1YsQLLly+3+3v44YcBAG+//fa420XIZEc9KoRMYkqlEk8//TQee+wx1NbWYunSpQgLC0NNTQ0++ugj3H333XjooYfw3Xff4b777sMNN9yAKVOmoL+/n+tJGJxIunr1ajzzzDNYvXo1zjvvPOzduxenT592qy1z5szByy+/jKeffhpZWVmIjY3FZZdd5q2n7tDDDz+M48eP43/+53+wZ88eLF++HPHx8WhubsbHH3+M4uJi/PTTTygqKkJVVRXuu+8+h+dJSkrCueeeix07dmD9+vU+fQ6ETDgsIWTC27BhAwuAbWtrc7i/sLCQveiii9jQ0FA2NDSUzcnJYe+99162oqKCZVmWra6uZn/zm9+wSqWSFYvFrFwuZy+99FL2m2++sTuPwWBg77rrLjYiIoINCwtjb7zxRra1tZUFwG7YsIE7buvWrSwAtqamhtvW3NzMXnXVVWxYWBgLgL344os99vzT0tLYq666yu3jP/jgA/bKK69k5XI5GxISwiYkJLArVqxgv//+e5ZlWXbt2rUsAFalUjk9x5NPPskCYI8dOzbu9hMymTEs66B/kxBCCCEkAFCOCiGEEEICFgUqhBBCCAlYFKgQQgghJGBRoEIIIYSQgEWBCiGEEEICFgUqhBBCCAlYQV/wzWq1orGxEWFhYaMqwU0IIYQQ/2FZFl1dXUhMTASP57zfJOgDlcbGRqSkpPi7GYQQQggZgzNnziA5Odnp/qAPVMLCwgAMPFHbMu2EEEIICWx6vR4pKSncddyZoA9UbMM94eHhFKgQQgghQWaktA1KpiWEEEJIwKJAhRBCCCEBiwIVQgghhASsoM9RcQfLsujv74fFYvF3UyY9Pp+PkJAQmkpOCCHELRM+UDGbzWhqaoLBYPB3U8hZUqkUCQkJEAqF/m4KIYSQADehAxWr1Yqamhrw+XwkJiZCKBTSL3k/YlkWZrMZbW1tqKmpQXZ2tssiP4QQQsiEDlTMZjOsVitSUlIglUr93RwCQCKRQCAQoK6uDmazGWKx2N9NIoQQEsAmxc9Z+tUeWOj9IIQQ4i66YhBCCCEkYE3ooR9CCCEkGOiKimAoK4M0Lw9R8+b5uzkBhXpUiEekp6fjn//8p7+bQQghQcWoVkOdl4eo889H0po1iMrPhzovD8bGRn83LWBQoEIIIYR4ga6oCOotW6ArLnZ6jHbJEiSUl9ttSygvh3bxYm83L2jQ0M8kYTabqW4JIYT4gFGthnbJEiSVlSHq7DZ1bi7ku3ZBkpjIHacrKkJSWdmw+/NYFkllZdAVF9MwEKhHxW0ajQaVlZXQaDQ+ebxLLrkE999/Px555BHI5XLEx8fjySef5PbX19fjuuuug0wmQ3h4OG688Ua0tLRw+5988kmcc8452LJlCzIyMrhpwAzD4D//+Q+uvvpqSKVSTJs2DQcOHEBVVRUuueQShIaG4oILLoBKpeLOpVKpcN111yEuLg4ymQxz587FN99845PXgRBCgo27vSQGB0GK3f7SUo+3LRhRoDICo9GIN998Ey+99BLeeustvPTSS3jzzTdhNBq9/thvvPEGQkNDUVRUhE2bNuEvf/kLdu/eDavViuuuuw5arRY//PADdu/ejerqaqxYscLu/lVVVSgsLMSHH36Io0ePctv/+te/4rbbbsPRo0eRk5ODW265Bb/97W/x2GOP4eeffwbLsrjvvvu447u7u/GrX/0K3377LUpKSrB48WJcc801qK+v9/prQAghwcTWS8JjWbvtg3tJbKS5uS7PJc3L80obgw0N/YygsLAQ1dXVdtuqq6tRWFiIlStXevWx8/LysGHDBgBAdnY2XnrpJXz77bcAgLKyMtTU1CAlJQUA8N///hczZszAoUOHMHfuXAADwz3//e9/ERMTY3feO++8EzfeeCMAYP369Zg/fz7+/Oc/o6CgAADw//7f/8Odd97JHT9r1izMmjWLu/3Xv/4VH330EXbu3GkX0BBCyGRnGDTc43B/aSk3nBOVnw91bi4SysvtAhsrw6Bp5kwk0bAPAOpRcUmj0UClUoEdEhmzLAuVSuX1YaC8IdF0QkICWltbcfLkSaSkpHBBCgBMnz4dkZGROHnyJLctLS1tWJAy9LxxcXEAgNxBkX1cXBx6e3uh1+sBDPSoPPTQQ5g2bRoiIyMhk8lw8uRJ6lEhhJAhRttLIt+1C00zZ9pta5o5E/JduzzetmBFPSouaLXaEfcrFAqvPb5AILC7zTAMrFar2/cPDQ0d8by2tY8cbbM91kMPPYTdu3fjH//4B7KysiCRSLB8+XKYzWa320IIIZPBaHtJJImJSCotha64GIbSUkjz8qgnZQgKVFyQy+Xj2u8t06ZNw5kzZ3DmzBmuV+XEiRPo6OjA9OnTPf54+/fvxx133IFf//rXAAZ6WGpraz3+OIQQMhHId+1C0+LFdjN6RuoliZo3j2b4OEFDPy4oFAoolcphKy4zDAOlUunV3hRXFi1ahNzcXNx66604cuQIiouLcdttt+Hiiy/Geeed5/HHy87O5hJyjx07hltuuWVUPTuEEDKZcL0kRUVQb948kGBbWmo3NZm4jwKVESxbtgyZmZl22zIzM7Fs2TI/tWggUPrkk08QFRWFhQsXYtGiRcjMzMS7777rlcd7/vnnERUVhQsuuADXXHMNCgoKcO6553rlsQghZKKImjcPSatXU0/JODHs0EzRIKPX6xEREYHOzk6Eh4fb7evt7UVNTY1dHZGx0mg00Gq1kMvlfutJmSg8+b4QQggJTq6u34NRjoqbFAoFBSiEEDIB0AKAwYUCFUIIIUFptAGHu6XtSWChQIUQQkhQGWvA4ay0fdPixUiicvUBi5JpCSGEBBxXKw+PZcXh0ZS2J4GFAhVCCCEBw6hWQ52Xh6jzz0fSmjUDBdTy8mBsbAQw9oCDFgAMXhSoEEIICRgj9ZaMNeCgBQCDFwUqhBBCAoI7vSVjDThspe2tQwp4WhkG6txcmv0TwChQIYQQEhDc6S0ZT8BBCwAGJ5r1QwghJCC421sylrV0AFoA0JVALmpKgcokwzAMPvroIyxduhS1tbXIyMhASUkJzjnnHH83jRAyybm78vB4Aw5aAPAXRqMRhYWFUKlU3DaxWIwZM2YgLCwMycnJUCqVfmwhBSoT1pNPPomPP/4YR48edXpMSkoKmpqaEB0d7buGEUKIC6PpLaGAY2QajQZ1dXVgWRbp6enDekuGBinAwDInhw8ftts2f/58XHnllV5vryMUqLjr9GlApQKysoDsbH+3xiP4fD7i4+PHdQ6z2QyhUOihFhFCJjsanvEMo9GI999/HzU1NXbbeTweZDIZcnJykJ2dPSxIcebAgQM4cOAAbr/9dqSnp3uhxc5RMu1ItFpg8WJg6lTgV78CpkwZuK3TefVhTSYT7r//fsTGxkIsFuOiiy7CoUOHAADbtm1DZGSk3fEff/wxmLPJZdu2bcNTTz2FY8eOgWEYMAyDbdu2DXuM2tpaMAxj1+tSXl6OJUuWQCaTIS4uDqtWrUJ7ezu3/5JLLsF9992HBx54ANHR0SgoKADLsnjyySeRmpoKkUiExMRE3H///R5/TQghkwetPDyyI0eO4MMPP0RJScmwfYWFhcOCFACwWq3Q6/UoLi7Gjh07Rv2Yb7zxxpjaOh7UozKSW24BvvnGfts33wA33wx4MVP8kUceQWFhId544w2kpaVh06ZNKCgoQFVV1Yj3XbFiBcrLy7Fr1y58c7btERERI96vo6MDl112GVavXo0XXngBRqMR69evx4033ojvvvuOO+6NN97APffcg/379wMY+Afxwgsv4J133sGMGTPQ3NyMY8eOjfGZE0ICha6oCJ2ffgqGYRB+zTUUNASIxsZGvPbaa7BarQCAsrIy7Ny5EzExMcjMzERWVpbbPSVjsW/fPixYsMBr5x+KAhVXTp8Gvvpq+HaLZWB7ZaVXhoF6enrw8ssvY9u2bViyZAkAYPPmzdi9ezdee+01xMTEuLy/RCKBTCZDSEjIqIZ2XnrpJcyePRt///vfuW2vv/46UlJScPr0aUyZMgUAkJ2djU2bNnHHfP7554iPj8eiRYsgEAiQmpqKefSFRkjQMqrV0C1ahMRTp7i1dPD002iaPh2Ru3fTAn5eptFouB7vtLS0YXklg4OUwdra2tDW1oaioiKvtq+6utqngYpXh35efvll5OXlITw8HOHh4Zg/fz6+/PJLbn9vby/uvfdeKBQKyGQyLFu2DC0tLd5s0uiMFJG60bsxtodVoa+vDxdeeCG3TSAQYN68eTh58qRXHhMAjh07hj179kAmk3F/OTk5XJts5syZY3e/G264AUajEZmZmVizZg0++ugj9Pf3e62dhJCxc7WGjo12yRIknDo1bHv8iRMu19Mh42M0GvHGG2/gpZdewmeffYZPP/0UL730EjZt2oRPP/0UKpUKR44ccRik+FJmZqZPH8+rPSrJycl45plnkJ2dDZZl8cYbb+C6665DSUkJZsyYgT/84Q/4/PPP8f777yMiIgL33Xcfrr/+em5Iwe9GmpKVleWbdgzB4/HADqnc2NfXN+7zdnd345prrsGzzz47bF9CQgL3/6GhoXb7UlJSUFFRgW+++Qa7d+/G73//ezz33HP44YcfIBAIxt0uQsj4ubvisK06rCMMwFWIpWEgzyssLERtbe2w7UajEUeOHMGRI0d83ygHfNmbAng5ULnmmmvsbv/tb3/Dyy+/jIMHDyI5ORmvvfYa3nrrLVx22WUAgK1bt2LatGk4ePAgzj//fG82zT1TpgAFBQM5KRbLL9v5fGDRIq/N/lEqlRAKhdi/fz/S0tIADAQihw4dwgMPPICYmBh0dXWhp6eHCxqGTkMWCoWwDG6zG84991wUFhYiPT0dISGj+2hIJBJcc801uOaaa3DvvfciJycHZWVlOPfcc0d1HkKIdzhbQ6dp8WIkDVofxzAokHHGUFpKgco4VFVV4dChQ+js7ERkZCTmzp2LyMhIr+aVeMrtt9/u88f0WY6KxWLB+++/j56eHsyfPx+HDx9GX18fFi1axB2Tk5OD1NRUHDhwwGmgYjKZYDKZuNt6vd67DX/77YHE2cG5KosWDWz3ktDQUNxzzz14+OGHIZfLkZqaik2bNsFgMOCuu+4Cy7KQSqX44x//iPvvvx9FRUXDZvWkp6ejpqYGR48eRXJyMsLCwiASiVw+7r333ovNmzfj5ptvxiOPPAK5XI6qqiq888472LJlC/h8vsP7bdu2DRaLBfn5+ZBKpXjzzTchkUi4IIsQ4l/OekkGr6FjCzxGqg4L0AJ+joyUVwIAWq0Wr776qt01rKWlBRUVFb5sqlvuu+8+dHR0YP/+/ejp6cHMmTN93pNi4/VApaysDPPnz0dvby9kMhk++ugjTJ8+HUePHoVQKBw2zTYuLg7Nzc1Oz7dx40Y89dRTXm71IFFRA7N7KisHclJ8VEflmWeegdVqxapVq9DV1YXzzjsPX331FaKiBn7rvPnmm3j44YexefNmXH755XjyySdx9913c/dftmwZPvzwQ1x66aXo6OjA1q1bcccdd7h8zMTEROzfvx/r16/HlVdeCZPJhLS0NCxevBg8nvN0psjISDzzzDNYt24dLBYLcnNz8emnnwZcGWZCgp2uqAiGsjJI8/JG1aMxUi/J4B4SW3XYxLIyMEOOYwE05uZSXZNBjEYj3nvvvWFDNqGhoZg6dSqmT5/OVXbdsmWLXZASqJRKJRQKBRQKhd+r0gIAww5NdvAws9mM+vp6dHZ24oMPPsCWLVvwww8/4OjRo7jzzjuHvWnz5s3DpZde6jBPAnDco5KSkoLOzk6Eh4fbHdvb24uamhpkZGRALBZ7/smRMaH3hZDRGZxfYuMov8QZXVERolwMp+uKiuwCH2Nj48CsnyHJ+5N11o+rdXDefPPNEYds+Hw+IiMjodFovNlMt1177bXQarXYv3//sHzHjIwM3HDDDZBIJF5vh16vR0REhMPr92Be71ERCoXIOpt0OmfOHBw6dAj/+7//ixUrVsBsNqOjo8OuV6WlpcXllFqRSDTiEAYhhEwk7uaXOOPuGjo2ksRESE6cgK64GJ07d3J1VBImWU+Ko3VwYmJikJqaiq6uLiQlJbmVV2KxWAImSJFIJJg9ezYA4PLLL3dryMrffF5HxWq1wmQyYc6cORAIBPj222+xbNkyAEBFRQXq6+sxf/58XzeLEEIC0mjyS1wZy4rDk30tncLCQlRXV9tts9UqAYDTp0/7o1lOXXvttQCAEydOOCwOKhQKsWbNGrtttiGeQObVQOWxxx7DkiVLuOjzrbfewvfff4+vvvoKERERuOuuu7Bu3TrI5XKEh4dj7dq1mD9/fmDM+CGEkAAwmvwSV2gNHdf27t2LmpoaZGZmYsGCBdBoNAEzCyckJGTE2lQ8Ho/rKbH9t6SkBKWlpRCJRJg7d25A5JuMhVcDldbWVtx2221oampCREQE8vLy8NVXX+GKK64AALzwwgvg8XhYtmwZTCYTCgoK8O9//9ubTSKEkKAy0iyc0c7AmSy9JEeOHEFtbS0yMjK4C7cj1dXV2L59O3e7trYW3333HeLi4nzRTLf87ne/AwDU1dWho6MD+/bts9vP4/GwevXqYfebPXu2y+ceLLyeTOttrpJxbEmb6enpPkkMIu4xGo3cFwgl0xIyMnVenvP8EjdyVCaToevg2CxZsgRRUVHDEmJ9Oot0DFJTU3HnnXcO215SUsJNSgjWYCRgkmn9yVYV1WAwUKASQAwGAwBQ1VoyIYx1yvBojCW/ZLJytg7O4OVbeDweUlJSRrUWmresXLkSer0eJSUlaG9vh9Fo5PYplUouh3OoidJb4o4JHajYpoS1trYCAKRSKRhmaGUA4issy8JgMKC1tRWRkZFOC8gREgzcLUnvCZRfMtyuXbtw4sQJ8Pl8pKamIjU1FT09PW6tg2O1WlFXV4e6ujoftNQ5iUTC5Y3Ygg5XU6Enqwk99AMMXBybm5vR0dHh+8YRhyIjIxEfH09BIwlqNBzjee5cpE+ePIn33nvPxy0bm5UrV6KzsxP19fUoLS21q1kikUiwZs0arojnZERDP2cxDIOEhATExsZ6ZOE+Mj4CgYB6UkjQ89SUYTLAUb2S1NRU5Ofno62tDcnJyVzPQ7AEKUqlkmvzueeei6VLl0KlUqGhocHu+ZCRTfhAxYbP59MFkhDiEZ6aMkwGOKpXUl9fj/r6erttgZR8HxcXB6FQiI6ODnR1ddntS09Pd5hbMjh4Ie6bNIEKIYR4iqenDE8GtgqoPT096OnpAQBMmTJlVKsG9/b2erOJbuPxeNyUYWDgudXV1YFlWaSnp1NuiYdRoEIIIaM02pL0k5mzRfsAoLi4OOBy1VauXAm1Wo2WlhaoVKph69ExDDOsZkkwVHcNZhSoEELIGNCU4V9oNBr88MMPUKvViIiIwIUXXsgNcRQWFjoMUmwCZT4HwzDIzMwcNjyj0Whw6NAh6HQ65OTkTJopwYFkws/6IYQQbxo8ZXiy5aUYjUb897//RXNz87B9PB4PiYmJaGho8EPLHFu5ciV++uknNDU1AYDDmiVUc8t3aNYPIYT4wEQuSW+bLqxSqVBTUwOpVIqLLrrIrrfEUZACDNQqCaQgxdZTMrS3hGqWBD4KVAghhNhxNF3YxjaMc/755wfMon3XXnst6urqUFZW5rDgm7NZOJRbEhwoUCGEkEmoqqoKpaWl0Gq16OvrQ1RUFLfCrqPpwkMdPHjQRy11TSKRcOXkbbVKTp8+DYZhEBMTQ7NwJgAKVAghAc8X6+lMZINfPzYrC5s3bx421be1tRUVFRVgGCZgElwBICcnBy0tLdDr9bBYLHb7xGIx1qxZY7eNapVMPBSoEEICli/X05koBs9SsbS1Yf5LL0FZWcm9flVZWcCyZYCTpNFAClKUSiVWrFjB3dZoNDh+/Dh6enowZcoUCkgmCZr1QwjxK1e9JbSejvuMRiN27NgBtVrNbbt1+3ZkVlcPe/2qMzOxY9UqfzSTc+2118JqtaKpqQmVlZXQ6/V2+9PT03HjjTfSLJwJjGb9EEIC2ki9JbSeznC2Cqitra0wGAyIjo7GjBkzoFAoUFhYaBekyNvbkeUg2ZXHsshSqSDXaKD1U+6GLa9kMKruSpyhQIUQ4nHu5JRolyxBQnm53baE8vKBImqlpbSeziBGoxHvv/8+ampqhu3bs2cPpFIpDAaD3Xa5TufynHKt1muBSmZmJqKionD8+PFhuTCO8koAmoFDnKNAhRDiMe7mlLjTWzKZ1tOx5V40Njaiu7sbAoEAeXl5XK9DYWGhwyDFZmiQAgDaKFdhHqCVy8fXaBdWnR1WuvrqqymvhIwbBSqEEI8ZqZfExp3ekqTVqyf8ejpGoxHvvPPOsFWCgYF6JTt37oRAIEBfX9+oz62NjkaVUuk0R2UsvSnnn38+amtrodPphq2BY3PTTTfZ3VYoFFi4cOGoH4sQGwpUCCEeMZqcEnd7SybCejq23Iuuri6EhYUhLS2NG+IoLCx0GKQMNpYgxaZw+XIs++ADu1yV6sxMFC5fPupzKZVKFBQUcLdts4sqKirQ39+PmTNn2u0nxFNo1g8hxCPUW7YgyUHuAbd/82YkDVp1djQzeoJxPR1XeSWhoaFIS0vDiRMnfNIWuUYzkJMilzvtSZk6dSqioqKgVqvR2tpq12NC6+AQb6BZP4QQAL4rljbanJLR9JYE6no6Go0G5eXlOHnyJAwGA5KSkrBo0SJuFo6zvJKenh6fBSkAoFUoXA718Hi8YUM2tA4OCRTUo0LIBDU4sdXG28XSxlL3JFh7S95++22cOXPG4X6hUAiz2ezjVjkXFxeHtrY2h+vg8Hg8rF69GgkJCX5oGZnM3L1+U6BCyATlj2JpxsZGaIf0kgRjJdmqqir8/PPP0Ol0EAgEUCgUyMvL42asvPnmmwGzIN9IJBIJHnnkEQCASqXi1vcJCQmxm1lEiK9RoELIJKYrKkLU+ee73u/F3otg7CUBAK1Wi1dffdXpjBZgoGKqbQVhf5syZQri4+Oxd+9eh/vFYjHuvvtuRI0wVZkQf6AcFUImMX8XSwvUnBIA2Lt3L06fPg2ZTIbs7Gy7KqhbtmxxGaQACJgghcfj4eabbwYAXHrppSgpKcGpU6fAMAwiIiKoZgmZMChQIWQCmkzF0txVXV2N7du3222rqKgAAERERGD+/PkwGo3+aJpDOTk5OHPmDHp6eobts+WVDDZ79mwaxiETEgUqhAQRd2fwROXnT/hiac4cOXIEFRUViIyMxLx587jekqFBymCdnZ3YFUC1WYauGqxSqXDo0CGYTCbKKyGTDgUqhAQBd0vTDzYRiqWNRmNjI1577TW7mS3FxcUICwtDamqqH1s23NSpUxEaGoqGhga0trba7cvIyMCyZcvstimVShrGIZMWJdMSEgTGM4MnWBNbh9JoNKitrQXDMHbVXW3++te/Opx+G2iUSiVWrlzJ3R7peREyUVEyLSF+5Mkia6MpTe9IICe2usNoNOK9994blsQqEomQlZWFjIwM9PT0BESQMmvWLDQ3N6OlpcXh/pSUlGG9JbRqMCGuUaBCiAeNZYhmJP6eweNtGo0Ge/fuRXNzM+Lj47Fw4UK7C3dhYaHDmTYmkwnHjx/H8ePHfdha55RKJZYuXcrd3rdvH44fPw6BQICsrCzMnDmTAhJCxoACFUJGYaSeEndXDx6NiTqDx2g0Yvv27WhqauK2tba2orS0FAzDQKlUIj8/P2AKq8lkMrAs63AWTnR09LCekgULFmDBggW+ah4hExblqBDiBnfK0XuzyJo/qsx6wpEjR3DkyBEAwJw5c+xmqwRTddeheSXvvvsu6urqEB0djeuuu456SggZA8pRIcSD3Okp8eYQTbDN4GlsbMSWLVsw+HeQWq3Gzp07cd5558FkMgVMkKJUKqHVaqHT6RzudzQLZ/DUYUKId1GgQsgI3E1m9eYQjSQxEUmlpXYzePxZC6WqqgqVlZXo7OwEy7LIycmx6y157bXX4Kyz9ueff/ZVM0ckkUi4nhLbasE8Hg8dHR00C4eQAOHVQGXjxo348MMPcerUKUgkElxwwQV49tlnMXXqVO6Y3t5ePPjgg3jnnXdgMplQUFCAf//734iLi/Nm0wgZkS0fpb+uzq2eEl8UWfP3DB6tVovNmzejt7fXbvvp06exc+dOxMfHQyKRBMQMHACYP38+Dhw44HCfUCjEmjVruNs0+4aQwOTVHJXFixfjpptuwty5c9Hf348//vGPKC8vx4kTJxAaGgoAuOeee/D5559j27ZtiIiIwH333Qcej4f9+/e79RiUo0I8zVE+iiuDc08mwurBe/fuxfHjxxEaGooLL7zQrtDYpk2bAqrMvCuD80r27duHI0eOoK+vD7GxscOeFyHE9wJy9eS2tjbExsbihx9+wMKFC9HZ2YmYmBi89dZbWL58OQDg1KlTmDZtGg4cOIDzXSQm2lCgQjzNUeKq7f+YQce5SmYNxiJrjtbCAYCQkBBcddVV0Ov12LNnjx9aNtzUqVNRWVnptOcmJSUFN998MyQSiY9bRghxV0Am03Z2dgIA5HI5AODw4cPo6+vDokWLuGNycnKQmprqNFAxmUx2q5vq9Xovt5pMJs7yURgHx7pKZvX3EI0jtryS0NBQzJgxY9gwh7O1cPr7+/HJJ5/4ooluUSqVuOmmmwAMrIHT0NAAHo+H7u5uSKVSqldCyATjs0DFarXigQcewIUXXoiZM2cCAJqbmyEUChEZGWl3bFxcHJqbmx2eZ+PGjXjqqae83VwySY00c6f28cchSE/3ezLraDjKK9mzZw9iY2MxZcoU6PV6dHV1+bGF9qKiopzOwElOTrabgUNr4BAy8fksULn33ntRXl6OH3/8cVzneeyxx7Bu3Trutl6vR0pKynibRwiAkYurRVx7bcD1lGg0GpSXl6OyshJ9fX2YOXOmXaGxLVu2DEt+BQaKqw1dEM/feDwe7r//fgC/rBjc3d2N5ORkzJ07l3pKCJmEfBKo3Hffffjss8+wd+9eJCcnc9vj4+NhNpvR0dFh16vS0tKC+Ph4h+cSiUQQiUTebjKZpHwxc8dTjEYj3nnnHdTX19tt/+677/Ddd98hIyMDubm5AZX8ahuPdmb16tXc/1NvCSEE8HKgwrIs1q5di48++gjff/89MjIy7PbPmTMHAoEA3377LdedW1FRgfr6esyfP9+bTSPEqUArruZsdd3CwsJhQcpgNTU1qKmp8VUzXWIYBpmZmVi5ciVXr6S6uhqVlZUICQlBfn6+XR0WQgix8eqsn9///vd466238Mknn9jVTomIiOCy8e+55x588cUX2LZtG8LDw7F27VoAwE8//eTWY9Csn4nDkysOe6Q9fp6542zVYB6Ph9jYWKd5XP5www034Msvv0R3d7fD/UqlEsuWLaNZOIQQTkBMT2YYR3MlgK1bt+KOO+4A8EvBt7ffftuu4JuzoZ+hKFAJfu6sozMRHTlyBBUVFYiKinKYfxEsa+EMrldiy5cxGAyIj4+HTCaDXC6n3BJCyDABEaj4AgUqwS9YF9wbK0fr4AAD9UrS0tKQkpKC5ORkvPnmm35qob3w8HCnZQASEhKwatUq6ikhhIxaQNZRIWQod9fRCSYajQZff/01NBoNsrOzUVBQYLff2To4/f39UKlUAdWLYust0Wg02Lt3L5fzkpGRgYULF1JPCSHE6yhQIeMy3rwSb6447GtGoxHbtm2zm/Kr0Whw8OBBJCYmQigUgmGYgFkHBxhY78ZsNjvcN3jVYIVCgV//+te+bBohhACgQIWM0eC8Elug0ZaSAusrryDuV79y+zzeXHHYG1ytg1NYWOi0LkljY6OvmjgqN954IyIjI3H8+HFoNBqIxWLExcXRqsGEkIBBOSpkTBzllXD7RpkIGww5Ks7WwQGAvLw8KBSKgFkHBxiYGTRSz41EIsEjjzzioxYRQog9ylEhXuMsr8Qmobx8oA6Jm0FGoNQt0Wg0OH78OHp6ejBlyhS73hJnQQoAlAZIMGUzOK9k3759qKqqQk9Pj90xEokEa9as8VMLCSHEfRSokFEbKa9ktImwksREJJWW2tUt8WUFWEcVXouLiwEAYrF42FpU/iSRSGAymZz2lgxeC0ehUGDp0qXcPtsCfsnJyVTxlRASNChQIaM2Ul6JzWgTYb254vCRI0dQW1uLjIyMYRVQXVV47e3tDZjCajwejxuqsVV3bW5uRkNDg9NaLINRSXpCSDCiHJUJxlfVXdV5eUgoKwNvhLb4e8ZOY2MjXnvttWE9EFlZWZBKpUhPT8fOnTv91Dp7oaGhw4ZobHg8HlavXo2EhAQft4oQQryDclQmGUezcLxZ3dVRXomNLxfwc5VXAsBhkAIAVVVVAAInv4TH4+Ghhx4CAHz11VeorKyEQCBAeHg4cnJyaB0cQsikRT0qE4S/Zs60fPEFePfcg5hBQye+KH/vbOVgAEhKSsKcOXPAsiw+/fRTr7VhNBISEtDU1ORwH/WWEEImIyqhP4noiooQdf75rvd7uXfDGwv42fIwHK0VEyzr4AxeNRgASkpKUFNTw00fdpQzQwghkwEN/UwigVDd1ZOJsEajEYWFhXaBSGhoKOLj4xEaGoq0tLSACVJCQkLQ39/vdH9mZiY3CwcAZs+eTYEJIYSMAgUqE0CwVXetqqqCWq12Ok12aJACAD09Pdy2QMkrsRVMs+XJnDhxAr29vUhPT8eMGTNo1WBCCPEAClSCwEgzeaLy86HOzXWeoxIga+VotVps2bIFRqPRbrtCocCFF16I2bNnQ6PRBExviStisZgrmKZQKLBw4UIsXLjQz60ihJCJh3JUAtjgmTw2zhJVjY2N0A6ZheOLpNbR2LRp07AgZSiBQIC+vj4ftci1a6+9FgBQU1OD0NBQGAwGAAMl86keCSGEjA/lqEwA2iVLkFBebrfNWXl6f1d3tdFoNDh06BBaWlogFAohFoshl8sRFhY2YpACwCdBSlhYGLq6ulwew+PxuFwSyikhhBD/oUAlQAwd3nG2ns5I5em9Vd21qqoKlZWVCA0NxYwZM4blXhiNRuzYsQNqtdrjj+0pg2fg2GYUqdVq/PDDD3bH2aYLE0II8T8KVDxstJVhnRVqs95+u99n8gADeSWbN29Gb28vt23Pnj0QCoXIysrCueeeC6VSicLCwoAOUgD7GTgKhQIKhQLZ2dm45JJLuGnDNF2YEEICC+WoeMho8kkGc1aorTUrC/GVlU7v58naKK6CK3fySgLJfffdh46ODpw+fRpSqRTJycmwWq00A4cQQgIM5aj42GjySWxcDe/EV1aiOSsLsSqV12byOOrN6ZZK0bZwIZg5c9Bz3nlBE6TYhnVsPSWU7EoIIRMDBSoeMNZ8kpEKtZl/9zs0vfGG3bmbZs6EfNcuTzR7ILga0m6ZwQDZrl3A2cdIEwpxIjcXzYmJqEtPh9aPvRLXXnstKioq0NnZCYPBAL1ez+0bWliNEELIxECBigeMtTLsSIXawhYsQNSDD457Jo8tEba9vR0mkwlTp07FTKHQYXA1lMxsxrzDh4HDhwEA1RkZeP/GG9ErkYy6HWNl6y0ZWtXVVYl9QgghEwMFKh4w1sqw7hZqczSTx52LtKNEWABQq9Wor6zErSM+s+Eyampw844d2OrhWTHnn38+Tp06BbPZDJZl7YacnPWW2IZ5CCGETFwUqHjAeCrDynftGshjcXN4x9E6OCKRCHK5HDExMXbFyLZs2TIsSLHRRrnqA3KOAZDa0AC5RuOxYSClUomCggIUFBRw26i3hBBCCECBiseMNuCwGVqozZKRAVNqKsQiERwNrrz33nuora2122YymdDU1ISmpiZuHRyRSASTyeT0cbXR0VAnJCCpqcnt5zjYnEOHsHvx4hGPu+yyy9DT04P29nY0Nzejp6fHbn96ejr1lhBCCHGKAhUPGW9lWHFuLj4/fRqqH3/ktvF4PDAMA7FYjPz8fEyfPn1YkOKMqyDF5s3bbsODzz2HEKvV7XbaRGm1Ix7D4/GwYMECu20ajQZ1dXVgWRbp6ekUjBBCCHGJ6qgEiDfffNMvi/FF6HT43SuvQOxGYDNY3ZNPQnbffdi3bx9qamrsZuAAv1R3TUhI8GRzCSGETBDuXr8pUPEhXVERWj/4AO0aDdRKJbri48GyLFJSUnDw4EG/ti1DpcKc4mJMqaiAwMVxLAALwzjshaHqroQQQtxFgUoAMarV0F5+OZIqKuy2+2OqrzsyVCpcXF6O0DNnIG9vB2/Qvn4eD9ovv0TslVf6rX2EEEKCH1Wm9QONRoPmvXvRcfgwtHI5ki+9FLNnz4Z2yRIkDglSgIGpvss++AA7Vq3ySft4PB6sbuSj8K68Emn//S93u+6pp4DvvgMuuwxpGzYg1puNJIQQQgahQMUDjEYjPtm6Fec9/zxmDMozqVIq8epll+FuJ4XVGABZKpVHp/q6cssttyAyMhIHDhxAaWkp+vr6hh2TkZExbBZO2oYNwIYNXm8fIYQQMhQFKm7QaDRQv/46LAcOoCktDbyCAsydO5ebsVJYWIjzn38emdXVdvfLrK6GdMh0XEfkWq3XAxWJRMLVV7n66qtx9dVXczNwurq6EBYWhrS0NJqFQwghJKBQoOKC0WjEZ//7v/jVX/6CvLOVUmcD6PnPf7D57rthTkxEdHQ0ekpKkOVgxg6PZZHY3Dzi42jlco+0d+XKldi/fz9qamrstkskEqxZs2bY8VSrhBBCSKCjQMWFwsJC/Povf4F0yArCUqMRa159Ff9Yvx5nzpxBlk7n8jyNCQlIaGoCM2Q7C0ClVHqkN0WpVHJ/AKBSqdDQ0IDk5GRaSZgQQkjQ4o18yOSk0WjA7tqFUKNxWIDBAAg1GpFxthdlpHL0n119NWrS04dtr8nIQOHy5SO25bLLLoPcRa+Lo+quSqUSF198MQUphBBCghr1qDih1WqRrFa7PCblzBnUKJXQRkejSqlEZnX1sLV+qjMz0ZSUhO133AG5RoO0s5Vl69LT3epJUSqVWLBgAVfhVaVS4fTp02AYBjExMVTdlRBCyITm1R6VvXv34pprrkFiYiIYhsHHH39st59lWTzxxBNISEiARCLBokWLUFlZ6c0muUWr1eLDDz9EQ1KSy+POpKRw/1+4fDmqMzPt9ldnZtr1mGgVCpTMmYOSOXNwy4YNuOyyy5Ceno7zzjsPERERw87vaAaOUqnEkiVLsHjxYsyZM4eCFEIIIROaV3tUenp6MGvWLPzmN7/B9ddfP2z/pk2b8K9//QtvvPEGMjIy8Oc//xkFBQU4ceIExGKxN5vmkm3V4ersbPRIJJAOGf5hARgkEtQMGlbplUiwY9UqyDWagVk8crnDHhOGYZCZmQmFQmHXUwIMDDfV1taCYRiagUMIIYTAh5VpGYbBRx99hKVLlwIY6E1JTEzEgw8+iIceeggA0NnZibi4OGzbtg033XSTW+f1dGXaqqoq7Nixg7sdodNhzauvInRQQm2PRILNd9+NThe5Keeffz70ej3q6ursVgxWKpVYtmwZJAFWjZYQQgjxpYCvTFtTU4Pm5mYsWrSI2xYREYH8/HwcOHDAaaBiMpnsVgYeuhjeeKmH5KV0RkXhH+vXI0OlQsqZM2hITR02xDMUj8dDQUEBd1uj0UCr1UIul1MvCSGEEDIKfgtUms/WF4mLi7PbHhcXx+1zZOPGjXjqqae81q4kJ3kpNUolapRKrFy5Er+KjMTBgwfx888/DzuOYRisXr3abhvVKyGEEELGJuhm/Tz22GNYt24dd1uv1yNlUFLreGVlZUEikcA4pHYKYF/d9aqrrsJVV12Fr776CuXl5RCJRLjwwgtp1WBCCCHEg/wWqMTHxwMAWlpakJCQwG1vaWnBOeec4/R+IpEIIpHIq21bs2YNNm/ebBesOKvuWlBQYDfMQwghhBDP8VugkpGRgfj4eHz77bdcYKLX61FUVIR77rnHX80CAERFReGRRx6h6q6EEEKIn3k1UOnu7kZVVRV3u6amBkePHoVcLkdqaioeeOABPP3008jOzuamJycmJnIzg/xtcEl6QgghhPieVwOVn3/+GZdeeil325Zbcvvtt2Pbtm145JFH0NPTg7vvvhsdHR246KKLsGvXLr/WUCGEEEJI4PBZHRVv8XQdFUIIIYR4n7vXb1qUkBBCCCEBiwIVQgghhAQsClQIIYQQErCCruAbIYQQ79AVFcFQVgZpXh6i5s3zd3MIAUCBCiGETHpGtRraJUuQVFYG21Kr6txcyHftgiQx0a9tI4SGfgghxIt0RUVQb9kCXXGxv5vilHbJEiSUl9ttSygvh3bxYj+1iJBfUI8KIYR4QbD0UuiKipBUVjZsO49lkVRWBl1xMQ0DEb+iHhVCCPGCYOmlMDgIUuz2l5b6qCWEOEaBCiGEeJitl4I3pJ7m4F6KQCHNzXW9Py/PRy0hxDEKVAghxMOCqZciKj8f6txcWBnGbruVYaDOzaVhH+J3FKgQQsYsGBJF/SHYeinku3ahaeZMu21NM2dCvmuXn1pEyC8omZYQMmrBkijqL7ZeioTycrvhHyvDoGnmTCQFWC+FJDERSaWl0BUXw1BaCmleXsC1kUxe1KNCSJAJhF6MYEkU9aeg7KUI4jVqA+HfBfEO6lEhJEgESi8GTWd1TzD1UgTKZ2ssgrntxD0UqBASJJz1YjQtXowkHyZnGgZdEBzuLy2lQGWwIOilCJTP1lh0XHEFEk+etNuWWFaG5iuugOT4cT+1yjPUW7ei/403wOvuRt/s2eAlJoI9cwaiiy9G4u232y15AJZ1uPzBRFgWgWHZIPhX5IJer0dERAQ6OzsRHh7u7+YQ4hW6oiJEnX++6/0++hIKpLYEssG/9G0C8Zd+ML+fnmq7rqgInZ9+CmtzM/gJCQi/5hqX91Nv3Qrzvn1cwOBqe+0TT4D54QfgssuQtmGDW8+r4/BhiC66CJLeXqfH9PN4CLFaHT+f6Gh03n8/BO+/P+7PnzcDHbev32yQ6+zsZAGwnZ2d/m4KIV7TsHkzyw78Nnf417B5s2/bk5vLWhjGrg0WhmEbcnN92o5AFiyvUcB9tl5/na2+9lpWtXo1qy0qYlmWZbUHD7INmzcPu119110u2177pz+5fCxDQwOrzslxeN/G6dNZg1ptd7zu55/ZHqnU7rgeqZRVv/328O0iEdvP49lt6+Px2JavvhrxNeiRSlmri+fFAiPud3SMFWCbpkxx630wNDQMfFYHfxZyc4e9JuPh7vWbAhVCgoD24EGXX0i2L3BfMajVXv8SC2aB9n65MlJbax5/3GF7G15/na2+805WvW2b0+0Nr7/O1l58MVt7ySXDjhtK9/PPbI9EMuzxDWLxsMBgpAu07a9u7lyn7WdZlm2cNs3pBd969jM9mEEsdnjxt/052j50Wz+P5/J1aHj9dbef31j/3Pn8+SLQpkCFkAkmkH6h++LXVjDzZi/F0N4F7jGHBA6jCRgcfbaGtfns++u0V+Gtt0YMInrEYrajpMTh83LWi+DoYj+Wi7N62jS7z+dIAdrQi7onA4jaJ590+v5W33mn1wMV1erVI37GxhvouIMCFUImGN3hww4vEM6++L0pkIKmQKI9eJCtvusutn7OnFF/0TsLQGycBYfNX3457HNhGeFCNTRgMKjVIwYZVoBtTUoaVa+Co3MYxOJhz80XvQhDe0hq//Qnt+5nCyprL77YY22pP/dcp5+hqtWrvf5aVF97rcvPsa+GA929ftOsH0L8ZLRJaj133IFwo9Fum9hohO622xDhw5kZgTQ92dFr6Op1dTZLYvD/j7btuqIidO3bB/GLLyK2vt7ljChHBd+MajU6L70U8ZWV3H3bUlNhffllxP3qV1yb+Zs2IaGqyu58CeXlYK+6CrwhSZX2xfCHk/T2AhdcABgMAIDeM2cQdfb/nWEAxKjVTve5gzn72I1vvGGXhGret8/NM4wdA9h9Pq1NTe7dTyAAALAs67G2mFNTne7jWSweexxnRNdf73J/oFVWpkDFwybCVLDJzBfv31jqPvg6OHD1Oox2evJoXlPbsUxICMxVVWAYxuEMDEevYWNODhgeDwknTgx7XbtKSsD8/veIGRJIOPp/d2dGOGrDSIYWfDOq1WCzsxE/JACNqa8HrroKBqkUUQaD0/NzqZpDjBQ4MACkRiMXMIz0nnpa39atwKBAxcrn++yxbZ9PJj7erePZvj4AgOCOO4C9ez3SBvljjzndJ1ywANi6deR2YeT3eegxLACjRGIXJDoScJWVPdJ/40eBMvRDY/YjG6lr25+P48v3z1ECnxUDswycGambeqTZDYMNzl0Y+lq58zqMNH7d/Pnn3LmasrNHPFfD5s1s82efDXvcwX9DZ2A4GnpylrzoKEFzpCECV++Fqza4+nOUG9KUlTViW3wxBOCLoRe7z+sll9i9Dr7Iy7D9DZ45NJrjWZZle5wMe/U5+ew52qbOzBzxs+XOrB93koqHDgGONFTc3t7Onj59mj18+DD70euvs6oR/v2Ol7vXb6qj4iHqvDzn0aePCyZ5slfAE+fyVT2J8TxO0/TpiD95ctivj+bp05HgomiUo9fHVkuBFQjA9PXZ1VQYbd0HR8/JmcZp0xD1zTdOn2vH4cMQLlwIqZMufnVuLnjd3YivqRn2OjRlZyPx9GluWz+fD77VOuwXHQugMTcX8i+/BJudDemQngLbaxr59dfDnhcL578QB78XI72GnuKqBsdY2lD3pz8h7a9/Hdc5PK169Wpkbt4M9ZYtSFqzxmeP27ht27D6I0m/+c2YzmX7xnWnd6ExN9fu+7hx+nQkDPl37+r4zqNHIbjwQrt/Q0axGHVr1kD22WdIrqnhtp+ZMgUhISFIOHHil23Tp+PwQw/BKBZDLBZDq9XCbDZDJpNBo9Ggt7cXISEhUHR1YcWmTZA6qKPSkpCAkt//Hg3x8ZCq1eDX1KA1PBw8Ph9R7e2QdHUhsrMTHeHhMISFQdrdjcjOTpxJSUGNUjnCqzScXKOBXKtFR0wMbnniCURFea7vzd3rNwUqHhAoBZPGcqF2Foh4MrjwZhA3eKhAvH49olpbHQYb4tdfR8fmzUBbG0TXX2/3JTmW98/R69OcnY2I+npITKZh5zBIpejbvx8dhYVIe/ppp49Vd8EFCH/hBe7xHAVQzjj6YrVrs1QKsdHoMhhw9Ti218Gdi0prSgpiz5xxur85KwuxKpXdZ8IduqIiGEpLfXJRHRpYDDaWC3vt448jfdB77+vgwBHbe+qpoGmkzxCLgQv7oV27UFtbCwDIy8tDamoqJKmpkBgMDoPfof+mB9/uEYuhjYlBiovPGwBUp6dj929/iw6GQW9vLxiGgchgwA3vvovMs22xOz4jA+/feCN6JZJh+zJUKmRUVyOzpgZJjY3c9rrUVBTPm4fmhARoFQoAv1zotXI5t81dGSoVplRUwMowaI+NRV16+rBzyNvbIdfpuPOLDQYsKyxElkrFHVOlVKJw+XKHz2W0br/9dqSnp4/7PID712/KUfGAkcZ3O3fu9EmgMpoy2CPlSYy3pLYtgEBIiMvciprrrrMLHEYqCW3bH5KQgP7HHhsxP4ABBn7RnH/+L8ft3AnDPfeg76efEHHOOdB/9pnLc+g//XTY++fo9YmrrHT6JS0xGIALLwT7hz+4eCQg7aefgPx8NE2fDt6mTUgYUhrclaHJgoOpt25F0pDeDUf3d0W3eTOi5s1zK/HRVZACAPFDkkLdpf/0U4RkZo7pvqPl6jfcSMmGjkRce+24z+HMSBdzR8fXpaTgv7t2gff11wgLC8M12dlIr6pyK3gcen4rw6A+ORkx7e0IdfE5M4rFePW3v0Xn999z22prayFvb0fKFVfgyi+/hNRstruPlWHAH9Qmg0SCXQUFkHd02PUSyDUapJ0NODojIhDR2YnQ7m70yGS/XOAH/YhgWRa9Egm233EHd99hxztRo1Tioh9/ROKgIAUAUuvrYeHzsX3QDyGtQjHqAGXw4zjrBXEWkPCsVqQPCbwyq6ux7IMPsGPVqjG1Y7A33ngDG9yssOspFKh4wEhfOOl/+xvUO3d6tXT2aJItdUVFYK+9FomtrXbH2tbH6H399TEnbo42wTBj504ucOhMSUHC6dMOExybpk0DCyDx5Elu23i6AiVGIzfrYaROxaH7nb3Wri4MDACpwQAmxL1/cvEnTkCzerVbxw7laK0d80cfjelcg/ErKwEATHLyuM81VizLAj6YFQEAPwB455lnwOPxIJVKwefzIRQKYTQaYTAYcL1Siczq6hEv7CyAmvR0bP/yS+DLLwEAfD4fLMviZqUSSpXK7V6usQYIQ9Wkp+P9FSvAsiwsFgs6Ojrw/vXXY9kHH9hd+JwxSCR2j1edmcn9Ys9QqZBy5gzOpKQAAPKOHQMAlM6aNeyi6+hiq05MRGN8PDojI3FyxgxoFQq7czq7cGsVChgkEocX75PTp7t8PqMNJuTt7cgcNMxjwwDIrKmBXKMZc3DirmWFhcisrrbblqlSgefgWB7LIkul8li79u3bhwULFoz7PO6iQMVHhvZGuJv7oSsqgv6zz2ApKwPDslzvw9A1Jbr27RtxJoY4KQkdV1zh9Fe6rfehboQeBsnChVBv2QL09nLt56ZQPvssEtz4oht2TqMRkkE5EEPFO2izu1MiHRk86wE8R/+0Bx17dnqizXhmSFjr66GJjYViSJDoqH3Rzc1jeoyh7QUANiZmTOcaTC2T4cSXXyLcakX6uM82Np91dYE9dgxr3Tze3fyFofdpjo2FXq+H6exraXQQBBQuX+7Whd0WFAxmORtsFS5f7nToARgeELgbINQolchQqTDt+HFk1tZCodVy96lLTcX7K1YMGwbolUiwY9Uqu6GKiI4O7pydkZF2QxjOhjSG9gK4yotwdLFNaGqCUSLBF4N6oFz1LIx0Pk/2Jtik1dW53l9b69VARd7e7vBz5/qbDAPvlwfaVVFRQYFKoBk8jNGvUg38quPzuVUsLe3tI164bL0RLZ9/PmzIojk7G7x//hN9jY1gQkLA9vcjJCEB1ocfRsKgHgQAwM6dsN5xB5Jst7duheH3v4dELnf5+NK8PHRccYXDC/5QlhESN0UmE5IG/aMfaQqlO9yZTukNln/9C0xYmMtjrAcO2N0eT5d9uV4P2QUX4NKPPx7zOUayZ/duVA268DEMgyip1O2LuzOHMzOhLS6GvLMTF45wbF1KClLPnHGYb1CTng4rn+9Wb8TQ+2nOfs6rHPRmWDEw9XLwhXwsnxsGQEJrK9a++KLLsX1HF3Zg4CIl7emBITR0xCGEoUMPANARGQm+1eo0IBhNgHDBTz8hSqeze8yUM2dcXrgH9y5oFQq7cw5+vPEMaQAuLrZj/PXv6fMFMvmQ99Rd2hGuE+5S+Ph1pEDFBbeGMbZuRT/j/tch/7e/ReyQoknxlZXAVVcNO9bZV/jQR5MYDE5ncgADiYsilnU734EZ4eLh6PGDVcqRIyMeE1ZcjGeeeQams+PbPB4PdyUkINHNglGD6cVi1EZF4dJR39N9Q7+MWJaFNjoatSkpSHMQPHDHATAIhZCazcOGG+pSUn65eEVHo8rJkAULQHX24u6op6DmbIIiALeHGYBfegFsHPVmVJ99XKnBALlWizC9Htd++qnTc+685hp0hYdzr9eyDz5AfHOzXfDjzq/xoRfssVwMXV30HZ3fnccI9Av3SBfb0f769/T5XKlLS3O930PJps5oR5h5Y2WYYZMXqjMzPfb8Fy5c6JHzuIsCFRc6rrgCiW5c3ENGMXMh2kllR0ecXVCGbh8pTCqdOhWmv/8d17j5uD+GhyPDzWPdefxgF63TIbSxEaaz/8itVis+u+oq3L1ly6jPZfsV7E7QoFIqkaBWQ9rb69ZrPNKX0bu33OIyOFAplfjs6qtx9Wef2R1jCzwGcxWI2HoghvYUDO1d2LFqFTKrqrDqzTedPqf955+PI3PnDntOjnozbMf0SiQDPQ/t7U7PO7Q98vZ2h4FnoFzUx8KXF+6xGOliO9pf/54+n8tzRUejOj0dGbW1w4L6mhF60Tz1+A57FRkGtWlpsPL59kH82SFCT0hISKAelUChKyoa1YyLQMY3GMDKZCMexwJoSEpCdVYWGsfYY+CIFYBZJILYwbTdYDH0S70pOXngi8JJ8tpQQ4MI6whJtbYLvqi3F2tefdWtRMmRvoycDVUMvdA7CwCGnmukQAQY+dd/dVaW0y/c6sxMfLN4scvn7LInwsWX+dCALtAv6mPhywv3WIzm/fHH+Uby/ooVwwJ/R0G9tzjsVRyUszSeadHOpKam4qabbvLIuUaD6qg4YDQa8eMdd+CK997zyPn8bec116AuLQ1rX3rJreOrlEr8eMEFuGP7do88vm2cf+0LL0AyZFjBZqSkR0f7RyoQ5up8o/Xi2rXD/rGLjUa3hy8G5zrI29tdvhf/XbVqWOKgLVGyIyICfKuVm0Y5NJ8hGDl6HT1V98Hdc4/0njh6/4PBrdu3O71wezK5dKw8/d5787PkjDcCgrE8fkd0NJCdDZlMBrFYjK6uLq6AHABIpVLExsait7cXDQ0N0Ol0sFqtkEgkkMvl6OnpgcVigVQqRX9/P7q7u8Hj8aBQKJCdnY0ZM2Z4vCeF6qiMw1tvvYWYUUz1c4eVYXAmJQVp9fUePa87bL90HXVVAsMv+Las+R6JBFIHBcLcmTJ5JiUFPy5YYPeP99V77nHaO1CTkQGwrNPZD472D50BYfecU1Nh5fHsjm+JjsapadNwsYs6IKMZ27X1UIw0fDE08Bjp1zt/yAJzgPuzHoKRq2EcX53b17/GfcXVr+5A4On3frTnk0gk4PF44PF4sFqtXCG4yMhIKBQKiMViiEQixMfHg2VZHD9+HGfOnAHLsoiMjIRIJIIpOhpaqxVCoRCKvj6EhIRAKpUCAMLCwiCVStHc3Ayj0QiJRAKxWIy2tjaYz9aLsVqtsFqt4PF4iIqKAsuy6Ojo4PYLhULwzs5MlEqliIyMREREBEJDQyGTyZCWlubzoRhfo0BlCI1Gg4aGBhhGSJYaLduXww3vvuswWHDEWY+Bo0DBWRLk4PHS91eswM07diC1ocHufEMfwzYu78zQ411NmRysMyoK/1i/3q53wCCT2X2ZjDQs4WwGhIXHQ2RHB4AhuQcOvrCSGhs9OrY70vDF0AAj0Lvk/WW8s0jGe+5Av6iPhScDgZCQELAsi5CQEEgkEjAMA6PRCPHZcvC9Z8u9m81mMAyD2NhYhIeHo729HdHR0VAoFGhoaEBUVBSys7OhVquh0WjAMAw0Gg3au7sBAPKzdWukUinkcjmsViuamprQ3t4Oq9UKmUwGqVSKrq4umEwmMAzD1bmxBQ96vR4WhoHEbEZcfz9MJhP4fD6ys7ORmZkJuVw+pov7ueeeO6bXjowPDf0M8eWXX6K4uBgAsGrbNreCClcBRVN8PApvuIH7chAbjbjhvfccFgsayiAWO1zroUcsRuig7VVOkiCddXnKNRrMOXQIyWfOIHUUyb2DDZ4x4WrKZCAaqXt4LM9ltF3Ogd4lP5l58rMsEAi4X8MymQwxMTEwmUxobW2F0WgEj8dDamoqzGYzdDodZDIZ0tPT0dvbi/b2dvT396O/vx/AwJTQeWdrLp0+fRqNjY3o6uqCWCzmega0Wi0MZ4sYisViSKVShISEIDo6GhqNBp2dnRCJROjq6kJfXx9kMhnCwsLQ1dUFg8EAPp8PmUwGi8UCPp+PrKwszJ07d8L/Yif+EVRr/fzf//0fnnvuOTQ3N2PWrFl48cUXuX+QI/F0oPLyyy+j9WwxLndzEIYGDjbVZws9ObpQDU1CBMD1DAytoeCotLOzL9PRfMmONC7vSrCO2Q/mjeDK3XP6Yyw9GERGRsJiscB6dvhLJpNxY+wKhQJ5eXlobGxEeXk5mLNlAQwGA6RSKeLj47mLe2hoKEJCQsDj8dDV1QWhUIiwsDCuF6Cvr4/7EwgEEAgE6DvbbW/7PhGJRJg6dSr0ej1OnjyJ7u5uCAQC8Pl89PX1gWEYKBQKyGQy6HQ6GAwGxMTEID4+HsnJyVBO0KE6QjwlaAKVd999F7fddhteeeUV5Ofn45///Cfef/99VFRUIDY2dsT7ezpQ2bJlC9RDehkcDS84Kso0mkJPgcLVL3sA9Kvfy8YTLMlkMhiNRq7Kqe1iLJVKYbVakZKSgszMTPB4PFRWVqKiogI9PT3cL2zbL+jMzEwYDAaYTCY0NDSgp6cHABAeHg6BQACxWAyLxYLW1lZYrVaEhIRAIBBwAQQAiEQiiEQihIWFQSgUoru7GxqNBv39/QMryCYkICsrC+3t7Thz5gwMBgN6e3shEomQkpKCWbNm0YWdkEkmaAKV/Px8zJ07Fy+d/WVv+4Jdu3YtHn300RHv7+lA5ciRI/jURZGoicbVL3tgeFGuifCrn8/nw2KxQCKRYNasWejo6EBzczM3Bs8wDHfhtVqtEIvF6O7uRmdnJ3cO2zh8ZGQkxGIxIiIi0NXVhba2NkilUqSnpyMmJgaRkZE4ffo0F/zKZDIwZ1dvjYiIgFgs5noEYmNjwTAMKioq0N3djejoaLS0tKCzsxPR0dGQSqUwmUzIy8vD7Nmz/fXyEUKIRwRFoGI2myGVSvHBBx9g6dKl3Pbbb78dHR0d+OSTT4bdx2QycRVCgYEnmpKS4tHpyU899ZRHzhNMnP2yF4lECGtuRmR7O7RyOaxKJdLS0lBdXQ2DwQCxWMwlt4WHh6OzsxNdXV0ICQlBfHw8AHDd8SaTCX19fQAAsViM5ORkLvHN1j1vNBrR0dGB0NBQREdHo7u7GwzDoLu7G93d3QOZ9QoF+Hw+eDweenp6YDabuXF8W7c8j8cDn8+H0WhESEgIkpOTMXfuXPrVTgghASIopie3t7fDYrEgLi7ObntcXBxOnTrl8D4bN270eiBx9913Y8uWLdw4+WgJhUIwDAOLxQKWZSGVSpGYmIjOzk5oNBrweDzIZDKuu902nW3w2Hx/fz83Di4UChESEsJl1UskEu5inJKSAqFQyCXDdXR0wGKxcGPpsbGxiImJ4bLzbd37ZrOZG8c3Go2AQoFeiQRSAOEhIfSrnRBCSEAIuunJjz32GNatW8fdtvWoeFJCQgL+/Oc/o6SkBDU1NQgNDeWm32m1WrvpdbW1tTAYDIiMjKRf7IQQQoiH+TVQiY6OBp/PR0tLi932lpYWbthgKFvugC/Mnj3bZa+CUqn0+eJMhBBCyGTizjIlXiMUCjFnzhx8++233Dar1Ypvv/0W8+fP92PLCCGEEBII/D70s27dOtx+++0477zzMG/ePPzzn/9ET08P7rzzTn83jRBCCCF+5vdAZcWKFWhra8MTTzyB5uZmnHPOOdi1a9ewBFtCCCGETD5+r6MyXt5YPZkQQggh3uXu9duvOSqEEEIIIa5QoEIIIYSQgEWBCiGEEEICFgUqhBBCCAlYFKgQQgghJGBRoEIIIYSQgEWBCiGEEEICFgUqhBBCCAlYfq9MG8g0Gg2Ki4uhVqshFAohFAqh0+nAMAzi4+MhFovBsixCQ0NRU1MDnU6HqKgoXHTRRbSKMiGEEOIBFKg4YDQasWPHDqjVaqfHDF3x2aazsxO1tbUAgMjISIhEIvT398NgMEAkEiE2NhZmsxkajQb9/f3g8/mQSqWIiopCREQEpkyZQkEOIYQQchYFKg4UFha6DFLc1dHRYXfbaDQO2wYA3d3daG1tBQAUFxcDAHJyctDV1QUASElJgVgshtFohE6nQ2dnJzo7O2G1WiEQCCASiXDOOedgwYIF425zoNMVFcFQVgZpXh6i5s3zd3MIIYR4Ga31M4RGo8FLL73kgZb5R3JyMkJDQ2EymSAWi9HV1YXOzk5YLBbweDwwDAOTyQSr1YqQkBDk5ORg6dKl/m72iIxqNbRLliCprIzbps7NhXzXLkgSE/3YMkIIIWPh7vWbelSG0Gq1/m7CuDQ0NLh9rMViwbFjx3Ds2DGEhIRAoVDAYDDAarUiKioKCoUCnZ2dMBgMEAgE6Ovrg9lsRmhoKLKzszFz5kwoFAovPptfaJcsQUJ5ud22hPJyNC1ejKTSUp+0gRBCiO9RoDKEXC73dxP8or+/3y7vpqenx2nQ09HRAbVaje+//x5SqRTp6emQyWQAgNbWVmg0GpjNZi4B2WQygWEYhIeHIzk5GRKJBMnJyW7n4uiKiux6Umx4LIuksjLoiotpGIgQQiYoClSGUCgUUCqVUKlU/m5KUDAYDDhx4oTDfSaTye52V1fXsNwfkUiExMRExMbGorW1FSzLIjMzE6GhoaioqEBLSwtSjx/H9a7aUFpKgQohhExQFKg4sGzZMrz11lujGkYhY2MymVBTU4Oamhpum23WlI1aLHZ5juMmE779739hMBgglUrR39+PtrY2MAwDqVQKs9kMlmUxc+ZMFBQUeONpEEII8RJKpnVBo9Hg0KFDaGhogFAohEgkgk6nAwC7OioikQjFxcXDehDI2Mjb2yHX6aCVy6E9mwNz6/btyKyuBm/Qx9XKMKjOzMSOVatGdf6kpCTIZDJ0d3ejt7cXISEh6O/vR1dXF6xWK0QiEQQCAfr7+xEaGor8/HzMnj3bo8+REEImO3ev3xSoeJBGo0FtbS3a2trQ2toKvV6PkJAQWCwW9PT0QCQSIS4uDmazGe3t7ejv7wfDMDAYDH5td6AQGwxYVliIrEHDblVKJQqXLwcALPvgA4f7eiUSn7TPVvMmISEBPB4PbW1tsFgsAAZ6hmwJySKRCCzLIicnhwIcQghxggKVIKNSqVBaWgqNRgOBQICIiAi0t7cD+KWOSm9vL7RaLTo7O6HX69Hf34/+/n4E+VvIcafXRK7RQK7V2vW2BLrs7Gz09/dzvXGRkZHo7+9Hd3c3oqKiMHPmTC55WSwWIy0tDWlpaT6bUUUIIf5AgcokotFocPz4cTQ2NnLbBtdRsQU1PB4PfD4fBoMB/f39fmzxcPL2dqx1Ub/mxbVrgyYw8RSxWIzk5GQYjUbo9XoYjUbw+XwkJiYiPT0dLMuCx+Ohu7sbjY2N0Ol0EIvFuPDCC6knhxAS8ChQISPSaDT45ptvUFdXBx6PB5lM5rCOitFo5PI4DAYDVzHXk7IqK3Hrjh1O9++49VZUZWd7/HEnsvDwcAgEAoSHh8NsNoNhGISGhoJlWZjNZojFYlitVrS3t0NcX4+47m5kLV6M6ddd5++mE0ImASr4RkakUCiwYsWKMd1XpVLh9OnTMJlMYFkWYrEYDMOgtbUV7e3tdnVUzGYzLBYLjEaj02EqbVSUy8fTTtL6NuOh1+sBDASkzgzLC3rlFVQplSj+wx9gEIlgNBoRExMDkUiE5uZmAIBQKATLskhJSUFmZibkcjkNUxFCvIZ6VAjHF+voqFQqHDt2jEs2BoCEhATExMRgyv/7f0ivrByeo6JUYsfKlR5th6OZRZORJ2ZTydvbseibbxDd1oaamTNx8s47IRKJ0N3djY6ODvT19UEkEiEmJgYhISFob2+HyWSCTCbDtGnTfFrhmBASOGjoh7gtUNbRMTY2Qrt4sdN2lJSU4NSpU+js7ITJZEJUVBTS09PR09ODtra2YXVUeDye3ZRywPXMIl/NHgoU480LEhsMWPnf/yLpbE+LDQvgzZtvRvXUqW63xVbzBgBYloVEIkF0dDSEQiGio6MBADU1NdDr9ejr64NUKqVp44QEOQpUiNvUeXlIKC8f9qu6aeZMv6yjoysuhqG01K5nZ7y9PSqVCocOHcK8J55AelXVsOdak5WF9+68E1arlSv7b5t6PFGNNy/o1u3boVSpwAzZbntl//Lkk+NuozvCw8MhkUjQ1dWFvr4+WK1W8Hg8iMViZGZmIioqCk1NTWBZFgaDAUajEdnZ2VT8jxA/oxwVD/HFcIg/BeI6OlHz5nGPObi3x5bFMpbeHqVSCXl7O6IqK4ft47EslJWV+N3ll9s9V41Gg7q6OnR3d6OsrAwdHR2QSCTD6qgwDMMVjlMoFAgJCUFDQwN6e3vH9Tp423jyguTt7Xa9UoPZApfLv/oK3/ogGNDr9dwwoo3FYkFfXx+OHTvm8D4ajQYHDx5EdnY2JBIJJBIJpFIpQkND0dPTg/b2doSGhsJgMECr1aKvrw+RkZGYO3eu22tUEUI8gwIVJzx1gQx0hkHPz+F+P6+j48lVk0f7XBUKBZc7sXDhwlE9FjBwMSwvL4dWq0V3dze3MrezOipVVVWor68f9eOMlTY6GlVKpdMcFVfDPvJBw2nOKFUqfOuRlnpPpYPA1ZmWlhZUVFQAADIzMxEWFobe3l5u0c2wsDAoFAq0t7dz7zWPx0NPTw8iIiJw4YUXUpBDyBhQoOKEJy+QgUyam+t6f16ej1oy3Hh6exz1hPn6uSoUClx88cVuH79gwQIAQElJCUpLS8EwDEQiEVcLZ3AdlYyMDG6Io7u7G3V1dXarX7urcPnyYRV/qzMzuWrAzozUGwMAqgl8Ua6urh7V8VqtFjU1NWAYBlOmTIFQKER3dzd6enogEAjQ19cHnU4Hi8UCkUjEVTeOj4/HlClTqAAgmdQoUHEgEIdDvCUqPx/q3FznOSp+fJ5j6e1x1RMWyM91sNmzZ485SVSlUqGhoQE6nQ5nzpwBwzDD6qjYhqrEYjFMJhN2rFo16oq/tt4YVzkqvhj2CTYsy3K9Ms4YjUYYjUYAQGdnJ3d8SEgIEhMTwefzodVqIRaLMWPGDHR3d6O2thYWiwVhYWEIDw/nhsLy8vIo4ZgEPQpUHAj04RBPk+/aNdBTNCg4a5o5E/Jdu/zYqrH1gIzUExaoz9VTlErlmIYXbEs49Gq1kLAsZDIZenp6YDAYEBMTA7FYjKamJjAMA4FAAJZlcfqppyB5+GEkNTUNO9+bN9/siadDBunv77cbGuzs7BzWiza0Zk5tbS127tyJ8PBwrgAgAISFhUEqlXJLcvT29kKhUCAtLQ21tbXQ6/WUcEwCBs36cUBXVISo8893vX8CBSo2jmbb+NtoZiSN5n0LxOcarOq//Ra969YhSq3m6qiIxWJ0d3dDp9Ohv78fQqEQMTExEAgEaG9vR3d3N602HiRCQkIgEAgQHR0Nq9WKjo4OAANLPPD5fBiNRphMJvD5fIhEIuTk5FCAQ9xC05PHKdCm7AYbT82WGqm2ymDqLVuQtGaN03OpN29G0urVY24L8bx9+/ahvLycq17MsixX6Tg6OhoikQgKhQIMw6C6uhodHR3chZIEttTUVPD5fAgEAvT390Oj0cBqtXL7+Xw++Hw+d5t6cCYfClTGydEFsnrKFJx+8klkz5tH2ftOeKt4nDs9IJO1J2wyUqlU+P7777mFGENCQtDd3Q2z2ey0jopt6KSvr8/fzScupKamQiwWw2w2c4nFLS0t0Gq1sFqtCAkJgUQiQWRkJEQiEUwmE2JjYzFv3jxKOA4yFKiMU3V1NbZv3+4yyTA0NBQymQyRkZGIiIjAlClTJn0A4++eKH8/Pgl8g+vj9PT0oLe3166OisFgQFtbm93/t7a2TvgCgBMBn8/nkscBIC4uDlarFS0tLbBarZDJZMjKykJsbCxqa2vBMAzy8vIm/fe2v1CgMk5PPfXUmO4nEAiQnJwMtVoNlmURFxeHSy65ZFL8QwiEHo3RDBURMhq2ujhNZ5OHxWLxsDoq0dHRXB2Vvr6+MU0ZJ/6RnJwMuVwOtVrNBaUmkwlSqRRJSUnQaDTo7u6GTCbDnDlzaDaVB1CgMg579+7Fnj17PHKuwZKTk2EwGNDX1wehUIhZs2ZxtTMmgkDKEaFkWRIobDOq9Ho9RCIRxGIxWJZFV1cXenp6IBKJYDabodVquToqAoEA3d3ddjkdJPBERUUhMjISLMuio6MDPT09sFqtXP4Nj8dDf38/LBYL+Hw+ZDIZoqOjkZiYiBkzZkz6oSq/Byp/+9vf8Pnnn+Po0aMQCoUOE+Dq6+txzz33YM+ePZDJZLj99tuxceNGhIS4P2vaG4HKG2+8gdraWo+cyx3JyclQKBSIioqCTCZDenp6UH6AA6FHhZCJRKPR4NChQ6ipqYHFYkF4eDgYhoFWq4VIJOLqqNTV1aG/vx9hYWGIiIhAa2sr1/NDApdUKkV4eDi6u7vBsiysVitEIhHi4+PR29sLhmG4tcfCw8ORlpY2oYr/+X2tH7PZjBtuuAHz58/Ha6+9Nmy/xWLBVVddhfj4ePz0009oamrCbbfdBoFAgL///e/eapZbMjIyfBqoNDQ0oKGhwW6bLRmwv78fUqkUs2fPDvgIPFgKqk1WE33dqolIoVBg8eLFY75/SUkJDh8+zOXhOKqjYqt6rFAoIJfL8fPPP3uq+WQEBoMBBoPBbpvRaHQ6s610UJ6dVCpFWFgYV9dIJBKhtbUVfX19iIqKQkxMDMxmM3Q6HQQCQVAPV3l96Gfbtm144IEHhr3wX375Ja6++mo0NjYiLi4OAPDKK69g/fr1aGtrg1AodOv8gZaj4m22suoCgQBJSUnIzs4OqAibckQCj7dmYpGJyxbg6PV6mM1m8Hg8REdHg2VZ6M6u82SbbWUwGLg6Knw+HwaDgYasAlhaWhoYhrGb/dbb2wuz2czVOrIFN0KhEDKZDLNmzfJKnqXfh35snAUqTzzxBHbu3ImjR49y22pqapCZmYkjR444jfxMJpNdoSi9Xo+UlBSPByq1tbV44403PHY+b5C3t0Ou00Erl6MzNhaxsbEQiUSIi4vD3Llz/Rq8UI5I4KCZUMTXVCoVjh07hu7ubq6Oii0Hx4bP54NhGOj1eppRFQSEQiF+97vfIcqNdb7c5fehn5E0NzdzPSk2ttvNzc1O77dx40af9Hakp6djw4YN2LdvHw4fPozOzk6vP6a7xAYDlhUW2i0kV6VUonD5cvRKJKitrUVRURE3VY/H43G1B3y19kfUvHkUoASAybRuFQkco13KQaPR4Pjx42hvbwePx+N+4QuFQqd1VGzbiW+YzWa89NJLeOihhyCRSHz62KMKVB599FE8++yzLo85efIkcnJyxtUoVx577DGsW7eOu23rUfGWBQsW2K1qW1RUxC34FRISwpUKty0i5gvLCguROWT11szqaiz74APsWLWK22axWLhuWhvb2h/Z2dkQi8VgGAZisXjMNWAo7yHwDH5PJtu6VSQ4KRQKLFy4cEz3tVU3tq1DZTQa0dvbC2Dgxy/Lsmhubraro8Lj8XDgwAFPPoVJwWq1Yvv27bj77rt9+rijClQefPBB3HHHHS6PyczMdOtc8fHxKC4utttmi47j4+Od3s9WqdAfXK1qq9FooNVqwePxUFRUhMrKSq+0Qd7ebteTYsNjWWSpVJBrNG6tfju0fcXFxWAYBhKJBLEdHYjv6YE5NRXJl17q8Dm7WqWY8h78w9F7YsrOdnkfRws7EhJMBv+YHI0rr7wS+/btw5EjR9DX14fY2FiEh4ejoaEBFouFW2VcKpUiOTkZ7e3t6OrqgsFgQH9/vxeeSXBoamqCRqPxaWrBqAKVmJgYxMTEeOSB58+fj7/97W9obW1FbGwsAGD37t0IDw/H9OnTPfIYvqRQKLg3ztYzodFosHv3brS0tCAsLAwMw6CxsXFcH3L5kB6SYfu1WrcCFUdEPT349X//O2xI6dnly5GSlwcej4fm5maIxWL86l//QvKpU3b3H7xKMfE9RytHx1ZVwSCVQmw00kwsQoYYa5Cj0Wiwb98+NDU1ITQ0FACg0+lc1lEZmsAazLRabeAGKqNRX18PrVaL+vp6WCwWLmk2KysLMpkMV155JaZPn45Vq1Zh06ZNaG5uxp/+9Cfce++9fusx8TSFQoGbbrpp2HZbCW+WZWEwGNDQ0ACBQMCV9XZFO0Iik1YuH3N7XQ4pDRqT5KtUSD15ctj9Ke/Bf1zlokgNBjRnZSG+qorb3jRzJuS7dvmyiYRMGAqFAkuXLh3TfUtKSrhpxhEREWhvb4der4fVanVYR8W2IGcgkY/jOjMWXgtUnnjiCbtZM7bhgz179uCSSy4Bn8/HZ599hnvuuQfz589HaGgobr/9dvzlL3/xVpMCxuDel6FsvTDNzc0wm83Dcl+00dGoUiqRWV097BdydWbmmHtTRjOkNFKvzhf/+hdazj0XUqkU+fn5QTt3P5iMlItiWb8eurw8biYW9aQQ4h+uUghcUalU2L9/P1pbW9Hf34+QkBCEhYUhJCSEq6PS1tYGs9nM1VHp6enxeJCjVCp9PqOUSugHAVsE3tvbi97eXvS1tmLpu+86nfUzFlmVlbh1xw6n+3fceiuqzuY7yNvbsfall5we++LatcMCpoULFyIiIgIVFRXo6elBcnKy36dQTyRUFZgQ4owtyDEYDIiKihq4jvT1gWEYsCzrsI4Kn8+HTqfjEpOBgSBl2bJlHpv1E/DTk4n7HEbgf/sbPv/nP9Fz7Bg6Y2JgTE5Gf1cXMMb8l9EMKY2lV2fv3r12t9VqNYqKirjCfrYp1KGhodQLMwZUFZgQ4sxop4sPZpsoIpfL/fbDknpUJhiNRoPi4mKo1Wr09/fDbDa7XVDp1u3bnQYfg6c9A4DYaMSyDz7waK/OUDNmzIBMJkNLSwtEIhHmzp07KVahHiuqCkwICSYBU5nW2yhQcY8tKu7u7kZzczNMJhOsVit6e3u5qcpjCT7kGs3ATCO5fMz5MaN1+eWXo6urCx0dHcjJyaHelyGoKjAhJBhQoEJGxba2R0dHByRqNSLb2nwafIyXQCCAWCxGTEwMt86Ir6rwEkIIGT0KVMi42KZQ19XVQa/XIzQ0FCqVyi6xKlgkJSVBp9OBZVmkpqbiiiuuoCReQgjxMwpUiFfY1uSoqamB0WiEQCBAX19f0K25YSu3HR4eDpFIBJlMRjkwhBDiQxSoEJ979913UVdXB4FAAABBW2r6nHPOgcFggFgsRl5eHgUvhBDiBRSokICg0WhQW1vLVVisqKhAd3c3QkJCUFdX5+/muc3W+5KVlUX1XwghxAMoUCFB4d1330VNTQ2sVmtQrYMRHR2NyMhItLe3g8/nIzk5GVFRUUhOTqYeGEIIcQMFKiQo7du3DxUVFRAKhYiJiUFHRwdOnz7t72aNWnR0NGz/tMRiMaZOnTqmxc8IIWSiokCFTChfffUVTp06hdDQUMyZMweVlZU46WBhxECXbjYjqbcXvcnJCJ8zBzNmzKBhJELIpESBCpkU9u3bhyNHjsBoNCIkJAT9/f0wmUz+btYwYoMBywoLHRbTs4SHIzExEVqtFr29veDz+Zg6deqYV2clhJBgQIEKmbSGVuFtb29HU1PTsJWofWk0yxMMFhUVhYiICDAMg7CwMJqFRAiZMGhRQjJpKRQKp8MpGo0Ghw4dwokTJ7gVRL1N3t5u15Niw2NZZKlUkGs0TisA63Q66HQ67nZpaSkYhkFubi7y8vIQGRnp9wXDCCHEmyhQIZOKQqHA4sWLsXjxYm5bSUkJioqKYDKZEB8fD5FIhGPHjnnsMeWDAg2H+7XaUS1VwLIsSktLUVpaaredz+dzSwlMmTIF8+bNo+CFEBL0KFAhk97s2bOHrQm0dOlSqFQqfP/992hrawMAyGQyJCcn4+TJkzCbzW6fXxsV5Xq/XD76RjtgsVhgsVjQ29uL4uJiFBcXg2EYhIaGgmEYREREIDs7mxJ4CSFBhXJUCBkDlUqF4uJitLa2wmq1Qq/Xuzx+rDkq3hIREYHQ0FC0tLSAx+NBLpcjLi6OcmAIIT5DybSE+FhJSQn2798Ps9mM0NBQGAwGLoARG41Y9sEHDmf99Eok/mqyU5GRkRCJREhPT6dKvIQQr6BAhZAAYcuBMRgMSOjuhlyrRRWA9hGGhAKJRCJBRkYGwsLCYDAYYDKZkJOTM2zIjBBC3EWBCiEBTqVS4dChQzCZTODxeGhtbUV3d7e/m+UWeXs75DodtHI5ZLNnIzExEZWVlTCbzZgxYwYKCgoAALqiIhjKyiDNy0PUvHl+bjUhJJBQoEKIh/j6YmubQt3Q0ACr1QqtVhswRexcFa4bPIQlNhiw7MMPkVVVxW2rmzYNsd98A0liok/bTAgJTBSoEDJORrUa2iVLkFRWxm1T5+ZCvmuXzy+2Go0Gx48fh0ajAcMwYFkWJ06cQH9/v0/b4W5SsKvj3r3zTggEAigUCkilUhpCImSSokCFkHFS5+Uhobx82MW2aeZMJA2pYeIvtuGjjo4OmEwmGI1Gr/W+yNvbsfall5zuf3HtWmgVCrePGyo3Nxdmsxnd3d1ISkqiOjCETHBUmZaQcdAVFdn1pNjwWBZJZWXQFRcHRM6FUql0OJ3YFsC0tbWhr68PFosFBoNhXI/lbuG6sRa4Kxvcc6VWo7i4GGFhYQgJCUFfXx9CQ0NpFhIhkxAFKoQ4YCgrg6s5OYbS0oAIVJxxFcCcPn0aUqkUKpUKarUaVqvVrXO6W7jOkwXuurq6uP/v7u5GS0sLioqKEBISgssuuwydnZ1oaGiAQqHAwoULKYAhZAKiQIUQB6S5ua735+X5qCWeNTiAufjii7ntKpUKP/74Izo6OsDn82GxWNDR0WF3X210NKqUSqe5J7ZeEnePG4/+/n58/fXX3G21Ws2tg5SQkID+/n4wDEM9MIRMAJSjQogTwZCj4m22Hpje3l4AgNRkQvYTTyCzspI7xuGsnwArcBceHo4pU6agvr4eFosFs2bNwoIFC3zeDkLILyiZlpBxMjY2Qrt4cUDM+gk0uuJiVO3ahRo+H+a0NDQ3N6Onp2fYcXKNZiAnRS73SE+Kp8XHx6O7uxsikQhJSUm0hAAhPkSBCiEeoisuhqG0lIqWjcBW/6WlpQVisRgdHR3cWkjBRqFQQKFQQC6XQywWIzk5mQIYQjyMAhVCgsxEreKq0Wig1WrB4/Gwf/9+nDlzxuf1XzwlMzMTISEhMBgMYFkWU6dOpSEkQsaIAhVCgkQgFZbzJZVKhdLSUmi1WoSEhCA+Ph46nQ7d3d0ICwvDqVOn/N1EtykUCoSEhKCzsxMCgQBz586lAIaQEVCgQkiQoKRd5/bt24djx46hq6sLZrPZ380Ztbi4OEilUpjNZshkMsydO5eGkAg5iwIVQoKArqgIUeef73r/BBoGGq+PP/4Y1dXViIyMxLRp0/DTTz8FzUKOg0VERMBqtaK/vx9paWlYsWKFv5tEiM9RoEJIEFBv2YKkNWuc79+8GUmrV/uwRcHHtg5SZWUljEYjhEIh2tvb0dfX5++mjcrcuXMRHx+PsrIyGAwGzJw5k4aPyIRGgQohQYB6VLzHlsTb3d0NvV6P9vZ2lJeX+7tZoyaVSiEUChEZGYmLLrqIho7IhEGBCiFBgnJUfKukpASnTp2CWCxGd3c31Gq11xZy9BaFQgGJRAKz2QyBQIA5c+bQCtQk6Pg9UKmtrcVf//pXfPfdd2hubkZiYiJWrlyJxx9/HEKhkDuutLQU9957Lw4dOoSYmBisXbsWjzzyiNuPQ4EKCXZUWC4wfPXVVzh27BisViukUil0IyyuGIhmzpwJhmHAVFZC0tgIQ2IiMq68koIYEpD8vnryqVOnYLVa8Z///AdZWVkoLy/HmjVr0NPTg3/84x9cI6+88kosWrQIr7zyCsrKyvCb3/wGkZGRuPvuu73VNEICiiQxEUmlpXaF5ZJouMfnCgoKUFBQYLfN1vtiq5siFouhGrQsQKCpKi7GssJC+6ULNm/Gs8uXg42MRGRkJOLj4yESiTBlyhQaRiJBwadDP8899xxefvllVFdXAwBefvllPP7442hubuZ6WR599FF8/PHHTmsomEwmu25avV6PlJQU6lEhhPiMrQZMV1cX+vr6YLFY0NLS4vcqvLdu3+50Mcgdq1YNOz6zshLZOh2Ms2aBV1CAsLAwpKWl0SKOxCf83qPiSGdnJ+SDlng/cOAAFi5caDcUVFBQgGeffRY6nQ5RDpaL37hxI5566imftJcQQhwZvAr1YBqNBvv27UNTUxOEQiFCQkJgsVhw5swZr7dJ3t5u15Niw2NZZKlUkGs03HpLkRoNVm/ZglCjceCgL75Azz//ic13343OqChIJBJER0cjMTERWVlZYFkWcrmcAhjiFz4LVKqqqvDiiy9ywz4A0NzcjIyMDLvj4uLiuH2OApXHHnsM69at427belQIIcTfFAoFli5d6nCfSqXCsWPH0NraCrPZDL1eD4vF4rHHlo+QUyPXarlAZfWWLZDagpSzpEYj1rz6Kv6xfj2MRiPOnDmDM2fOoKioyO44gUCAsLAwxMbGcqtS0xAS8aZRByqPPvoonn32WZfHnDx5Ejk5OdxttVqNxYsX44YbbsAaFzUj3CESiSASicZ1DkII8TVHvTCD10GyWq3QarX49ttvx1QDRuvgh53d/rO92ZmVlb/0pAzCAAg1GpGhUqHGReDR19cHrVYLrVYLACguLgbDMMjPz4dOp4PJZEJeXh4l8BKPGXWg8uCDD+KOO+5weUxmZib3/42Njbj00ktxwQUX4NVXX7U7Lj4+Hi0tLXbbbLfj4+NH2zRCCAkqtlWaB8vPz+eGkBoaGmC1WmGxWGA0Gl0GMNroaFQplU5zVGy9Kclqtcs2pZw54zJQcYRlWRw8eJC7XVtbi507dyIiIgJisRgAIJFIKIAhYzLqQCUmJgYxMTFuHatWq3HppZdizpw52Lp1K3g8nt3++fPn4/HHH0dfXx8EAgEAYPfu3Zg6darDYR9CCJkMnA0hDc2B6enpsZtGXbh8OZZ98IFdrkp1ZiYKly/nbjckJbl87DMeHErv7OxEZ2cnd3twABMfH4/IyEjExMQgPT2d8l+IU16b9aNWq3HJJZcgLS0Nb7zxBvh8PrfP1lvS2dmJqVOn4sorr8T69etRXl6O3/zmN3jhhRfcnp5MdVQIIZNdSUkJampqEBoaCoPBAFRWQlhfjxo+H5pBExhsHnr2WUiNRjCDtrEADBIJ/rF+vc/aPZgt78VqtaK1tRU8Ho9WoZ7g/F7wbdu2bbjzzjsd7hv8kIMLvkVHR2Pt2rVYP4p/KBSoEEKIcyqVCnv27EFHRwf4fP7Ad6ZOhzWvvmqXq9IjkXCzfgKNUqnkVqFOTEzEjBkzqAdmAvB7oOIrFKgQQsjo2FahTq+qQlJdHWoSElARZLMnIyIikJWVhebmZvT19SEjIwNz586lACaIUKBCCCHEbbZVqDUaDVdYMyIiAuXl5R6dRu1tfD4fU6dOhVKpRFdXF5KTk2n6dICiQIUQQohHqFQqfP/992hra0N/f39QBS4AIBQKMW3aNFRXV0MoFGLWrFmIj4+nInZ+RoEKIYQQr/n4449x8uRJMAyDxMREJCcno7i4OOhWohaLxUhKSkJ0dDTNQPIxClQIIYT43OAaMABgsVjQ0dHh30aNUmhoKFiWBcuyiI+Px4wZMyiA8QIKVAghhASMr776CseOHYPFYkFYWBiio6Mhk8lQVVVlV2slkPF4PPD5fAgEAqSkpCA7O5sCmHGgQIUQQkhQ0Gg0OHToEHQ6HfR6PZqbm/3dpFFhGAbTp09HaGgoAND6R26iQIUQQkjQ2rdvH44cOQIASE5ORk1NDXp6evzcKvcJhUIsWbIEJ0+eREtLCxQKBWbMmIG0tDTqgTmLAhVCCCETim0Rx+7ubuj1evT29qK2tjboemD4fD5ycnK4oa+QkBDk5+dPunWQKFAhhBAyaahUKvz444/o6upCTEwMVCrVmFah9jeZTIaQkBBERUUhLS0NM2fOnLA9MBSoEEIImdRUKhUaGhqQnJyMqqoqlJWVBdXwkQ3DMAgLC4NCoYBAIEBOTs6E6H2hQIUQQghxQKVS4dixY+ju7gYwkE8ik8lQWVkJvV7v59a5h2EYpKWlob29HWKxGFarFQzDYNasWUGzkCMFKoQQQsgo2erAVFVVob+/P+gK2NlkZmbCbDbDaDQiKSkJCxcuDLghJApUCCGEEA9QqVQ4dOgQGhsbYTKZwLJsUOa/8Pl8MAwDi8UCmUyGSy+91K9DSBSoEEIIIV708ccf4/Tp0wgJCUFmZib4fD6qqqqCZvjIJiYmBn19fejp6QHDMJg2bRqWLl3q9celQIUQQgjxA9s0ah6Ph59//hn19fUwGAz+btaoZWZmerX2CwUqhBBCSACxFbGzWCzIzMyExWJBeXm5v5vlloyMDNxwww2QSCQeOycFKoQQQkgQKCkpwalTp2A0GtHV1QWLxYKuri5/N2sYpVKJlStXeux87l6/Qzz2iIQQQggZtdmzZztMalWpVNizZw+0Wi1EIhHCw8PR1tYGo9Hoh1YOtEej0fh89hAFKoQQQkgAUiqVDhc3tOXAHP/oI5hPnkRreDg0crlP2qTVailQIYQQQohz0t5e9C5bhqVlZdy2hpkzcWDtWpzp7oZUKoVIJEJ9fb3HH1vuo4BoMApUCCGEkCCiXbIECUOScBOPH8cFL72EpNJSu+1fffUVTp06BZFIBIFAgMbGRlit1jE9rlKp9EvROEqmJYQQQoKErqgIUeef73r/vHkjnscWwPD5fEgkEnR2drpM4PXnrB/qUSGEEEKChKGsDFGu9peWuhWoFBQUoKCgYNh2lUqF0tJSmEwmREREIC4uzmt1VNxFgQohhBASJKS5ua735+WN6/zOEnj9iefvBhBCCCHEPVH5+VDn5sLKMHbbrQwDdW6uW70pwYYCFUIIISSIyHftQtPMmXbbmmbOhHzXLj+1yLto6IcQQggJALqiIhjKyiDNy3PZMyJJTERSaSl0xcUwlJZCmpeHpAnYk2JDgQohhBDiR0a1GtolS5A0KFFWnZsL+a5dkCQmOr1f1Lx5E3KoZyga+iGEEEL8yFFdlITycmgXL/ZTiwILBSqEEEKIn+iKipBUVgbekJJmPJZFUlkZdMXFfmpZ4KBAhRBCCPETw6Ay+A73D6k0OxlRoEIIIYT4ibfrokwEFKgQQgghfjIZ66KMFgUqhBBCiB9Ntrooo0XTkwkhhBA/GktdFHdrrkwEFKgQQgghAcCduihjrbkSzLw69HPttdciNTUVYrEYCQkJWLVqFRobG+2OKS0txYIFCyAWi5GSkoJNmzZ5s0mEEEJI0JqMNVe8GqhceumleO+991BRUYHCwkKoVCosX76c26/X63HllVciLS0Nhw8fxnPPPYcnn3wSr776qjebRQghhASdyVpzxatDP3/4wx+4/09LS8Ojjz6KpUuXoq+vDwKBADt27IDZbMbrr78OoVCIGTNm4OjRo3j++edx9913OzynyWSCyWTibuv1em8+BUIIISQgGAYN9zjcX1o6IfNVfDbrR6vVYseOHbjgggsgEAgAAAcOHMDChQshFAq54woKClBRUQGdTufwPBs3bkRERAT3l5KS4pP2E0IIIf40WWuueD1QWb9+PUJDQ6FQKFBfX49PPvmE29fc3Iy4uDi74223m5ubHZ7vscceQ2dnJ/d35swZ7zWeEEIICRCTtebKqAOVRx99FAzDuPw7deoUd/zDDz+MkpISfP311+Dz+bjtttvADhlfGw2RSITw8HC7P0IIIWQymIw1V0ado/Lggw/ijjvucHlMZmYm9//R0dGIjo7GlClTMG3aNKSkpODgwYOYP38+4uPj0dLSYndf2+34+PjRNo0QQgiZ0MZScyXYjTpQiYmJQUxMzJgezGq1AgCXDDt//nw8/vjjXHItAOzevRtTp05FVJSrlCFCCCFk8nKn5spE4bUclaKiIrz00ks4evQo6urq8N133+Hmm2+GUqnE/PnzAQC33HILhEIh7rrrLhw/fhzvvvsu/vd//xfr1q3zVrMIIYQQEkS8FqhIpVJ8+OGHuPzyyzF16lTcddddyMvLww8//ACRSAQAiIiIwNdff42amhrMmTMHDz74IJ544gmnU5MJIYQQMrkw7HgyWwOAXq9HREQEOjs7KbGWEEIICRLuXr9p9WRCCCGEBCwKVAghhBASsChQIYQQQkjAokCFEEIIIQGLAhVCCCGEBCwKVAghhBASsChQIYQQQkjAokCFEEIIIQGLAhVCCCGEBCwKVAghhBASsChQIYQQQkjAokCFEEIIIQGLAhVCCCGEBCwKVAghhBASsChQIYQQQkjACvF3AwghhJBgpCsqgqGsDNK8PETNm+fv5kxYFKgQQggho2BUq6FdsgRJZWWIOrtNnZsL+a5dkCQm+rVtExEN/RBCCCGjoF2yBAnl5XbbEsrLoV282E8tmtgoUCGEEELcpCsqQlJZGXgsa7edx7JIKiuDrrjYTy2buChQIYQQQtxkKCtzvb+01EctmTwoUCGEEELcJM3Ndb0/L89HLZk8KFAhhBBC3BSVnw91bi6sDGO33cowUOfm0uwfL6BAhRBCCBkF+a5daJo5025b08yZkO/a5acWTWw0PZkQQggZBUliIpJKS6ErLoahtBTSvDwkUU+K11CgQgghhIxB1Lx5NNTjAzT0QwghhJCARYEKIYQQQgIWBSqEEEIICVgUqBBCCCEkYFGgQgghhJCARYEKIYQQQgIWBSqEEEIICVgUqBBCCCEkYFGgQgghhJCARYEKIYQQQgJW0JfQZ1kWAKDX6/3cEkIIIYS4y3bdtl3HnQn6QKWrqwsAkJKS4ueWEEIIIWS0urq6EBER4XQ/w44UygQ4q9WKxsZGhIWFgWEYfzfH4/R6PVJSUnDmzBmEh4f7uzmTCr32/kOvvX/R6+8/k+m1Z1kWXV1dSExMBI/nPBMl6HtUeDwekpOT/d0MrwsPD5/wH9pARa+9/9Br71/0+vvPZHntXfWk2FAyLSGEEEICFgUqhBBCCAlYFKgEOJFIhA0bNkAkEvm7KZMOvfb+Q6+9f9Hr7z/02g8X9Mm0hBBCCJm4qEeFEEIIIQGLAhVCCCGEBCwKVAghhBASsChQIYQQQkjAokCFEEIIIQGLAhU/+dvf/oYLLrgAUqkUkZGRDo+pr6/HVVddBalUitjYWDz88MPo7++3O+b777/HueeeC5FIhKysLGzbtm3Yef7v//4P6enpEIvFyM/PR3FxsReeUXBLT08HwzB2f88884zdMaWlpViwYAHEYjFSUlKwadOmYed5//33kZOTA7FYjNzcXHzxxRe+egoTCn1mPe/JJ58c9hnPycnh9vf29uLee++FQqGATCbDsmXL0NLSYncOd76TCLB3715cc801SExMBMMw+Pjjj+32syyLJ554AgkJCZBIJFi0aBEqKyvtjtFqtbj11lsRHh6OyMhI3HXXXeju7rY7xp3vpAmBJX7xxBNPsM8//zy7bt06NiIiYtj+/v5+dubMmeyiRYvYkpIS9osvvmCjo6PZxx57jDumurqalUql7Lp169gTJ06wL774Isvn89ldu3Zxx7zzzjusUChkX3/9dfb48ePsmjVr2MjISLalpcUXTzNopKWlsX/5y1/YpqYm7q+7u5vb39nZycbFxbG33norW15ezr799tusRCJh//Of/3DH7N+/n+Xz+eymTZvYEydOsH/6059YgUDAlpWV+eMpBS36zHrHhg0b2BkzZth9xtva2rj9v/vd79iUlBT222+/ZX/++Wf2/PPPZy+44AJuvzvfSWTAF198wT7++OPshx9+yAJgP/roI7v9zzzzDBsREcF+/PHH7LFjx9hrr72WzcjIYI1GI3fM4sWL2VmzZrEHDx5k9+3bx2ZlZbE333wzt9+d76SJggIVP9u6davDQOWLL75geTwe29zczG17+eWX2fDwcNZkMrEsy7KPPPIIO2PGDLv7rVixgi0oKOBuz5s3j7333nu52xaLhU1MTGQ3btzo4WcS3NLS0tgXXnjB6f5///vfbFRUFPfasyzLrl+/np06dSp3+8Ybb2Svuuoqu/vl5+ezv/3tbz3e3omMPrPesWHDBnbWrFkO93V0dLACgYB9//33uW0nT55kAbAHDhxgWda97yQy3NBAxWq1svHx8exzzz3Hbevo6GBFIhH79ttvsyzLsidOnGABsIcOHeKO+fLLL1mGYVi1Ws2yrHvfSRMFDf0EqAMHDiA3NxdxcXHctoKCAuj1ehw/fpw7ZtGiRXb3KygowIEDBwAAZrMZhw8ftjuGx+Nh0aJF3DHkF8888wwUCgVmz56N5557zq5L+8CBA1i4cCGEQiG3raCgABUVFdDpdNwxrt4PMjL6zHpXZWUlEhMTkZmZiVtvvRX19fUAgMOHD6Ovr8/udc/JyUFqair3urvznURGVlNTg+bmZrvXOiIiAvn5+XavdWRkJM477zzumEWLFoHH46GoqIg7ZqTvpIki6FdPnqiam5vtvhAAcLebm5tdHqPX62E0GqHT6WCxWBwec+rUKS+2Pvjcf//9OPfccyGXy/HTTz/hscceQ1NTE55//nkAA691RkaG3X0Gvx9RUVFO3w/b+0VG1t7eTp9ZL8nPz8e2bdswdepUNDU14amnnsKCBQtQXl6O5uZmCIXCYflygz+/7nwnkZHZXitX3xXNzc2IjY212x8SEgK5XG53zEjfSRMFBSoe9Oijj+LZZ591eczJkyftEtiI94zm/Vi3bh23LS8vD0KhEL/97W+xceNGWnODTAhLlizh/j8vLw/5+flIS0vDe++9B4lE4seWEeIaBSoe9OCDD+KOO+5weUxmZqZb54qPjx8208GWgR8fH8/9d2hWfktLC8LDwyGRSMDn88Hn8x0eYzvHRDae9yM/Px/9/f2ora3F1KlTnb7WwMjvx2R4rT0lOjp6Un9mfSkyMhJTpkxBVVUVrrjiCpjNZnR0dNj1qgx+3d35TiIjs71WLS0tSEhI4La3tLTgnHPO4Y5pbW21u19/fz+0Wu2I3zeDH2OioBwVD4qJiUFOTo7Lv8Hjia7Mnz8fZWVldh/W3bt3Izw8HNOnT+eO+fbbb+3ut3v3bsyfPx8AIBQKMWfOHLtjrFYrvv32W+6YiWw878fRo0fB4/G47tf58+dj79696Ovr447ZvXs3pk6dynWxjvR+kJFN9s+sL3V3d0OlUiEhIQFz5syBQCCwe90rKipQX1/Pve7ufCeRkWVkZCA+Pt7utdbr9SgqKrJ7rTs6OnD48GHumO+++w5WqxX5+fncMSN9J00Y/s7mnazq6urYkpIS9qmnnmJlMhlbUlLClpSUsF1dXSzL/jIV8Morr2SPHj3K7tq1i42JiXE4Pfnhhx9mT548yf7f//2fw+nJIpGI3bZtG3vixAn27rvvZiMjI+0y9ye7n376iX3hhRfYo0ePsiqVin3zzTfZmJgY9rbbbuOO6ejoYOPi4thVq1ax5eXl7DvvvMNKpdJh05NDQkLYf/zjH+zJkyfZDRs20PTkMaDPrHc8+OCD7Pfff8/W1NSw+/fvZxctWsRGR0ezra2tLMsOTE9OTU1lv/vuO/bnn39m58+fz86fP5+7vzvfSWRAV1cX950OgH3++efZkpIStq6ujmXZgenJkZGR7CeffMKWlpay1113ncPpybNnz2aLiorYH3/8kc3OzrabnuzOd9JEQYGKn9x+++0sgGF/e/bs4Y6pra1llyxZwkokEjY6Opp98MEH2b6+Prvz7Nmzhz3nnHNYoVDIZmZmslu3bh32WC+++CKbmprKCoVCdt68eezBgwe9/OyCy+HDh9n8/Hw2IiKCFYvF7LRp09i///3vbG9vr91xx44dYy+66CJWJBKxSUlJ7DPPPDPsXO+99x47ZcoUVigUsjNmzGA///xzXz2NCYU+s563YsUKNiEhgRUKhWxSUhK7YsUKtqqqittvNBrZ3//+92xUVBQrlUrZX//612xTU5PdOdz5TiID38uOvt9vv/12lmUHpij/+c9/ZuPi4liRSMRefvnlbEVFhd05NBoNe/PNN7MymYwNDw9n77zzTu6HrI0730kTAcOyLOunzhxCCCGEEJcoR4UQQgghAYsCFUIIIYQELApUCCGEEBKwKFAhhBBCSMCiQIUQQgghAYsCFUIIIYQELApUCCGEEBKwKFAhhBBCSMCiQIUQQgghAYsCFUIIIYQELApUCCGEEBKw/j8cOSLH+eXELwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "ori_test = pd.read_csv('./data/test_data.csv')\n",
    "ori_test[\"label\"] = sub[\"label\"].values\n",
    "\n",
    "outliers=sub.loc[ori_test['label']==1]\n",
    "outlier_index=list(outliers.index)\n",
    "\n",
    "pca = PCA(2)\n",
    "res = pd.DataFrame(pca.fit_transform(ori_test))\n",
    "\n",
    "plt.title(\"result - PCA\")\n",
    "b1 = plt.scatter(res[0], res[1], c='gray', s=20, label='normal')\n",
    "b2 = plt.scatter(res.iloc[outlier_index, 0], res.iloc[outlier_index, 1], c='red', s=20, edgecolor=\"red\", label='outliers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"AD_64.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLOP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
